{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9c9577e7-fde4-4833-8bf9-03a6fb35ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lgb1d, lgb imputer\n",
    "mname = 'lgb2d'\n",
    "path = './'\n",
    "ncf = 0\n",
    "ncd = 0\n",
    "\n",
    "start = 550\n",
    "stop = 700\n",
    "\n",
    "importance_type = 'gain'\n",
    "# importance_type = 'weight'\n",
    "# importance_type = 'cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7922de86-9f83-4339-8ffc-32b3ee587687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc, os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b8b2d30e-eca5-46c0-96a6-b76312bd8448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PublicID</th>\n",
       "      <th>A02_Complete</th>\n",
       "      <th>A02_Complete_1</th>\n",
       "      <th>A02_Status</th>\n",
       "      <th>A02_Status_1</th>\n",
       "      <th>A02Ver</th>\n",
       "      <th>A02Ver_1</th>\n",
       "      <th>A02DATE_INT</th>\n",
       "      <th>A02DATE_INT_1</th>\n",
       "      <th>A02A01</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 11707</th>\n",
       "      <th>Unnamed: 11708</th>\n",
       "      <th>Unnamed: 11709</th>\n",
       "      <th>Unnamed: 11710</th>\n",
       "      <th>Unnamed: 11711</th>\n",
       "      <th>Unnamed: 11712</th>\n",
       "      <th>Unnamed: 11713</th>\n",
       "      <th>Unnamed: 11714</th>\n",
       "      <th>Unnamed: 11715</th>\n",
       "      <th>Unnamed: 11716</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001U</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004O</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007I</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00008G</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00015J</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>17349I</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>17350A</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>17351V</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>17352T</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>17354P</td>\n",
       "      <td>Complete</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9289 rows × 11717 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PublicID A02_Complete A02_Complete_1 A02_Status A02_Status_1  A02Ver  \\\n",
       "0      00001U     Complete            NaN     Passed          NaN       2   \n",
       "1      00004O     Complete            NaN     Passed          NaN       2   \n",
       "2      00007I     Complete            NaN     Passed          NaN       2   \n",
       "3      00008G     Complete            NaN     Passed          NaN       2   \n",
       "4      00015J     Complete            NaN     Passed          NaN       2   \n",
       "...       ...          ...            ...        ...          ...     ...   \n",
       "9284   17349I     Complete            NaN     Passed          NaN       2   \n",
       "9285   17350A     Complete            NaN     Passed          NaN       2   \n",
       "9286   17351V     Complete            NaN     Passed          NaN       2   \n",
       "9287   17352T     Complete            NaN     Passed          NaN       2   \n",
       "9288   17354P     Complete            NaN     Passed          NaN       2   \n",
       "\n",
       "      A02Ver_1  A02DATE_INT  A02DATE_INT_1  A02A01  ...  Unnamed: 11707  \\\n",
       "0          NaN         -197            NaN       1  ...             NaN   \n",
       "1          NaN         -199            NaN       1  ...             NaN   \n",
       "2          NaN         -208            NaN       1  ...             NaN   \n",
       "3          NaN         -205            NaN       1  ...             NaN   \n",
       "4          NaN         -198            NaN       1  ...             NaN   \n",
       "...        ...          ...            ...     ...  ...             ...   \n",
       "9284       NaN         -202            NaN       1  ...             NaN   \n",
       "9285       NaN         -219            NaN       1  ...             NaN   \n",
       "9286       NaN         -200            NaN       1  ...             NaN   \n",
       "9287       NaN         -196            NaN       1  ...             NaN   \n",
       "9288       NaN         -186            NaN       1  ...             NaN   \n",
       "\n",
       "     Unnamed: 11708 Unnamed: 11709 Unnamed: 11710 Unnamed: 11711  \\\n",
       "0               NaN            NaN            NaN            NaN   \n",
       "1               NaN            NaN            NaN            NaN   \n",
       "2               NaN            NaN            NaN            NaN   \n",
       "3               NaN            NaN            NaN            NaN   \n",
       "4               NaN            NaN            NaN            NaN   \n",
       "...             ...            ...            ...            ...   \n",
       "9284            NaN            NaN            NaN            NaN   \n",
       "9285            NaN            NaN            NaN            NaN   \n",
       "9286            NaN            NaN            NaN            NaN   \n",
       "9287            NaN            NaN            NaN            NaN   \n",
       "9288            NaN            NaN            NaN            NaN   \n",
       "\n",
       "     Unnamed: 11712 Unnamed: 11713 Unnamed: 11714 Unnamed: 11715  \\\n",
       "0               NaN            NaN            NaN            NaN   \n",
       "1               NaN            NaN            NaN            NaN   \n",
       "2               NaN            NaN            NaN            NaN   \n",
       "3               NaN            NaN            NaN            NaN   \n",
       "4               NaN            NaN            NaN            NaN   \n",
       "...             ...            ...            ...            ...   \n",
       "9284            NaN            NaN            NaN            NaN   \n",
       "9285            NaN            NaN            NaN            NaN   \n",
       "9286            NaN            NaN            NaN            NaN   \n",
       "9287            NaN            NaN            NaN            NaN   \n",
       "9288            NaN            NaN            NaN            NaN   \n",
       "\n",
       "     Unnamed: 11716  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "...             ...  \n",
       "9284            NaN  \n",
       "9285            NaN  \n",
       "9286            NaN  \n",
       "9287            NaN  \n",
       "9288            NaN  \n",
       "\n",
       "[9289 rows x 11717 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main data table, specify D as a missing value for many of the numeric columns\n",
    "a = pd.read_csv(path+'nuMoM2b_Dataset_NICHD Data Challenge.csv', low_memory=False, na_values='D')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cd21bd81-edcd-4336-bedf-216738955b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1988.000000\n",
       "mean      -21.683099\n",
       "std        30.949480\n",
       "min      -143.000000\n",
       "25%       -30.000000\n",
       "50%       -11.000000\n",
       "75%        -1.000000\n",
       "max        18.000000\n",
       "Name: CMDA05A_INT, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create survival target for xgboost, negative values indicate censoring\n",
    "a['CMDA05A_INT'] = a['CMDA05A_INT'].apply(pd.to_numeric, errors='coerce')\n",
    "a['CMDA05A_INT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c120c67f-d5e3-4f03-aba6-c729fb604c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     7301\n",
       "False    1988\n",
       "Name: CMDA05A_INT, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " a.CMDA05A_INT.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1784d662-f8b8-4b01-81fd-ea1741e26aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9289.000000\n",
       "mean        0.785983\n",
       "std         0.410160\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: censor, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['censor'] = a.CMDA05A_INT.isnull().astype(int)\n",
    "a.censor.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f434dfc7-bd67-4edb-935a-98a7a96ad898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8886.000000\n",
       "mean       38.485483\n",
       "std         3.402333\n",
       "min         6.000000\n",
       "25%        38.000000\n",
       "50%        39.000000\n",
       "75%        40.000000\n",
       "max        43.000000\n",
       "Name: GAwksCA, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.GAwksCA.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "127c938f-e832-4a02-b276-1eaba9c920bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a['cmda05_days'] = a.CMDA05A_INT.fillna(0) + a.CMDA05a_HR.fillna(0)/24.0 + a.CMDA05a_MIN.fillna(0)/(24.0*60)\n",
    "a.cmda05_days.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6d01a29e-20e4-4a1e-939f-d93fa9cc7dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a['tthd'] = (7 * a.GAwksCA + a.GAdysCA + a.cmda05_days)*(1.0 - 2 * a.censor)\n",
    "a.tthd.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9ec63065-8108-4634-9036-9d34ca9d7fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8886.000000\n",
       "mean     -155.557149\n",
       "std       219.958845\n",
       "min      -304.000000\n",
       "25%      -282.000000\n",
       "50%      -274.000000\n",
       "75%      -234.000000\n",
       "max       316.055556\n",
       "Name: tthd, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.tthd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fdb14ea1-b38b-4fad-bc23-2f69ef5429b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9289, 11720)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with missing target\n",
    "# a = a[a.tthd.notnull()]\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2051b26-a9ec-4c26-990b-0cc8a596c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'tthd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f68f7fb1-b4b3-406a-9cf2-166d0b1fd795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFQ_Date_int</th>\n",
       "      <th>JAN_PP</th>\n",
       "      <th>FEB_PP</th>\n",
       "      <th>MAR_PP</th>\n",
       "      <th>APR_PP</th>\n",
       "      <th>MAY_PP</th>\n",
       "      <th>JUN_PP</th>\n",
       "      <th>JUL_PP</th>\n",
       "      <th>AUG_PP</th>\n",
       "      <th>SEP_PP</th>\n",
       "      <th>...</th>\n",
       "      <th>AHEI_WGRAINS</th>\n",
       "      <th>AHEI_SUGBEVS</th>\n",
       "      <th>AHEI_NUTLEGS</th>\n",
       "      <th>AHEI_RMEATS</th>\n",
       "      <th>AHEI_TRFATPCT</th>\n",
       "      <th>AHEI_DHAEPA</th>\n",
       "      <th>AHEI_PUFAPCT</th>\n",
       "      <th>AHEI_SODIUM</th>\n",
       "      <th>AHEI_ALCDRKS</th>\n",
       "      <th>AHEI2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.4900</td>\n",
       "      <td>6.162236</td>\n",
       "      <td>7.478604</td>\n",
       "      <td>7.360</td>\n",
       "      <td>9.020737</td>\n",
       "      <td>6.962302</td>\n",
       "      <td>2.5</td>\n",
       "      <td>52.410880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.3800</td>\n",
       "      <td>6.564417</td>\n",
       "      <td>7.673692</td>\n",
       "      <td>0.936</td>\n",
       "      <td>6.294495</td>\n",
       "      <td>6.954905</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.209509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002</td>\n",
       "      <td>5.366402</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>5.310157</td>\n",
       "      <td>9.430597</td>\n",
       "      <td>5.400</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>70.084156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>202.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.1650</td>\n",
       "      <td>4.669393</td>\n",
       "      <td>8.982259</td>\n",
       "      <td>3.596</td>\n",
       "      <td>4.476044</td>\n",
       "      <td>5.179470</td>\n",
       "      <td>2.5</td>\n",
       "      <td>40.753166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4909</td>\n",
       "      <td>1.567825</td>\n",
       "      <td>7.280527</td>\n",
       "      <td>1.052</td>\n",
       "      <td>8.100696</td>\n",
       "      <td>9.633505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>38.578954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294</td>\n",
       "      <td>9.155644</td>\n",
       "      <td>3.5790</td>\n",
       "      <td>8.588957</td>\n",
       "      <td>9.874415</td>\n",
       "      <td>3.496</td>\n",
       "      <td>6.962957</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.258473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.9600</td>\n",
       "      <td>7.600545</td>\n",
       "      <td>8.367089</td>\n",
       "      <td>9.040</td>\n",
       "      <td>8.911255</td>\n",
       "      <td>9.068236</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68.488125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.3000</td>\n",
       "      <td>5.501022</td>\n",
       "      <td>9.063648</td>\n",
       "      <td>2.152</td>\n",
       "      <td>9.032943</td>\n",
       "      <td>6.730854</td>\n",
       "      <td>2.5</td>\n",
       "      <td>42.594468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9289 rows × 733 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FFQ_Date_int  JAN_PP  FEB_PP  MAR_PP  APR_PP  MAY_PP  JUN_PP  JUL_PP  \\\n",
       "0              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1            234.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "2              0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3            205.0     0.0     1.0     1.0     1.0     0.0     0.0     0.0   \n",
       "4            198.0     0.0     1.0     1.0     1.0     0.0     0.0     0.0   \n",
       "...            ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9284         202.0     1.0     1.0     1.0     0.0     0.0     0.0     0.0   \n",
       "9285         229.0     0.0     0.0     0.0     1.0     1.0     1.0     0.0   \n",
       "9286         200.0     0.0     0.0     1.0     1.0     1.0     0.0     0.0   \n",
       "9287         196.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9288         187.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      AUG_PP  SEP_PP  ...  AHEI_WGRAINS  AHEI_SUGBEVS  AHEI_NUTLEGS  \\\n",
       "0        0.0     0.0  ...         0.000      0.000000        0.0000   \n",
       "1        0.0     0.0  ...         1.502      0.000000        4.4900   \n",
       "2        0.0     0.0  ...         0.000      0.000000        0.0000   \n",
       "3        0.0     0.0  ...         1.186      0.000000        3.3800   \n",
       "4        0.0     0.0  ...         1.002      5.366402       10.0000   \n",
       "...      ...     ...  ...           ...           ...           ...   \n",
       "9284     0.0     0.0  ...         0.860      0.000000        3.1650   \n",
       "9285     0.0     0.0  ...         0.816      0.000000        0.4909   \n",
       "9286     0.0     0.0  ...         0.294      9.155644        3.5790   \n",
       "9287     0.0     0.0  ...         1.956      0.000000        5.9600   \n",
       "9288     0.0     1.0  ...         0.562      0.000000        4.3000   \n",
       "\n",
       "      AHEI_RMEATS  AHEI_TRFATPCT  AHEI_DHAEPA  AHEI_PUFAPCT  AHEI_SODIUM  \\\n",
       "0        0.000000       0.000000        0.000      0.000000     0.000000   \n",
       "1        6.162236       7.478604        7.360      9.020737     6.962302   \n",
       "2        0.000000       0.000000        0.000      0.000000     0.000000   \n",
       "3        6.564417       7.673692        0.936      6.294495     6.954905   \n",
       "4        5.310157       9.430597        5.400     10.000000     0.000000   \n",
       "...           ...            ...          ...           ...          ...   \n",
       "9284     4.669393       8.982259        3.596      4.476044     5.179470   \n",
       "9285     1.567825       7.280527        1.052      8.100696     9.633505   \n",
       "9286     8.588957       9.874415        3.496      6.962957    10.000000   \n",
       "9287     7.600545       8.367089        9.040      8.911255     9.068236   \n",
       "9288     5.501022       9.063648        2.152      9.032943     6.730854   \n",
       "\n",
       "      AHEI_ALCDRKS   AHEI2010  \n",
       "0              0.0   0.000000  \n",
       "1              2.5  52.410880  \n",
       "2              0.0   0.000000  \n",
       "3              5.0  53.209509  \n",
       "4              5.0  70.084156  \n",
       "...            ...        ...  \n",
       "9284           2.5  40.753166  \n",
       "9285           5.0  38.578954  \n",
       "9286           5.0  61.258473  \n",
       "9287          10.0  68.488125  \n",
       "9288           2.5  42.594468  \n",
       "\n",
       "[9289 rows x 733 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_food_onehot = a.loc[:,\"FFQ_Date_int\":\"AHEI2010\"].apply(lambda foodCol: pd.to_numeric(foodCol, errors=\"coerce\")).fillna(0)\n",
    "a_food_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "75bd6c2a-dd1f-4552-a9cf-10653e064095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map positive numbers to 1 and the others to 0\n",
    "# a_food_onehot[a_food_onehot > 0] = 1 \n",
    "# a_food_onehot[a_food_onehot <= 0] = 0 \n",
    "# a_food_onehot = a_food_onehot.astype(int)\n",
    "# a_food_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "92d83f28-9c57-4556-ad2a-98d5267dd29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.unique(a_food_onehot.values.ravel(\"K\")) # now there are only 0 and 1 s in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61cfa88c-d139-46fb-8124-1b15fd54f4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_food_onehot.mean().plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2290b212-b163-4590-858f-082a90037b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca on foods\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "if ncf > 0:\n",
    "    tsvd = TruncatedSVD(n_components=ncf)\n",
    "\n",
    "    a_food_onehot0 = a_food_onehot.copy()\n",
    "\n",
    "    a_food_onehot = tsvd.fit_transform(a_food_onehot0)\n",
    "    a_food_onehot = pd.DataFrame(a_food_onehot, columns = [f'food_svd{i}' for i in range(ncf)],\n",
    "                                index=a_food_onehot0.index)\n",
    "    a_food_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e971ba8-784c-4369-8e94-f2b357888efe",
   "metadata": {},
   "source": [
    "#### One-hot Encoding for Drugs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e3861eca-59df-4fdc-8ec4-ea00f3d8565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many unique drug names in all the drug name columns \n",
    "drug_union = pd.unique(a[a.columns[a.columns.str.startswith(\"DrugName\")]].values.ravel(\"K\"))\n",
    "len(drug_union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9638baa4-dec4-40f0-ab90-dac4ec20dd14",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'IBUPROFEN' 'FLUTICASONE' 'PRENATAL VITAMIN' 'LEVOTHYROXINE'\n",
      " 'ADDERALL' 'SERTRALINE' 'DESVENLAFAXINE' 'VITAMIN D' 'UNKNOWN'\n",
      " 'ACYCLOVIR' 'NAPROXEN' 'INFLUENZA VACCINE' 'OCP' 'ALBUTEROL'\n",
      " 'TETANUS VACCINE' 'TOPIRAMATE' 'ERYTHROMYCIN' 'RANITIDINE' 'DHA'\n",
      " 'FLUCONAZOLE' 'IRON' 'ACETAMINOPHEN/OXYCODONE' 'PENICILLIN' 'PPD'\n",
      " 'ACETAMINOPHEN' 'CETIRIZINE' 'ENOXAPARIN' 'METFORMIN' 'PROMETHAZINE'\n",
      " 'BUDESONIDE' 'CEPHALEXIN' 'ONDANSETRON' 'ROBITUSSIN' 'TERCONAZOLE'\n",
      " 'METHYLDOPA' 'ASPIRIN/ACETAMINOPHEN/CAFFEINE' 'METRONIDAZOLE'\n",
      " 'METHOTREXATE' 'CITALOPRAM' 'NITROFURANTOIN' 'FOLIC ACID' 'ASPIRIN'\n",
      " 'LACTULOSE' 'BUPRENORPHINE/NALOXONE' 'LORATADINE' 'PREDNISONE'\n",
      " 'OMEPRAZOLE' 'LISDEXAMFETAMINE' 'ESTROGEN' 'AZELAIC ACID' 'BUPROPION'\n",
      " 'FLUOXETINE' 'HYDROXYCHLOROQUINE' 'AMOXICILLIN' 'MULTIVITAMIN'\n",
      " 'MICONAZOLE' 'LEVETIRACETAM' 'VERAPAMIL' 'MESALAMINE' 'VALACYCLOVIR'\n",
      " 'VITAMIN B-6' 'AZITHROMYCIN' 'RIZATRIPTAN' 'INSULIN' 'ZOLPIDEM'\n",
      " 'VENLAFAXINE' 'CALCIUM' 'LABETALOL' 'MONTELUKAST' 'METOCLOPRAMIDE'\n",
      " 'DOXYCYCLINE' 'CLOMIPHENE' 'FISH OIL' 'FEXOFENADINE/PSEUDOEPHEDRINE'\n",
      " 'ESOMEPRAZOLE' 'AMOXICILLIN/CLAVULONATE' 'ALMOTRIPTAN' 'DULOXETINE'\n",
      " 'CYCLOBENZAPRINE' 'TRAZODONE' 'HYDROCORTISONE' 'BUTALBITAL'\n",
      " 'FLUOCINONIDE' 'LISINOPRIL' 'TDAP' 'TRIMETHOPRIM/SULFAMETHOXAZOLE'\n",
      " 'ALPRAZOLAM' 'LAMOTRIGINE' 'ETONOGESTREL/ETHINYL ESTRADIOL VAGINAL RING'\n",
      " 'METHYLPREDNISOLONE' 'CHOLESTYRAMINE' 'PANTOPRAZOLE' 'CABERGOLINE'\n",
      " 'HYDROCHLOROTHIAZIDE' 'SUMATRIPTAN' 'ESCITALOPRAM' 'MOMETASONE'\n",
      " 'ADALIMUMAB' 'GLATIRAMER' 'ALLERGY SHOT' 'PROBIOTIC'\n",
      " 'POLYETHYLENE GLYCOL' 'DOCUSATE' 'MINOCYCLINE' 'PROPRANOLOL' 'DAPSONE'\n",
      " 'METOPROLOL' 'CEFTRIAXONE' 'METHYLPHENIDATE' 'DOXYLAMINE' 'AMLODIPINE'\n",
      " 'BROMOCRIPTINE' 'ANTACID' 'DIPHENHYDRAMINE' 'OXCARBAZEPINE'\n",
      " 'SUMATRIPTAN/NAPROXEN' 'ACETAMINOPHEN/CAFFEINE' 'PROPYLTHIOURACIL'\n",
      " 'PROGESTERONE' 'ESZOPICLONE' 'CLOBETASOL' 'AIRBORNE' 'METHYLERGONOVINE'\n",
      " 'QUETIAPINE' 'PSEUDOEPHEDRINE' 'INTERFERON' 'CLINDAMYCIN' 'GUAIFENESIN'\n",
      " 'MEDROXYPROGESTERONE' 'ARIPIPRAZOLE' 'MENOTROPIN' 'FAMCICLOVIR'\n",
      " 'PROCHLORPERAZINE' 'DALTEPARIN' 'ATENOLOL' 'MAGNESIUM' 'DILTIAZEM'\n",
      " 'DESSICATED THYROID' 'ACETAMINOPHEN/CODEINE' 'HYOSCYAMINE'\n",
      " 'SULFACETAMIDE' 'CIPROFLOXACIN' 'ACETAMINOPHEN/HYDROCODONE'\n",
      " 'BETAMETHASONE' 'CELECOXIB' 'BENZOYL PEROXIDE/CLINDAMYCIN' 'DEPO-PROVERA'\n",
      " 'AMPICILLIN' 'HERBAL' 'GLUTIRAMER' 'NIFEDIPINE' 'LORAZEPAM' 'CEFUROXIME'\n",
      " 'LEVALBUTEROL' 'CEFDINIR' 'TRETINOIN' 'VITAMIN B-COMPLEX' 'SIMVASTATIN'\n",
      " 'ACETAMINOPHEN/BUTALBITAL/CAFFEINE' 'FEXOFENADINE' 'UROFOLLITROPIN'\n",
      " 'SPIRONOLACTONE' 'CYPROHEPTADINE' 'MMR' 'CRANBERRY' 'FLUVOXAMINE'\n",
      " 'OCULAR LUBRICANT' 'OMALIZUMAB' 'DOCOSANOL' 'PSYLLIUM' 'SULFASALAZINE'\n",
      " 'ATOVAQUONE/PROGUANIL' 'ETODOLAC' 'CLONAZEPAM' 'ELETRIPTAN'\n",
      " 'AMITRIPTYLINE' 'TRUVADA' 'ACETAMINOPHEN/DIPHENHYDRAMINE'\n",
      " 'HUMAN CHORIONIC GONADOTROPIN' 'BECLOMETHASONE' 'IUD' 'METHOCARBAMOL'\n",
      " 'CLOTRIMAZOLE' 'NORTRIPTYLINE' 'VILAZODONE' 'FROVATRIPTAN' 'LANSOPRAZOLE'\n",
      " 'TRIAMCINOLONE' 'HEPARIN' 'NYSTATIN' 'HYDROCODONE' 'WARFARIN'\n",
      " 'ZOLMITRIPTAN' 'LEVOFLOXACIN' 'TYPHOID' 'FAMOTIDINE' 'CARBAMAZEPINE'\n",
      " 'URSODIOL' 'ALUMINUM CHLORIDE HEXAHYDRATE' 'NARATRIPTAN' 'AZATHIOPRINE'\n",
      " 'BISMUTH SUBSALICYLATE' 'DEXLANSOPRAZOLE' 'LETROZOLE' 'TACROLIMUS'\n",
      " 'HYDROMORPHONE' 'VITAMIN C' 'CEFAZOLIN' 'COMPLERA' 'TRAMADOL'\n",
      " 'FLUTICASONE/SALMETEROL' 'PHENTERMINE' 'PAROXETINE' 'MERCAPTOPURINE'\n",
      " 'AMINO ACIDS' 'MELATONIN' 'LORATADINE/PSEUDOEPHEDRINE' 'SOLPADEINE'\n",
      " 'NYQUIL' 'OMEGA 3' 'METHIMAZOLE' 'SELENIUM' 'VITAMIN B-12' 'CARVEDILOL'\n",
      " 'GLUCAGON' 'BENZOIC ACID/METHENAMINE/SALICYLATE' 'MODAFINIL'\n",
      " 'ATOMOXETINE' 'DEXTROMETHORPHAN/DOXYLAMINE' 'TAMSULOSIN'\n",
      " 'CALCIUM/VITAMIN D' 'TRIMETHOBENZAMIDE' 'HEPATITIS A VACCINE'\n",
      " 'NYSTATIN/TRIAMCINOLONE' 'OXYCODONE' 'TOBRAMYCIN' 'GABAPENTIN'\n",
      " 'OLOPATADINE' 'L-METHYLFOLATE/VITAMIN B12/N-ACETYLCYSTEINE' 'OXICONAZOLE'\n",
      " 'DOXYLAMINE/B6' 'RHO (D) IMMUNE GLOBULIN' 'DIET PILL' 'PIMECROLIMUS'\n",
      " 'PREGABALIN' 'RISPERIDONE' 'HPV VACCINE' 'CHLORHEXIDINE' 'POTASSIUM'\n",
      " 'ACETAMINOPHEN/DEXTROMETHORPHAN/GUAIFENESIN/PHENYLEPHRINE' 'FIBER'\n",
      " 'CICLESONIDE' 'CHLORPROMAZINE' 'TIOCONAZOLE' 'PENTOSAN' 'BISACODYL'\n",
      " 'PERMETHRIN' 'CETIRIZINE/PSEUDOEPHEDRINE' 'EMETROL' 'TRIAMTERENE'\n",
      " 'GLYBURIDE' 'METHADONE' 'GLUCOSAMINE' 'VITAMIN A' 'NICOTINE' 'TAZAROTENE'\n",
      " 'DEXAMETHASONE' 'LEVONORGESTREL' 'PHENYTOIN' 'NORETHINDRONE'\n",
      " 'OSELTAMIVIR' 'GLYCOPYRROLATE' 'COD LIVER OIL' 'NEVIRAPINE' 'VANCOMYCIN'\n",
      " 'ORAL MEDICATION' 'SIMETHICONE'\n",
      " 'ACETAMINOPHEN/DICHLORALPHENAZONE/ISOMETHEPTENE' 'HYDROXYZINE'\n",
      " 'KETOCONAZOLE' 'LOPERAMIDE' 'ZIPRASIDONE' 'BUDESONIDE/FEMOTEROL'\n",
      " 'VARENICLINE' 'MORPHINE' 'BENZOYL PEROXIDE' 'PENCICLOVIR' 'CETRORELIX'\n",
      " 'MECLIZINE' 'VITAMIN B-6/B-12' 'FENTANYL' 'RBC TRANSFUSION'\n",
      " 'HYDROCHLOROTHIAZIDE/TRIAMTRENE' 'CICLOPIROX' 'LECITHIN' 'COLESTIPOL'\n",
      " 'CHLORPHENAMINE' 'ZAFIRLUKAST' 'VITAMIN E' 'CLINDAMYCIN/BENZOYL PEROXIDE'\n",
      " 'DOCUSATE/SENNA' 'GUAIFENESIN/DEXTROMETHORPHAN' 'INDOMETHACIN' 'PATANOL'\n",
      " 'EMOLLIENTS TOPICAL' 'MARIJUANA' 'SODIUM SULFACETAMIDE' 'SENNA'\n",
      " 'DICYCLOMINE' 'PRIMIDONE' 'ADAPALENE' 'PERTUSSIS VACCINE'\n",
      " 'ESSENTIAL OILS' 'DIAZEPAM' 'TERBUTALINE' 'COUGH DROPS' 'FLUORIDE'\n",
      " 'AZELASTINE' 'HEPATITIS B VACCINE' 'SUCRALFATE' 'VITAMIN B' 'ORTHO EVRA'\n",
      " 'CLONIDINE' 'CEVIMELINE' 'GENTAMICIN'\n",
      " 'ACETAMINOPHEN / DICHLORALPHENAZONE / ISOMETHEPTENE'\n",
      " 'ACETAMINOPHEN/PHENYLEPHRINE' 'ALDOMET' 'VALPROIC ACID' 'TINIDAZOLE'\n",
      " 'LITHIUM' 'LIOTHYRONINE' 'OXYTOCIN' 'LEUPROLIDE' 'ISOTRETINOIN'\n",
      " 'MISOPROSTOL' 'TENOFOVIR' 'NILOTINIB' 'DAYQUIL' 'CIMETIDINE'\n",
      " 'FLAXSEED OIL' 'VARICELLA VACCINE' 'CYCLOSPORINE' 'LEVONORGESTREL IUD'\n",
      " 'LEVOCETIRIZINE' 'CERTOLIZUMAB' 'LINACLOTIDE' 'VITAMIN B-2' 'TIOTROPIUM'\n",
      " 'CODEINE' 'CHLOROQUINE' 'COQ10' 'ORPHENADRINE' 'BUPRENORPHINE'\n",
      " 'ALPHA-GALACTOSIDASE' 'BUDESONIDE NASAL' 'MOXIFLOXACIN' 'BIOPLASMA'\n",
      " 'PYRIDIUM' 'GLIMEPIRIDE' 'OFLOXACIN' 'OLANZAPINE' 'PREVALIN'\n",
      " 'FOLLITROPIN' 'GRAPEFRUIT' 'IBUPROFEN/ACETAMINOPHEN' 'SCOPOLAMINE'\n",
      " 'ISONIAZID' 'HETASTARCH' 'PNV' 'ETONOGESTREL' 'BUSPIRONE' 'DESIPRAMINE'\n",
      " '17-HYDROXYPROGESTERONE' 'CLINICA MOUTHWASH' 'IMIQUIMOD'\n",
      " 'IBUPROFEN/PSEUDOEPHEDRINE' 'LYSINE' 'DESLORATADINE' 'THIAMINE'\n",
      " 'GLYCOLIC ACID' 'DIFLUPREDNATE' 'AFRIN' 'ZINC' 'IODINE' 'ANUSOL'\n",
      " 'CLARITHROMYCIN' 'CALCIUM/MAGNESIUM' 'HALOPERIDOL' 'DICLOFENAC'\n",
      " 'SODIUM PHOSPHORUS' 'INFLIXIMAB' 'ASTRINGENT' 'COLCHICINE' 'OXYMORPHONE'\n",
      " 'BENZONATATE' 'PENICILLIN/AMOXICILLIN' 'CYCLIZINE'\n",
      " 'CHORIOGONADOTROPIN ALFA' 'FLUDROCORTISONE' 'PNEUMONIA VACCINE'\n",
      " 'LIDOCAINE' 'PHENAZOPYRIDINE' 'DESONIDE' 'GLIPIZIDE'\n",
      " 'GUAIFENESIN/PSEUDOEPHEDRINE' 'MUPIROCIN' 'HYDRALAZINE' 'SALICYLIC ACID'\n",
      " 'AMPICILLIN/SULBACTAM' 'CHOLINE'\n",
      " 'ACETAMINOPHEN/DEXTROMETHORPHAN/GUAIFENESIN/PSEUDOEPHEDRINE' 'CROMOLYN'\n",
      " 'ZONISAMIDE' 'TAMOXIFEN' 'L-GLUTAMINE' 'GUAIFENESIN/CODEINE'\n",
      " 'PRALATREXATE' 'GINGER' 'BOTOX' 'CORTISONE' 'SODIUM FLUORIDE' 'LINDANE'\n",
      " 'ANTI NAUSEA PILL' 'GANIRELIX' 'NABUMETONE' 'NOVACAINE' 'PHENOL'\n",
      " 'BALSALAZIDE' 'DIMENHYDRINATE' 'EPHEDRINE' 'RABEPRAZOLE' 'TORADOL'\n",
      " 'FLAXSEED OIL/OMEGA 3' 'FATTY ACID' 'ETANERCEPT' 'NALBUPHINE' 'SODIUM C1'\n",
      " 'ETHOSUXIMIDE' 'PRAMOXINE/PHENYLEPHRINE/GLYCERIN/PETROLATUM'\n",
      " 'DESMOPRESSIN' 'BETAMETHASONE/CLOTRIMAZOLE' 'OXYMETAZOLINE'\n",
      " 'TRIFLURIDINE' 'SAXAGLIPTIN' 'CLINDAMYCIN/TRETINOIN' 'IMIPRAMINE'\n",
      " 'PHOSPHORUS' 'ACCUPUNTURE' 'ARMODAFINIL' 'BICYCLOVERINE' 'CEFIXIME'\n",
      " 'LACTATED RINGER' 'EUCERIN CREAM' 'CEFADROXIL' 'BRIMONIDINE/TIMOLOL'\n",
      " 'IV FLUIDS' 'NEOMYCIN' 'ACETAMINOPHEN/ASPIRIN/CAFFEINE' 'ENSURE'\n",
      " 'IPRATROPIUM' 'SILVER NITRATE' 'VITAMIN K' 'TERBINAFINE'\n",
      " 'RUBELLA VACCINATION' 'ATORVASTATIN' 'HEPATITIS A/B VACCINE'\n",
      " 'LIDOCAINE/HYDROCORTISONE' 'MELOXICAM' 'TRIAZOLAM' 'VITAMIN B-7'\n",
      " 'PROMETHAZINE/CODEINE' 'TETRAHYDROZOLINE' 'LOTEPREDNOL' 'MEFLOQUINE'\n",
      " 'CALAMINE LOTION' 'TRYPTOPHAN' 'DOXAZOSIN' 'ALBUTEROL/IPRATROPIUM'\n",
      " 'LACTAID' 'MIDODRINE' 'DHEA' 'HYDROCORTISONE/PRAMOXINE' 'TETRACYCLINE'\n",
      " 'ACTAMINOPHEN/OXYCODONE' 'MIFEPRISTONE' 'ACETAMINOPHEN/TRAMADOL'\n",
      " 'VITAMIN B-6/GINGER' 'AZTREONAM' 'INOSITOL' 'CODEINE/GUAIFENESIN'\n",
      " 'LACTASE' 'ADENOSINE' 'CHORATUSSIN/CODEINE' 'CLOTRIMAZOLE/BETAMETHASONE'\n",
      " 'HEROIN' 'TOLNAFTATE' 'KETOTIFEN' 'CHLORPHENIRAMINE' 'CHONDROITIN'\n",
      " 'PINDOLOL' 'AMPHETAMINE' 'GRANISETRON' 'VICKS' 'STEROID INJECTION'\n",
      " 'CHONDROITIN/GLUCOSAMINE' 'NIACIN' 'YELLOW FEVER VACCINE' 'ACETAZOLAMIDE'\n",
      " 'NEUROPLEX' 'IVACAFTOR' 'UREA CREAM' 'FOLIC ACID/VITAMIN B-12'\n",
      " 'CODEINE SYRUP' 'NASAL STEROID SPRAY' 'KETOROLAC' 'VITAMIN B-1'\n",
      " 'FLEET ENEMA' 'BACITRACIN' 'LOPINAVIR' 'SALINE' 'RABIES IG' 'PREVICED'\n",
      " 'POLYETHYLENE GLYCOL/ELECTROLYTES' 'CEFPODOXIME'\n",
      " 'ACETAMINOPHEN/PHENYLEPHRINE/GUAIFENESIN' 'FLUOROMETHOLONE' 'NALTREXONE'\n",
      " 'CHROMIUM' 'ACETAMINOPHEN/PROPOXYPHENE' 'ACETYLCYSTEINE' 'SULINDAC'\n",
      " 'OXYBUTYNIN' 'BENZOCAINE' 'MAGNESIUM/CALCIUM' 'VONWILLEBRANDS FACTOR'\n",
      " 'MENINGOCOCCAL VACCINATION' 'PRAVASTATIN' 'CEFOXITIN'\n",
      " 'METHYLSULFONYLMETHANE' 'CEFOTAXIME' 'HOMOCYSTEINE' 'PIPERACILLIN'\n",
      " 'TIZANIDINE' 'LURASIDONE' 'CALAMINE/DIPHENHYDRINATE' 'PERPHENAZINE'\n",
      " 'BUTOCONZOLE' 'PLATELETS' 'DOMPERIDONE' 'COMBIVIR' 'TRICHLOROCETIC ACID'\n",
      " 'AURALGAN' 'LUBIPROSTONE' 'PRAMIPEXOLE' 'DOXEPIN'\n",
      " 'PRIMABELLA RELIEF BAND' 'IODOQUINOL' 'L-ARGININE' 'CINNAMON'\n",
      " 'NEOMYCIN/POLYMYXIN B/BACITRACIN' 'IBUPROFEN/DIPHENHYDRAMINE' 'CEFACLOR'\n",
      " 'BRIMONIDINE' 'PHENYLEPHRINE' 'SOMATROPIN' 'FLUOCINOLONE' 'COLESEVELAM'\n",
      " 'CAFFEINE' 'HUMAN GROWTH HORMONE' 'AMILORIDE' 'MAGNESIUM/ZINC'\n",
      " 'DEXTROMETHORPHAN' 'RILPIVIRINE' 'PETADOLEX' 'ANTIPYRINE/BENZOCAINE'\n",
      " 'EPINEPHRINE' 'TROLAMINE SALICYLATE' 'MEPERIDINE' 'METAXALONE' 'ZICAM'\n",
      " 'PODOPHYLLOTOXIN' 'RETINOID' 'CEFEPIME' 'IBUPROFEN/HYDROCODONE'\n",
      " 'ZIDOVUDINE' 'POLIO VACCINE' 'CALCITRIOL' 'MIRTAZAPINE' 'FUROSEMIDE'\n",
      " 'CARISOPRODOL' 'PROPOFOL' 'OMEGA 3/DHA' 'LIDOCAINE/PRILOCAINE'\n",
      " 'APREPITAND' 'TESTOSTERONE' 'CIPROFLOXACIN/DEXAMETHASONE'\n",
      " 'ATAVAQUONE/PROGUANIL' 'PROPARACAINE' 'XYLOCAINE' 'ACETIC ACID'\n",
      " 'PHOTOTHERAPY' 'CERAMIDE' 'GLUCOSE' 'DROPERIDOL' 'LINOLEIC ACID'\n",
      " 'EPINASTINE' 'CEFPROZIL' 'LICOID' 'BUPIVACAINE'\n",
      " 'PHENYLEPHRINE/SHARK LIVER OIL' 'SOLIFENACIN' 'OXACILLIN'\n",
      " 'NOREPINEPHRINE' 'ROCURONIUM' 'SUCCINYLCHOLINE' 'CISATRACURIUM'\n",
      " 'NEOSTIGMINE' 'DEXTROSE' 'DORNASE ALFA' 'OLMESARTAN' 'INDIGO CARMINE'\n",
      " 'DRONABINOL' 'MEROPENEM']\n"
     ]
    }
   ],
   "source": [
    "print(drug_union) \n",
    "# note that nan is one of the drug names, so the real drug name number should be 624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6ae07eab-6888-4002-89fe-a75cde70ccf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DrugName_ACETAMINOPHEN</th>\n",
       "      <th>DrugName_ACETAMINOPHEN/BUTALBITAL/CAFFEINE</th>\n",
       "      <th>DrugName_ACETAMINOPHEN/CAFFEINE</th>\n",
       "      <th>DrugName_ACETAMINOPHEN/CODEINE</th>\n",
       "      <th>DrugName_ACETAMINOPHEN/DIPHENHYDRAMINE</th>\n",
       "      <th>DrugName_ACETAMINOPHEN/HYDROCODONE</th>\n",
       "      <th>DrugName_ACETAMINOPHEN/OXYCODONE</th>\n",
       "      <th>DrugName_ACYCLOVIR</th>\n",
       "      <th>DrugName_ADALIMUMAB</th>\n",
       "      <th>DrugName_ADDERALL</th>\n",
       "      <th>...</th>\n",
       "      <th>DrugName_ROCURONIUM</th>\n",
       "      <th>DrugName_SUCCINYLCHOLINE</th>\n",
       "      <th>DrugName_CISATRACURIUM</th>\n",
       "      <th>DrugName_NEOSTIGMINE</th>\n",
       "      <th>DrugName_DEXTROSE</th>\n",
       "      <th>DrugName_DORNASE ALFA</th>\n",
       "      <th>DrugName_OLMESARTAN</th>\n",
       "      <th>DrugName_DRONABINOL</th>\n",
       "      <th>DrugName_INDIGO CARMINE</th>\n",
       "      <th>DrugName_MEROPENEM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9289 rows × 624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DrugName_ACETAMINOPHEN  DrugName_ACETAMINOPHEN/BUTALBITAL/CAFFEINE  \\\n",
       "0                          0                                           0   \n",
       "1                          0                                           0   \n",
       "2                          0                                           0   \n",
       "3                          1                                           0   \n",
       "4                          0                                           0   \n",
       "...                      ...                                         ...   \n",
       "9284                       0                                           0   \n",
       "9285                       0                                           0   \n",
       "9286                       0                                           0   \n",
       "9287                       0                                           0   \n",
       "9288                       0                                           0   \n",
       "\n",
       "      DrugName_ACETAMINOPHEN/CAFFEINE  DrugName_ACETAMINOPHEN/CODEINE  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "...                               ...                             ...   \n",
       "9284                                0                               0   \n",
       "9285                                0                               0   \n",
       "9286                                0                               0   \n",
       "9287                                0                               0   \n",
       "9288                                0                               0   \n",
       "\n",
       "      DrugName_ACETAMINOPHEN/DIPHENHYDRAMINE  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "9284                                       0   \n",
       "9285                                       0   \n",
       "9286                                       0   \n",
       "9287                                       0   \n",
       "9288                                       0   \n",
       "\n",
       "      DrugName_ACETAMINOPHEN/HYDROCODONE  DrugName_ACETAMINOPHEN/OXYCODONE  \\\n",
       "0                                      0                                 0   \n",
       "1                                      1                                 0   \n",
       "2                                      0                                 0   \n",
       "3                                      1                                 0   \n",
       "4                                      0                                 0   \n",
       "...                                  ...                               ...   \n",
       "9284                                   0                                 0   \n",
       "9285                                   0                                 0   \n",
       "9286                                   0                                 0   \n",
       "9287                                   0                                 0   \n",
       "9288                                   0                                 0   \n",
       "\n",
       "      DrugName_ACYCLOVIR  DrugName_ADALIMUMAB  DrugName_ADDERALL  ...  \\\n",
       "0                      0                    0                  0  ...   \n",
       "1                      0                    0                  0  ...   \n",
       "2                      0                    0                  0  ...   \n",
       "3                      0                    0                  0  ...   \n",
       "4                      0                    0                  0  ...   \n",
       "...                  ...                  ...                ...  ...   \n",
       "9284                   0                    0                  0  ...   \n",
       "9285                   0                    0                  0  ...   \n",
       "9286                   0                    0                  0  ...   \n",
       "9287                   0                    0                  0  ...   \n",
       "9288                   0                    0                  0  ...   \n",
       "\n",
       "      DrugName_ROCURONIUM  DrugName_SUCCINYLCHOLINE  DrugName_CISATRACURIUM  \\\n",
       "0                       0                         0                       0   \n",
       "1                       0                         0                       0   \n",
       "2                       0                         0                       0   \n",
       "3                       0                         0                       0   \n",
       "4                       0                         0                       0   \n",
       "...                   ...                       ...                     ...   \n",
       "9284                    0                         0                       0   \n",
       "9285                    0                         0                       0   \n",
       "9286                    0                         0                       0   \n",
       "9287                    0                         0                       0   \n",
       "9288                    0                         0                       0   \n",
       "\n",
       "      DrugName_NEOSTIGMINE  DrugName_DEXTROSE  DrugName_DORNASE ALFA  \\\n",
       "0                        0                  0                      0   \n",
       "1                        0                  0                      0   \n",
       "2                        0                  0                      0   \n",
       "3                        0                  0                      0   \n",
       "4                        0                  0                      0   \n",
       "...                    ...                ...                    ...   \n",
       "9284                     0                  0                      0   \n",
       "9285                     0                  0                      0   \n",
       "9286                     0                  0                      0   \n",
       "9287                     0                  0                      0   \n",
       "9288                     0                  0                      0   \n",
       "\n",
       "      DrugName_OLMESARTAN  DrugName_DRONABINOL  DrugName_INDIGO CARMINE  \\\n",
       "0                       0                    0                        0   \n",
       "1                       0                    0                        0   \n",
       "2                       0                    0                        0   \n",
       "3                       0                    0                        0   \n",
       "4                       0                    0                        0   \n",
       "...                   ...                  ...                      ...   \n",
       "9284                    0                    0                        0   \n",
       "9285                    0                    0                        0   \n",
       "9286                    0                    0                        0   \n",
       "9287                    0                    0                        0   \n",
       "9288                    0                    0                        0   \n",
       "\n",
       "      DrugName_MEROPENEM  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "9284                   0  \n",
       "9285                   0  \n",
       "9286                   0  \n",
       "9287                   0  \n",
       "9288                   0  \n",
       "\n",
       "[9289 rows x 624 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_drug_onehot = pd.get_dummies(a[a.columns[a.columns.str.startswith(\"DrugName\")]], prefix=\"DrugName\").max(axis=1, level=0)\n",
    "a_drug_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "450bbd73-4200-4da5-89f9-22c1f5f8e909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_drug_onehot.mean().plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4ca95053-4ed8-479b-bf61-bdd09eb06ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca on drugs\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "if ncd > 0:\n",
    "    tsvd = TruncatedSVD(n_components=ncd)\n",
    "\n",
    "    a_drug_onehot0 = a_drug_onehot.copy()\n",
    "\n",
    "    a_drug_onehot = tsvd.fit_transform(a_drug_onehot0)\n",
    "    a_drug_onehot = pd.DataFrame(a_drug_onehot, columns = [f'drug_svd{i}' for i in range(ncd)],\n",
    "                                index=a_drug_onehot0.index)\n",
    "    a_drug_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9fc60188-b514-48fe-bce6-5f3a9918bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xlrd\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "39222acc-43a7-4e5e-86aa-f020a2e068a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Dataset Title</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Total # of Columns</th>\n",
       "      <th>Total # of Rows</th>\n",
       "      <th>Corresponding Case Report Form (CRF) Name</th>\n",
       "      <th>CRF Study Timepoint</th>\n",
       "      <th>CRF Section Heading Names</th>\n",
       "      <th>Relevance to Maternal Morbidity (Y/N)</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a02</td>\n",
       "      <td>nuMoM2b Elements of Consent [A02] Dataset</td>\n",
       "      <td>Informed consent; Assent</td>\n",
       "      <td>32</td>\n",
       "      <td>9290</td>\n",
       "      <td>nuMoM2b_A02_Elements of Consent_2010-09-27.pdf</td>\n",
       "      <td>Administrative/Screening</td>\n",
       "      <td>A. Administration of Informed Consent\\nB. Elements of Informed Consent</td>\n",
       "      <td>N</td>\n",
       "      <td>CRF is about whether consent to participant was obtained and level of consent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a03</td>\n",
       "      <td>nuMoM2b Protocol Deviations [A03] Dataset</td>\n",
       "      <td>Protocol deviation</td>\n",
       "      <td>18</td>\n",
       "      <td>301</td>\n",
       "      <td>nuMoM2b_A03_Protocol Deviations_2010-09-27.pdf</td>\n",
       "      <td>Administrative/Overall</td>\n",
       "      <td>A. Details on Deviations(s)</td>\n",
       "      <td>N</td>\n",
       "      <td>CRF is about protocol deviations (e.g., failure to obtain consent, breach of confidentiality)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a04</td>\n",
       "      <td>nuMoM2b Adverse Event [A04] Dataset</td>\n",
       "      <td>Adverse event</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "      <td>nuMoM2b_A04_Adverse Event_2010-09-27.pdf</td>\n",
       "      <td>Administrative/Overall</td>\n",
       "      <td>A. Details on Event</td>\n",
       "      <td>Y</td>\n",
       "      <td>Information such as participant death, suicidal ideation, and other adverse events captured</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>a05</td>\n",
       "      <td>nuMoM2b Study Withdrawal [A05] Dataset</td>\n",
       "      <td>Study withdrawal; Study discontinuation</td>\n",
       "      <td>27</td>\n",
       "      <td>304</td>\n",
       "      <td>nuMoM2b_A05_Study Withdrawal_2010-09-27.pdf</td>\n",
       "      <td>Administrative/Overall</td>\n",
       "      <td>A. Study Withdrawal</td>\n",
       "      <td>Y</td>\n",
       "      <td>Information such as participant unable to continue due to medical condition, death, and other wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>a09</td>\n",
       "      <td>nuMoM2b Brief Report of Pregnancy Outcome [A09] Dataset</td>\n",
       "      <td>Pregnancy outcome; Complications</td>\n",
       "      <td>18</td>\n",
       "      <td>9216</td>\n",
       "      <td>nuMoM2b_A09_Report of Pregnancy Outcome_2012-02-16.pdf</td>\n",
       "      <td>Administrative/Overall</td>\n",
       "      <td>A. Outcome Information</td>\n",
       "      <td>Y</td>\n",
       "      <td>Preterm birth and maternal hypertension indicated</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>v3j</td>\n",
       "      <td>nuMoM2b Brief Pregnancy Experience Scale (PES) Visit 3 [V3J] Dataset</td>\n",
       "      <td>Feelings; Emotions</td>\n",
       "      <td>26</td>\n",
       "      <td>8181</td>\n",
       "      <td>nuMoM2b_V3J_Brief Pregnancy Experience Scale (PES) Visit 3_2010-09-27_redacted.pdf</td>\n",
       "      <td>Visit 3</td>\n",
       "      <td>A. Pregnancy Experience</td>\n",
       "      <td>Y</td>\n",
       "      <td>Information on pregnancy experiences (Note: CRF redacted since proprietary)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>v3k</td>\n",
       "      <td>nuMoM2b Sleep Monitoring Following Visit 3 [V3K] Dataset</td>\n",
       "      <td>Sleep time; Sleep length; Sleep position; Sleep quality</td>\n",
       "      <td>30</td>\n",
       "      <td>2450</td>\n",
       "      <td>nuMoM2b_V3K_Portable Sleep Assessment Questionnaire Visit 3_2011-01-17.pdf</td>\n",
       "      <td>Sleep Disordered Breathing (SDB) Substudy</td>\n",
       "      <td>A. Time Spent Sleeping\\nB. Sleep Quality</td>\n",
       "      <td>Y</td>\n",
       "      <td>Self-assessment of sleep time, quality, and position after using the sleep monitor at home</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>v3l</td>\n",
       "      <td>nuMoM2b Revised Sleep Questionnaire Visit 3 [V3L] Dataset</td>\n",
       "      <td>Sleep habits; Snoring; Sleep issues; Sleep quality; Sleep position</td>\n",
       "      <td>66</td>\n",
       "      <td>7816</td>\n",
       "      <td>nuMoM2b_V3L_Revised Sleep Questionnaire Visit 3_2011-01-17_redacted.pdf</td>\n",
       "      <td>Visit 3</td>\n",
       "      <td>A. General Work and Sleep Patterns\\nB. Sleep Habits\\nC. Sleepiness\\nD. Symptoms of Restless Legs...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Information on sleep quality, issues, and disorders (Note: CRF replaced V3F)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>v4a</td>\n",
       "      <td>nuMoM2b Delivery Maternal Interview [V4A] Dataset</td>\n",
       "      <td>Hospital; Labor; Induction; Cesarean section; Illnesses; Activity restriction; Substance use</td>\n",
       "      <td>137</td>\n",
       "      <td>6662</td>\n",
       "      <td>nuMoM2b_V4A_Maternal_Interview Delivery_2011-12-09.pdf</td>\n",
       "      <td>Delivery Visit</td>\n",
       "      <td>A. Interview Administration\\nB. Verification of Participant Identity\\nC. Medical Provider Inform...</td>\n",
       "      <td>Y</td>\n",
       "      <td>Hospitalization information, delivery details and complications, activity before delivery, and l...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>79</td>\n",
       "      <td>vxx</td>\n",
       "      <td>nuMoM2b Medical Conditions and Medications [VXX] Dataset</td>\n",
       "      <td>Medical conditions; Diagnosis; Chart abstraction; Medications; Vaccinations; Vitamins; Supplements</td>\n",
       "      <td>984</td>\n",
       "      <td>9023</td>\n",
       "      <td>nuMoM2b_VXX_Medical Conditions and Medications_2011-12-09.pdf</td>\n",
       "      <td>Across Visits</td>\n",
       "      <td>A. Administration and Verification\\nB. Medical Conditions / Diagnoses\\nC. Medications</td>\n",
       "      <td>Y</td>\n",
       "      <td>Pre-existing health conditions and medications taken</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    No. Dataset Name  \\\n",
       "0     1          a02   \n",
       "1     2          a03   \n",
       "2     3          a04   \n",
       "3     4          a05   \n",
       "4     5          a09   \n",
       "..  ...          ...   \n",
       "74   75          v3j   \n",
       "75   76          v3k   \n",
       "76   77          v3l   \n",
       "77   78          v4a   \n",
       "78   79          vxx   \n",
       "\n",
       "                                                           Dataset Title  \\\n",
       "0                              nuMoM2b Elements of Consent [A02] Dataset   \n",
       "1                              nuMoM2b Protocol Deviations [A03] Dataset   \n",
       "2                                    nuMoM2b Adverse Event [A04] Dataset   \n",
       "3                                 nuMoM2b Study Withdrawal [A05] Dataset   \n",
       "4                nuMoM2b Brief Report of Pregnancy Outcome [A09] Dataset   \n",
       "..                                                                   ...   \n",
       "74  nuMoM2b Brief Pregnancy Experience Scale (PES) Visit 3 [V3J] Dataset   \n",
       "75              nuMoM2b Sleep Monitoring Following Visit 3 [V3K] Dataset   \n",
       "76             nuMoM2b Revised Sleep Questionnaire Visit 3 [V3L] Dataset   \n",
       "77                     nuMoM2b Delivery Maternal Interview [V4A] Dataset   \n",
       "78              nuMoM2b Medical Conditions and Medications [VXX] Dataset   \n",
       "\n",
       "                                                                                              Keywords  \\\n",
       "0                                                                             Informed consent; Assent   \n",
       "1                                                                                   Protocol deviation   \n",
       "2                                                                                        Adverse event   \n",
       "3                                                              Study withdrawal; Study discontinuation   \n",
       "4                                                                     Pregnancy outcome; Complications   \n",
       "..                                                                                                 ...   \n",
       "74                                                                                  Feelings; Emotions   \n",
       "75                                             Sleep time; Sleep length; Sleep position; Sleep quality   \n",
       "76                                  Sleep habits; Snoring; Sleep issues; Sleep quality; Sleep position   \n",
       "77       Hospital; Labor; Induction; Cesarean section; Illnesses; Activity restriction; Substance use    \n",
       "78  Medical conditions; Diagnosis; Chart abstraction; Medications; Vaccinations; Vitamins; Supplements   \n",
       "\n",
       "    Total # of Columns  Total # of Rows  \\\n",
       "0                   32             9290   \n",
       "1                   18              301   \n",
       "2                   14               72   \n",
       "3                   27              304   \n",
       "4                   18             9216   \n",
       "..                 ...              ...   \n",
       "74                  26             8181   \n",
       "75                  30             2450   \n",
       "76                  66             7816   \n",
       "77                 137             6662   \n",
       "78                 984             9023   \n",
       "\n",
       "                                             Corresponding Case Report Form (CRF) Name  \\\n",
       "0                                       nuMoM2b_A02_Elements of Consent_2010-09-27.pdf   \n",
       "1                                       nuMoM2b_A03_Protocol Deviations_2010-09-27.pdf   \n",
       "2                                             nuMoM2b_A04_Adverse Event_2010-09-27.pdf   \n",
       "3                                          nuMoM2b_A05_Study Withdrawal_2010-09-27.pdf   \n",
       "4                               nuMoM2b_A09_Report of Pregnancy Outcome_2012-02-16.pdf   \n",
       "..                                                                                 ...   \n",
       "74  nuMoM2b_V3J_Brief Pregnancy Experience Scale (PES) Visit 3_2010-09-27_redacted.pdf   \n",
       "75          nuMoM2b_V3K_Portable Sleep Assessment Questionnaire Visit 3_2011-01-17.pdf   \n",
       "76             nuMoM2b_V3L_Revised Sleep Questionnaire Visit 3_2011-01-17_redacted.pdf   \n",
       "77                              nuMoM2b_V4A_Maternal_Interview Delivery_2011-12-09.pdf   \n",
       "78                       nuMoM2b_VXX_Medical Conditions and Medications_2011-12-09.pdf   \n",
       "\n",
       "                          CRF Study Timepoint  \\\n",
       "0                    Administrative/Screening   \n",
       "1                      Administrative/Overall   \n",
       "2                      Administrative/Overall   \n",
       "3                      Administrative/Overall   \n",
       "4                      Administrative/Overall   \n",
       "..                                        ...   \n",
       "74                                    Visit 3   \n",
       "75  Sleep Disordered Breathing (SDB) Substudy   \n",
       "76                                    Visit 3   \n",
       "77                             Delivery Visit   \n",
       "78                              Across Visits   \n",
       "\n",
       "                                                                              CRF Section Heading Names  \\\n",
       "0                                A. Administration of Informed Consent\\nB. Elements of Informed Consent   \n",
       "1                                                                           A. Details on Deviations(s)   \n",
       "2                                                                                   A. Details on Event   \n",
       "3                                                                                   A. Study Withdrawal   \n",
       "4                                                                                A. Outcome Information   \n",
       "..                                                                                                  ...   \n",
       "74                                                                              A. Pregnancy Experience   \n",
       "75                                                             A. Time Spent Sleeping\\nB. Sleep Quality   \n",
       "76  A. General Work and Sleep Patterns\\nB. Sleep Habits\\nC. Sleepiness\\nD. Symptoms of Restless Legs...   \n",
       "77  A. Interview Administration\\nB. Verification of Participant Identity\\nC. Medical Provider Inform...   \n",
       "78                A. Administration and Verification\\nB. Medical Conditions / Diagnoses\\nC. Medications   \n",
       "\n",
       "   Relevance to Maternal Morbidity (Y/N)  \\\n",
       "0                                      N   \n",
       "1                                      N   \n",
       "2                                      Y   \n",
       "3                                      Y   \n",
       "4                                      Y   \n",
       "..                                   ...   \n",
       "74                                     Y   \n",
       "75                                     Y   \n",
       "76                                     Y   \n",
       "77                                     Y   \n",
       "78                                     Y   \n",
       "\n",
       "                                                                                               Comments  \\\n",
       "0                         CRF is about whether consent to participant was obtained and level of consent   \n",
       "1         CRF is about protocol deviations (e.g., failure to obtain consent, breach of confidentiality)   \n",
       "2           Information such as participant death, suicidal ideation, and other adverse events captured   \n",
       "3   Information such as participant unable to continue due to medical condition, death, and other wi...   \n",
       "4                                                     Preterm birth and maternal hypertension indicated   \n",
       "..                                                                                                  ...   \n",
       "74                          Information on pregnancy experiences (Note: CRF redacted since proprietary)   \n",
       "75           Self-assessment of sleep time, quality, and position after using the sleep monitor at home   \n",
       "76                         Information on sleep quality, issues, and disorders (Note: CRF replaced V3F)   \n",
       "77  Hospitalization information, delivery details and complications, activity before delivery, and l...   \n",
       "78                                                 Pre-existing health conditions and medications taken   \n",
       "\n",
       "    Unnamed: 11  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "..          ...  \n",
       "74          NaN  \n",
       "75          NaN  \n",
       "76          NaN  \n",
       "77          NaN  \n",
       "78          NaN  \n",
       "\n",
       "[79 rows x 12 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column groups\n",
    "b = pd.read_excel(path+'nuMoM2b Dataset Information.xlsx', header=2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fe48d648-1dd0-4a57-804f-0edbb4ec2172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Dataset Name</th>\n",
       "      <th>Variable Name</th>\n",
       "      <th>Variable Label</th>\n",
       "      <th>Variable Type</th>\n",
       "      <th>Variable Unit\\n(if Numeric)</th>\n",
       "      <th>Variable Code List\\n(if Coded)</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PublicID</td>\n",
       "      <td>Public nuMoM2b ID</td>\n",
       "      <td>Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a02</td>\n",
       "      <td>A02_Complete</td>\n",
       "      <td>(A02) Data entry status</td>\n",
       "      <td>Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a02</td>\n",
       "      <td>A02_Complete_1</td>\n",
       "      <td>(A02) Data entry status</td>\n",
       "      <td>Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a02</td>\n",
       "      <td>A02_Status</td>\n",
       "      <td>(A02) Validation status</td>\n",
       "      <td>Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a02</td>\n",
       "      <td>A02_Status_1</td>\n",
       "      <td>(A02) Validation status</td>\n",
       "      <td>Character</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11612</th>\n",
       "      <td>vxx</td>\n",
       "      <td>VXXC01j_045</td>\n",
       "      <td>(VXX) Medications and vaccinations (45) - Source: Chart abstraction (checkbox)</td>\n",
       "      <td>Coded</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Checked</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>vxx</td>\n",
       "      <td>VXXC01k_045</td>\n",
       "      <td>(VXX) Medications and vaccinations (45) - Final assessment: Took medication/vaccine (checkbox)</td>\n",
       "      <td>Coded</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Checked</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11614</th>\n",
       "      <td>vxx</td>\n",
       "      <td>VXXC02a</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Weeks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11615</th>\n",
       "      <td>vxx</td>\n",
       "      <td>VXXC02b</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Months</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11616</th>\n",
       "      <td>vxx</td>\n",
       "      <td>VXXC02c</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11617 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Original Dataset Name   Variable Name  \\\n",
       "0                       NaN        PublicID   \n",
       "1                       a02    A02_Complete   \n",
       "2                       a02  A02_Complete_1   \n",
       "3                       a02      A02_Status   \n",
       "4                       a02    A02_Status_1   \n",
       "...                     ...             ...   \n",
       "11612                   vxx     VXXC01j_045   \n",
       "11613                   vxx     VXXC01k_045   \n",
       "11614                   vxx         VXXC02a   \n",
       "11615                   vxx         VXXC02b   \n",
       "11616                   vxx         VXXC02c   \n",
       "\n",
       "                                                                                            Variable Label  \\\n",
       "0                                                                                        Public nuMoM2b ID   \n",
       "1                                                                                  (A02) Data entry status   \n",
       "2                                                                                  (A02) Data entry status   \n",
       "3                                                                                  (A02) Validation status   \n",
       "4                                                                                  (A02) Validation status   \n",
       "...                                                                                                    ...   \n",
       "11612                       (VXX) Medications and vaccinations (45) - Source: Chart abstraction (checkbox)   \n",
       "11613       (VXX) Medications and vaccinations (45) - Final assessment: Took medication/vaccine (checkbox)   \n",
       "11614  (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...   \n",
       "11615  (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...   \n",
       "11616  (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...   \n",
       "\n",
       "      Variable Type Variable Unit\\n(if Numeric)  \\\n",
       "0         Character                         NaN   \n",
       "1         Character                         NaN   \n",
       "2         Character                         NaN   \n",
       "3         Character                         NaN   \n",
       "4         Character                         NaN   \n",
       "...             ...                         ...   \n",
       "11612         Coded                         NaN   \n",
       "11613         Coded                         NaN   \n",
       "11614       Numeric                       Weeks   \n",
       "11615       Numeric                      Months   \n",
       "11616       Numeric                       Years   \n",
       "\n",
       "      Variable Code List\\n(if Coded)  Unnamed: 6  \n",
       "0                                NaN         NaN  \n",
       "1                                NaN         NaN  \n",
       "2                                NaN         NaN  \n",
       "3                                NaN         NaN  \n",
       "4                                NaN         NaN  \n",
       "...                              ...         ...  \n",
       "11612                        Checked         NaN  \n",
       "11613                        Checked         NaN  \n",
       "11614                            NaN         NaN  \n",
       "11615                            NaN         NaN  \n",
       "11616                            NaN         NaN  \n",
       "\n",
       "[11617 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column labels\n",
    "c = pd.read_excel(path+'nuMoM2b_Codebook_NICHD Data Challenge.xlsx', header=1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "adfcd846-d2b9-4a53-91ad-e3c3d6b00812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PublicID</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Public nuMoM2b ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Complete</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Data entry status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Complete_1</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Data entry status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Status</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Validation status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Status_1</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Validation status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC01j_045</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) Medications and vaccinations (45) - Source: Chart abstraction (checkbox)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC01k_045</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) Medications and vaccinations (45) - Final assessment: Took medication/vaccine (checkbox)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC02a</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC02b</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC02c</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11617 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset  \\\n",
       "feature                  \n",
       "PublicID           NaN   \n",
       "A02_Complete       a02   \n",
       "A02_Complete_1     a02   \n",
       "A02_Status         a02   \n",
       "A02_Status_1       a02   \n",
       "...                ...   \n",
       "VXXC01j_045        vxx   \n",
       "VXXC01k_045        vxx   \n",
       "VXXC02a            vxx   \n",
       "VXXC02b            vxx   \n",
       "VXXC02c            vxx   \n",
       "\n",
       "                                                                                                              label  \n",
       "feature                                                                                                              \n",
       "PublicID                                                                                          Public nuMoM2b ID  \n",
       "A02_Complete                                                                                (A02) Data entry status  \n",
       "A02_Complete_1                                                                              (A02) Data entry status  \n",
       "A02_Status                                                                                  (A02) Validation status  \n",
       "A02_Status_1                                                                                (A02) Validation status  \n",
       "...                                                                                                             ...  \n",
       "VXXC01j_045                          (VXX) Medications and vaccinations (45) - Source: Chart abstraction (checkbox)  \n",
       "VXXC01k_045          (VXX) Medications and vaccinations (45) - Final assessment: Took medication/vaccine (checkbox)  \n",
       "VXXC02a         (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...  \n",
       "VXXC02b         (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...  \n",
       "VXXC02c         (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...  \n",
       "\n",
       "[11617 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clab = c[['Original Dataset Name', 'Variable Name','Variable Label']]\n",
    "clab.columns = ['dataset','feature','label']\n",
    "clab = clab.set_index('feature')\n",
    "clab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c9ab073d-dcd4-4632-bad7-02c2168a7a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code List Name</th>\n",
       "      <th>Value</th>\n",
       "      <th>Value Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activity_Code</td>\n",
       "      <td>1</td>\n",
       "      <td>Aerobics Class/Exercise Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Activity_Code</td>\n",
       "      <td>2</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Activity_Code</td>\n",
       "      <td>3</td>\n",
       "      <td>Bowling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Activity_Code</td>\n",
       "      <td>4</td>\n",
       "      <td>Calisthenics/Home or Gym Exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Activity_Code</td>\n",
       "      <td>5</td>\n",
       "      <td>Canoeing/Rowing/Sailing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>Yes_No_v10</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes, temporarily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Yes_No_v10</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>Zygosity</td>\n",
       "      <td>1</td>\n",
       "      <td>Present heterozygote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>Zygosity</td>\n",
       "      <td>2</td>\n",
       "      <td>Present homozygote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>Zygosity</td>\n",
       "      <td>3</td>\n",
       "      <td>Absent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1545 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Code List Name Value                        Value Label\n",
       "0     Activity_Code     1   Aerobics Class/Exercise Machines\n",
       "1     Activity_Code     2                         Basketball\n",
       "2     Activity_Code     3                            Bowling\n",
       "3     Activity_Code     4  Calisthenics/Home or Gym Exercise\n",
       "4     Activity_Code     5            Canoeing/Rowing/Sailing\n",
       "...             ...   ...                                ...\n",
       "1540     Yes_No_v10     2                   Yes, temporarily\n",
       "1541     Yes_No_v10     3                                 No\n",
       "1542       Zygosity     1               Present heterozygote\n",
       "1543       Zygosity     2                 Present homozygote\n",
       "1544       Zygosity     3                             Absent\n",
       "\n",
       "[1545 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column codes\n",
    "c1 = pd.read_excel(path+'nuMoM2b_Codebook_NICHD Data Challenge.xlsx', sheet_name=1)\n",
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c7c69cdd-8952-4a79-8b16-e191b1abf6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (a02, [A02_Complete, A02_Complete_1, A02_Status, A02_Status_1, A02Ver, A02Ver_1, A02DATE_INT, A0...\n",
       "1     (a03, [A03_FormNumber, A03_FormNumber_1, A03_FormNumber_2, A03_Complete, A03_Complete_1, A03_Com...\n",
       "2     (a04, [A04_FormNumber, A04_FormNumber_1, A04_Complete, A04_Complete_1, A04_Status, A04_Status_1,...\n",
       "3     (a05, [A05_Complete, A05_Status, A05Ver, A05DATE_INT, A05A01_INT, A05A02a, A05A02b, A05A02c, A05...\n",
       "4     (a09, [A09_Complete, A09_Status, A09Ver, A09DATE_INT, A09A01_Check, A09A01_INT, A09A02, A09A03a,...\n",
       "                                                     ...                                                 \n",
       "74    (v3j, [V3J_Complete, V3J_Status, V3JVer, V3JDATE_INT, V3JA01a, V3JA01b, V3JA01c, V3JA01d, V3JA01...\n",
       "75    (v3k, [V3K_Complete, V3K_Status, V3KVer, V3KDATE_INT, V3KA01_HR, V3KA01_MIN, V3KA01_AMPM, V3KA02...\n",
       "76    (v3l, [V3L_Complete, V3L_Status, V3LVer, V3LDATE_INT, V3LA01, V3LA01a, V3LA01b, V3LA02a, V3LA02b...\n",
       "77    (v4a, [V4A_Complete, V4A_Status, V4AVer, V4ADATE_INT, V4AA01, V4AA01_SP, V4AA02, V4AB01_INT, V4A...\n",
       "78    (vxx, [VXX_Complete, VXX_Status, VXXVer, VXXDATE_INT, VXXA01V1, VXXA01AV1_INT, VXXA01V2, VXXA01A...\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature sets\n",
    "s = pd.Series(c.groupby('Original Dataset Name')['Variable Name'], dtype=object)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2a7ed008-11c9-4f37-b17d-e2ec8cfdc108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['a02', 'a03', 'a04', 'a05', 'a09', 'a10', 'a11', 'a12', 'a13', 'a14', 'a15', 'a33', 'a34', 'a35', 'af1', 'af2', 'af3', 'af4', 'af5', 'af6', 'af7', 'cba', 'cbb', 'cbc', 'cla', 'clb', 'cma', 'cmb', 'cmc', 'cmd', 'cme', 'cpa', 'cua', 'cub', 'demographics', 'drugs_in_pregnancy', 'e2c', 'food_frequency_analysis', 'physical_activity', 'placental_analytes', 'pregnancy_outcomes', 's01', 's02', 'sample_selection', 'sleep_actigraphy', 'sleep_actigraphy_modified', 'sleep_disordered_breathing', 'u02', 'u1c', 'u2a', 'u2b', 'u2c', 'u3a', 'u3b', 'u3c', 'u3d', 'v1a', 'v1b', 'v1c', 'v1e', 'v1f', 'v1g', 'v1h', 'v1k', 'v1l', 'v2a', 'v2b', 'v2i', 'v2m', 'v3a', 'v3b', 'v3c', 'v3e', 'v3f', 'v3j', 'v3k', 'v3l', 'v4a', 'vxx'])\n",
      "\n",
      "['A09_Complete', 'A09_Status', 'A09Ver', 'A09DATE_INT', 'A09A01_Check', 'A09A01_INT', 'A09A02', 'A09A03a', 'A09A03a1', 'A09A03a1_sp', 'A09A03a1a', 'A09A03a1b', 'A09A03b', 'A09A03b1', 'A09A03b2', 'A09A03b3']\n"
     ]
    }
   ],
   "source": [
    "# feature set dictionary\n",
    "fd = {}\n",
    "for k,v in s:\n",
    "    fd[k] = list(v.values)\n",
    "print(fd.keys())\n",
    "print()\n",
    "print(fd['a09'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "314dae81-ed6c-4538-a138-d897f7c400cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature sets to use, limit to information available on or before visit 1\n",
    "fs = ['cla','demographics','s01','s02','u02','u1c','v1a', 'v1b', 'v1c', 'v1e', 'v1f', 'v1g', 'v1h', 'v1k', 'v1l']\n",
    "# fs = ['cla','demographics','v1b']\n",
    "# fs = ['cla','demographics','u02','v1b','v1l']\n",
    "# fs = ['cla','demographics','s01','s02','u02','v1b','v1l']\n",
    "# fs = ['cla','demographics','u02','v1b','v1l','v1g']\n",
    "# fs = ['cla','demographics','s01','u02','v1b','v1l']\n",
    "fs = fs + ['v2a', 'v2b', 'v2i', 'v2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8a9732c-bb06-44ae-b81d-6a8de8d9d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb4db38c-3fb0-4c7d-b048-b5676d9cd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing from data but in feature set\n",
    "nlist = ['V1AF08_D', 'V2AF06_D', 'V2AF09_D', 'V2AF19_D', 'V2AF23_D', 'V2AF26_D']\n",
    "for n in nlist: a[n] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "79849006-c520-4d66-b941-1bb2cb865672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cla\n",
      "demographics\n",
      "s01\n",
      "s02\n",
      "u02\n",
      "u1c\n",
      "v1a\n",
      "v1b\n",
      "v1c\n",
      "v1e\n",
      "v1f\n",
      "v1g\n",
      "v1h\n",
      "v1k\n",
      "v1l\n",
      "v2a\n",
      "v2b\n",
      "v2i\n",
      "v2m\n"
     ]
    }
   ],
   "source": [
    "# coerce to numeric\n",
    "for s in fs:\n",
    "    print(s)\n",
    "    a.loc[:,fd[s]] = a.loc[:,fd[s]].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7040b123-afd5-4d2b-8c0e-dc0b5d969a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9014.000000\n",
       "mean       83.087022\n",
       "std        13.377050\n",
       "min        29.600000\n",
       "25%        74.000000\n",
       "50%        80.000000\n",
       "75%        89.500000\n",
       "max       157.000000\n",
       "Name: V1BA03a, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.V1BA03a.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "90aff7b1-3cf4-4784-9adc-c505c19d3782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11726\n"
     ]
    }
   ],
   "source": [
    "# feature engineering\n",
    "nc = a.shape[1]\n",
    "print(nc)\n",
    "a['Height_mean'] = a[['V1BA02a','V1BA02b','V1BA02c']].mean(axis=1)\n",
    "a['Waist_mean'] = a[['V1BA03a','V1BA03b','V1BA03c']].mean(axis=1)\n",
    "a['Waist_iliac_mean'] = a[['V1BA04a','V1BA04b','V1BA04c']].mean(axis=1)\n",
    "a['Hip_mean'] = a[['V1BA05a','V1BA05b','V1BA05c']].mean(axis=1)\n",
    "a['BP_Sys_mean'] = a[['V1BA06a1','V1BA06b1']].mean(axis=1)\n",
    "a['BP_Dia_mean'] = a[['V1BA06b1','V1BA06b2']].mean(axis=1)\n",
    "a['Neck_mean'] = a[['V1BA07a','V1BA07b','V1BA07c']].mean(axis=1)\n",
    "\n",
    "a['Height_std'] = a[['V1BA02a','V1BA02b','V1BA02c']].std(axis=1)\n",
    "a['Waist_std'] = a[['V1BA03a','V1BA03b','V1BA03c']].std(axis=1)\n",
    "a['Waist_iliac_std'] = a[['V1BA04a','V1BA04b','V1BA04c']].std(axis=1)\n",
    "a['Hip_std'] = a[['V1BA05a','V1BA05b','V1BA05c']].std(axis=1)\n",
    "a['BP_Sys_std'] = a[['V1BA06a1','V1BA06b1']].std(axis=1)\n",
    "a['BP_Dia_std'] = a[['V1BA06b1','V1BA06b2']].std(axis=1)\n",
    "a['Neck_std'] = a[['V1BA07a','V1BA07b','V1BA07c']].std(axis=1)\n",
    "\n",
    "a['Height_max'] = a[['V1BA02a','V1BA02b','V1BA02c']].max(axis=1)\n",
    "a['Waist_max'] = a[['V1BA03a','V1BA03b','V1BA03c']].max(axis=1)\n",
    "a['Waist_iliac_max'] = a[['V1BA04a','V1BA04b','V1BA04c']].max(axis=1)\n",
    "a['Hip_max'] = a[['V1BA05a','V1BA05b','V1BA05c']].max(axis=1)\n",
    "a['BP_Sys_max'] = a[['V1BA06a1','V1BA06b1']].max(axis=1)\n",
    "a['BP_Dia_max'] = a[['V1BA06b1','V1BA06b2']].max(axis=1)\n",
    "a['Neck_max'] = a[['V1BA07a','V1BA07b','V1BA07c']].max(axis=1)\n",
    "\n",
    "\n",
    "drop = ['V1BA02a','V1BA02b','V1BA02c'] + ['V1BA03a','V1BA03b','V1BA03c'] + \\\n",
    "       ['V1BA04a','V1BA04b','V1BA04c'] +['V1BA05a','V1BA05b','V1BA05c'] + \\\n",
    "       ['V1BA06a1','V1BA06b1'] + ['V1BA06b1','V1BA06b2'] + ['V1BA07a','V1BA07b','V1BA07c']\n",
    "\n",
    "# a['BP_Diff1'] = a.V1BA06a1 - a.V1BA06b1\n",
    "# a['BP_Ratio1'] = a.V1BA06a1 / a.V1BA06b1\n",
    "# a['WH_Ratio1'] = a.V1BA01_LB / a.V1BA02a\n",
    "# a['WW_Ratio1'] = a.V1BA01_LB / a.V1BA03a\n",
    "# a['WI_Ratio1'] = a.V1BA01_LB / a.V1BA04a\n",
    "# a['WP_Ratio1'] = a.V1BA01_LB / a.V1BA05a\n",
    "# a['WN_Ratio1'] = a.V1BA01_LB / a.V1BA07a\n",
    "# a['BMIS_Ratio1'] = a.BMI / a.V1BA06a1\n",
    "# a['BMID_Ratio1'] = a.BMI / a.V1BA06b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0d08cb92-04d2-487a-94e2-f5b36c94778b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.BP_Sys_mean.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "44e5f9e5-d6b6-48d0-a714-70a88e6ae200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.BP_Sys_max.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d0a082d-8a77-4a19-bb23-5e801320cac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9087.000000\n",
       "mean       88.109222\n",
       "std         8.573187\n",
       "min        54.000000\n",
       "25%        82.000000\n",
       "50%        87.500000\n",
       "75%        94.000000\n",
       "max       130.000000\n",
       "Name: BP_Sys_mean, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.BP_Sys_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a5e0ff9d-36e0-4b31-9f43-e00d40203fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9087.000000\n",
       "mean      109.210631\n",
       "std        10.938519\n",
       "min        66.000000\n",
       "25%       100.000000\n",
       "50%       110.000000\n",
       "75%       118.000000\n",
       "max       168.000000\n",
       "Name: BP_Sys_max, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.BP_Sys_max.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "20b6a485-5b7d-4058-907f-f8bfbe728620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9087.000000\n",
       "mean       66.980907\n",
       "std         8.283447\n",
       "min        30.000000\n",
       "25%        60.000000\n",
       "50%        68.000000\n",
       "75%        72.000000\n",
       "max       101.000000\n",
       "Name: BP_Dia_mean, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.BP_Dia_mean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf4c0222-be50-4d16-b871-df5a8db4cdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9087.000000\n",
       "mean       29.841898\n",
       "std         6.530458\n",
       "min         0.000000\n",
       "25%        25.455844\n",
       "50%        29.698485\n",
       "75%        33.941125\n",
       "max        73.539105\n",
       "Name: BP_Sys_std, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.BP_Sys_std.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "996ddb24-7235-45b1-b624-d36ab7d5dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Height_mean', 'Waist_mean', 'Waist_iliac_mean', 'Hip_mean',\n",
       "       'BP_Sys_mean', 'BP_Dia_mean', 'Neck_mean', 'Height_std', 'Waist_std',\n",
       "       'Waist_iliac_std', 'Hip_std', 'BP_Sys_std', 'BP_Dia_std', 'Neck_std',\n",
       "       'Height_max', 'Waist_max', 'Waist_iliac_max', 'Hip_max', 'BP_Sys_max',\n",
       "       'BP_Dia_max', 'Neck_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new feature set with engineered features\n",
    "ef = a.columns[nc:]\n",
    "ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "957eb9e3-a0ef-4204-a6b7-e3c6a26d8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd['eng'] = ef\n",
    "fs = fs + ['eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0e59fe57-dffd-4c64-bf46-c9dae77b4c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.V1AE2_04c_4.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c87560fb-34cc-4cf2-92d5-a948e76d80d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9289, 11747)\n",
      "(9289, 4271)\n"
     ]
    }
   ],
   "source": [
    "# drop columns with high percentage of missing values\n",
    "print(a.shape)\n",
    "pthresh = 0.2\n",
    "a = a.dropna(axis=1, thresh=int(pthresh*len(a)))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fd6f3a5b-de70-4921-9652-43ff47272a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join one-hots\n",
    "fd['food'] = list(a_food_onehot.columns)\n",
    "fd['drug'] = list(a_drug_onehot.columns)\n",
    "# fs = fs + ['food','drug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "70eb33dc-51a7-4265-92bc-ba36f204f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adrop = [c for c in a.columns if (c in fd['food']) or c.startswith('DrugName')]\n",
    "# print(a.shape, len(adrop))\n",
    "# a = a.drop(columns=adrop)\n",
    "# print(a.shape)\n",
    "# a = pd.concat([a, a_food_onehot, a_drug_onehot], axis=1)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3d9808fa-468b-459b-8187-5f63dc692c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PublicID</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Public nuMoM2b ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Complete</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Data entry status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Complete_1</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Data entry status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Status</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Validation status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A02_Status_1</th>\n",
       "      <td>a02</td>\n",
       "      <td>(A02) Validation status</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC01j_045</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) Medications and vaccinations (45) - Source: Chart abstraction (checkbox)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC01k_045</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) Medications and vaccinations (45) - Final assessment: Took medication/vaccine (checkbox)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC02a</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC02b</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VXXC02c</th>\n",
       "      <td>vxx</td>\n",
       "      <td>(VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11617 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset  \\\n",
       "feature                  \n",
       "PublicID           NaN   \n",
       "A02_Complete       a02   \n",
       "A02_Complete_1     a02   \n",
       "A02_Status         a02   \n",
       "A02_Status_1       a02   \n",
       "...                ...   \n",
       "VXXC01j_045        vxx   \n",
       "VXXC01k_045        vxx   \n",
       "VXXC02a            vxx   \n",
       "VXXC02b            vxx   \n",
       "VXXC02c            vxx   \n",
       "\n",
       "                                                                                                              label  \n",
       "feature                                                                                                              \n",
       "PublicID                                                                                          Public nuMoM2b ID  \n",
       "A02_Complete                                                                                (A02) Data entry status  \n",
       "A02_Complete_1                                                                              (A02) Data entry status  \n",
       "A02_Status                                                                                  (A02) Validation status  \n",
       "A02_Status_1                                                                                (A02) Validation status  \n",
       "...                                                                                                             ...  \n",
       "VXXC01j_045                          (VXX) Medications and vaccinations (45) - Source: Chart abstraction (checkbox)  \n",
       "VXXC01k_045          (VXX) Medications and vaccinations (45) - Final assessment: Took medication/vaccine (checkbox)  \n",
       "VXXC02a         (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...  \n",
       "VXXC02b         (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...  \n",
       "VXXC02c         (VXX) How long have you been taking [perinatal vitamins/other multivitamins/ folate supplements]...  \n",
       "\n",
       "[11617 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flab = pd.DataFrame({'feature':fd['food'],'dataset':'food','label':fd['food']}).set_index('feature')\n",
    "# dlab = pd.DataFrame({'feature':fd['drug'],'dataset':'drug','label':fd['drug']}).set_index('feature')\n",
    "# clab = pd.concat([clab,flab,dlab])\n",
    "clab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bdaa9489-bb81-4050-85d3-231f63c9f3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['CLAVer',\n",
       "  'CLAA01a',\n",
       "  'CLAA01b',\n",
       "  'CLAA01c',\n",
       "  'CLAA01d',\n",
       "  'CLAA02',\n",
       "  'CLAA03',\n",
       "  'CLAA04',\n",
       "  'CLAA05',\n",
       "  'CLAA06'],\n",
       " ['Hip_std',\n",
       "  'BP_Sys_std',\n",
       "  'Neck_std',\n",
       "  'Height_max',\n",
       "  'Waist_max',\n",
       "  'Waist_iliac_max',\n",
       "  'Hip_max',\n",
       "  'BP_Sys_max',\n",
       "  'BP_Dia_max',\n",
       "  'Neck_max'],\n",
       " 654)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assemble features\n",
    "features = []\n",
    "for s in fs: features.extend(fd[s])\n",
    "# restrict to numeric features, remove _INT dates\n",
    "features = [f for f in features if ((f in a.columns) and (a[f].dtype != 'O') and (f[-4:]!='_INT')) and \\\n",
    "           (f not in drop)]\n",
    "\n",
    "# drop second and third trimester features\n",
    "features = [f for f in features if f[:4] not in ['CLAC','CLAD']]\n",
    "\n",
    "features[:10], features[-10:], len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6ec1cd0a-b08b-4723-b84f-37223fced13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standardize features\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# d.loc[:,features] = scaler.fit_transform(d[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "72a65316-eabf-4e34-b80d-b4a4a67021c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed data\n",
    "# cols = ['PublicID',target] + features\n",
    "# fname = mname + '.csv'\n",
    "# a[cols].to_csv(fname, index=False)\n",
    "# print(fname, a[cols].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e9a23782-ac4e-4950-8840-40b7d619fa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9289, 654) (9289,)\n"
     ]
    }
   ],
   "source": [
    "# training and test data\n",
    "x = a[features]\n",
    "y = a[target]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fc480ce2-aa86-4f90-8f2f-66301a2a16b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLAVer               3.933423\n",
       "CLAA01a             12.921480\n",
       "CLAA01b             38.040291\n",
       "CLAA01c             89.458561\n",
       "CLAA01d            253.540454\n",
       "                      ...    \n",
       "Waist_iliac_max     95.056257\n",
       "Hip_max            104.342963\n",
       "BP_Sys_max         109.210631\n",
       "BP_Dia_max          67.025421\n",
       "Neck_max            32.956357\n",
       "Length: 654, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2ebf8b63-dd76-4ad4-8637-d2ca2ba2ec0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-155.5571493547903"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8bd88f9f-4d34-474a-989e-0d60269c5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make colorful output ###\n",
    "from colorama import Fore\n",
    "c_ = Fore.CYAN\n",
    "m_ = Fore.MAGENTA\n",
    "r_ = Fore.RED\n",
    "b_ = Fore.BLUE\n",
    "y_ = Fore.YELLOW\n",
    "g_ = Fore.GREEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "80c0278d-73af-4b67-a03d-50ae71d0c389",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path+'mod', exist_ok=True)\n",
    "os.makedirs(path+'oof', exist_ok=True)\n",
    "os.makedirs(path+'imp', exist_ok=True)\n",
    "os.makedirs(path+'sub', exist_ok=True)\n",
    "os.makedirs(path+'cvr', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4580d6aa-a3ad-4dd2-8e4c-1edd521f2357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm --upgrade\n",
    "# !pip install xgboost --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e1d430b0-761b-4391-ad88-8aca34143c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a867767e-9fa2-4f5f-8aff-573cf3f6ed50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8886.000000\n",
       "mean     -155.557149\n",
       "std       219.958845\n",
       "min      -304.000000\n",
       "25%      -282.000000\n",
       "50%      -274.000000\n",
       "75%      -234.000000\n",
       "max       316.055556\n",
       "Name: tthd, dtype: float64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6be9390e-9f06-421a-ae61-dd6e59a6c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harrell's C concordance index, AUC for survival, sorting efficiency\n",
    "# https://github.com/jameslu01/Compute_HazRatio_ML/blob/main/XGB_Code_Data/Breast%20Cancer/BreastCancer_Dataset_HR_Estimations_Manuscript_Mean.ipynb\n",
    "def c_statistic_harrell(labels, pred):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for i in range(len(labels)):\n",
    "        for j in range(len(labels)):\n",
    "            if int(labels[j]) > 0 and abs(int(labels[i])) > int(labels[j]):\n",
    "                total += 1\n",
    "                if pred[j] > pred[i]:\n",
    "                    matches += 1\n",
    "    return matches/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0efe6945-594c-44a3-9c09-fcc533b75e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "c_scorer = make_scorer(c_statistic_harrell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "82f8e69f-1851-4e67-b3c7-74e6ecb3531a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d6396a8d-9d87-471d-9ede-4c1490a08cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n"
     ]
    }
   ],
   "source": [
    "features0 = features\n",
    "nf = len(features0)\n",
    "print(nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cd16b6a4-2a86-47a5-9bfe-cfee02067a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "N_SPLITS = 7\n",
    "N_REPEATS = 7\n",
    "N_TRIES = 7\n",
    "seed = 312\n",
    "folds = []\n",
    "for i in range(N_REPEATS):\n",
    "    folds.extend(list(StratifiedKFold(n_splits=N_SPLITS, random_state=i+seed, shuffle=True).split(x, (y > 0))))\n",
    "print(len(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9b4468cf-7944-47c4-b9b2-5a16720c4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation\n",
    "# %%time\n",
    "def fitModel(folds, x, y, model, params, n_iter, scoring, cv, verbose = 0):\n",
    "    global BOUND\n",
    "    scores = []; y_preds = []; test_preds = []; models = []\n",
    "    start = time.time()\n",
    "    \n",
    "    for fold_idx, fold in enumerate(folds[:N_REPEATS * N_SPLITS]):\n",
    "        \n",
    "        foldi = fold_idx // N_SPLITS\n",
    "        foldj = fold_idx % N_SPLITS\n",
    "\n",
    "        # print()\n",
    "        # print(\"Fold\", foldi, foldj)\n",
    "         \n",
    "        BOUND = random.random() * 0.7 + 0.3\n",
    "        clf = RandomizedSearchCV(model, params, n_iter = n_iter,\n",
    "            scoring = scoring, n_jobs = -1,\n",
    "            cv = cv\n",
    "        )\n",
    "        xr = x.iloc[fold[0]].copy()\n",
    "        # for col in random.sample(list(x.columns), k = int(0.05 * len(x.columns))):\n",
    "        # xr[col] = 0\n",
    "\n",
    "        # for col in [c for c in x.columns if 'DrugTest' in c][:5]:\n",
    "        # xr[col] *= np.exp(np.random.normal(0, 0.1, len(xr)))\\\n",
    "\n",
    "\n",
    "        clf.fit(xr, y.iloc[fold[0]])\n",
    "        # display(pd.DataFrame(clf.cv_results_).sort_values('rank_test_score'))\n",
    "\n",
    "        model = clf.best_estimator_\n",
    "        models.append(model)\n",
    "        \n",
    "        # requires python 3.8, walrus operator\n",
    "        # models.append(model := clf.best_estimator_)\n",
    "        \n",
    "        # y_pred = ( (clf.predict_proba if hasattr(clf, 'predict_proba') else clf.predict)\n",
    "        #     (x.iloc[fold[1]]) )\n",
    "        y_pred = ( (model.predict_proba if hasattr(model, 'predict_proba') else model.predict)\n",
    "            (x.iloc[fold[1]]) )\n",
    "\n",
    "        y_pred = y_pred[:, -1] if len(y_pred.shape) == 2 else y_pred\n",
    "\n",
    "        score = mean_squared_error(y.iloc[fold[1]], ( y_pred ) )\n",
    "        scores.append( score )\n",
    "\n",
    "        # requires python 3.8, walrus operator\n",
    "        # scores.append( score := mean_squared_error(y.iloc[fold[1]], ( y_pred ) ) )\n",
    "\n",
    "        y_preds.append( pd.Series(y_pred, index = x.iloc[fold[1]].index ) )\n",
    "        # print('{:.4f}'.format(score))\n",
    "        # break\n",
    "\n",
    "        if (fold_idx + 1) % N_SPLITS == 0:\n",
    "            print(c_)\n",
    "            print('Running average after {} repeats: {:.4f}'.format( fold_idx // N_SPLITS + 1, np.mean(scores)) )\n",
    "            yp = pd.concat(y_preds)\n",
    "            yp = yp.groupby(yp.index).mean()\n",
    "            print('Blended average after {} repeats: {:.4f}'.format( fold_idx // N_SPLITS + 1,\n",
    "                mean_squared_error( yp.reindex(y.index), y ) ) )\n",
    "            print('{:.1f}s'.format(time.time() - start))\n",
    "            print(c_)\n",
    "\n",
    "            if verbose >= 3:\n",
    "                # print(models[-5:])\n",
    "                print(models[-1])\n",
    "           \n",
    "        # test preds\n",
    "        if len(x_test):\n",
    "            test_pred = ( (model.predict_proba if hasattr(model, 'predict_proba') else model.predict)\n",
    "                (x_test))\n",
    "            test_pred = test_pred[:, -1] if len(test_pred.shape) == 2 else test_pred       \n",
    "            # preds_test = model.predict(x_test)\n",
    "            # preds_test = model.predict_proba(x_test)[:,-1]\n",
    "            test_preds.append(test_pred)\n",
    "\n",
    "    # save oofs\n",
    "    yp = pd.concat(y_preds)\n",
    "    yp = yp.groupby(yp.index).mean()\n",
    "    # fname = f'oof/{mname}.pkl'\n",
    "    # yp.to_pickle(fname)\n",
    "    # print(fname, yp.shape)\n",
    "    \n",
    "    # save test set predictions\n",
    "    if len(x_test):\n",
    "        tp = np.stack(test_preds)\n",
    "        tps = len(tp.shape)\n",
    "        if tps==2:\n",
    "            tp = np.mean(tp,axis=0)\n",
    "        else:\n",
    "            tp = np.mean(tp,axis=(0,2))\n",
    "        # fname = f'sub/{mname}.npy'\n",
    "        # np.save(fname, tp)\n",
    "        # print(fname, tp.shape)\n",
    "    else:\n",
    "        tp = None\n",
    "    \n",
    "    return models, scores, yp, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9fc0fd32-b813-4001-9fcb-ca538a818088",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'n_estimators': [ 50, 100, 150, 225, 350 ],  \n",
    "    'min_split_gain': [0, 0, 1e-4, 1e-3, 1e-2, 0.1],\n",
    "    'min_child_samples': [ 1, 2, 4, 7, 10, 20, 30, 40, 70, 100],\n",
    "    'min_child_weight': [0],\n",
    "    'num_leaves': [  20, 30, 50, 100],\n",
    "    'learning_rate': [0.05, 0.07, 0.1],         \n",
    "    'colsample_bytree': [0.33, 0.5, 0.65, 0.8, 0.9, 1.0], \n",
    "    'colsample_bynode':[0.33, 0.5, 0.65, 0.81, 0.9, 1.0],\n",
    "    'reg_lambda': [0, 1e-5, 1e-4, 1e-3, 1e-2, 0.1, 1, 10, 100 ],\n",
    "    'reg_alpha': [0, 1e-3, 1e-2, 0.1, 1, 10], \n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'subsample_freq': [1],\n",
    "    # 'max_bin': [50, 90, 125, 175, 255],\n",
    "}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "750b38cb-f3f6-41b9-a8e3-c7e1adf17035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models, scores, y_preds, test_preds = fitModel(x, y, \n",
    "#     lgb.LGBMRegressor(), params, 20,\n",
    "#     'neg_mean_squared_error', StratifiedKFold(n_splits = 5, shuffle = True), verbose = 5)\n",
    "\n",
    "# models, scores, y_preds, test_preds = fitModel(x, y,\n",
    "#     lgb.LGBMClassifier(), params, 10,\n",
    "#     'neg_brier_score', StratifiedKFold(n_splits = 5, shuffle = True), verbose = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dde11e53-732d-4189-88bf-07c822235380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fb5c8b71-404d-4dac-9d11-013d08606650",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\n",
    "    'PublicID', \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "63f2b32c-bd11-4ee1-a897-d23bea3f5d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "581/654 V2AH02b 46 0.427\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(5319, 4271) (3970, 4271)\n",
      "(5319, 653) (5319,) (3970, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 88.5020\n",
      "Blended average after 1 repeats: 88.4902\n",
      "46.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, max_depth=6,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=100, reg_alpha=0, reg_lambda=0.1, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 89.3227\n",
      "Blended average after 2 repeats: 87.2648\n",
      "86.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=50, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 89.3645\n",
      "Blended average after 3 repeats: 86.5477\n",
      "125.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=50, num_leaves=20, reg_alpha=0.01,\n",
      "              reg_lambda=0.0001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 90.2445\n",
      "Blended average after 4 repeats: 87.0718\n",
      "173.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=0.01, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 90.2184\n",
      "Blended average after 5 repeats: 86.6630\n",
      "219.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=0.001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 90.4297\n",
      "Blended average after 6 repeats: 86.8078\n",
      "262.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=0.01, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 90.1594\n",
      "Blended average after 7 repeats: 86.2912\n",
      "303.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                     gain\n",
      "feature                  \n",
      "V1AG07b        104.448980\n",
      "V2AH02c         91.775510\n",
      "V1AG05b         81.897959\n",
      "V2AH02          30.918367\n",
      "V1AG05c         25.163265\n",
      "PctFedPoverty   24.244898\n",
      "V1AG07c         23.530612\n",
      "CLAA01c         21.020408\n",
      "Height_std      20.612245\n",
      "CLAE02a1        20.448980\n",
      "          gain\n",
      "feature       \n",
      "V1AF15b    0.0\n",
      "V1LE10     0.0\n",
      "V1AF12i    0.0\n",
      "V2AF25h    0.0\n",
      "V1AF12h    0.0\n",
      "V2AF25d    0.0\n",
      "V1LVer     0.0\n",
      "CLAE06c2   0.0\n",
      "V2AA01     0.0\n",
      "V2AF01f    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred\n",
      "0      00001U            2.348026\n",
      "1      00004O            1.474683\n",
      "2      00007I           24.095593\n",
      "3      00008G           -0.172039\n",
      "4      00015J            0.100838\n",
      "...       ...                 ...\n",
      "9284   17349I            0.866327\n",
      "9285   17350A            0.450175\n",
      "9286   17351V           -0.153617\n",
      "9287   17352T            0.851284\n",
      "9288   17354P            1.434162\n",
      "\n",
      "[9289 rows x 2 columns]\n",
      "lgb2d.csv (9289, 2)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "582/654 V2AH02c 8 0.426\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(5329, 4271) (3960, 4271)\n",
      "(5329, 653) (5329,) (3960, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.1891\n",
      "Blended average after 1 repeats: 0.1891\n",
      "48.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=1, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.1885\n",
      "Blended average after 2 repeats: 0.1855\n",
      "90.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0.0001, n_estimators=225,\n",
      "              num_leaves=50, reg_alpha=0.01, reg_lambda=10, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1888\n",
      "Blended average after 3 repeats: 0.1847\n",
      "135.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=1e-05, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1884\n",
      "Blended average after 4 repeats: 0.1838\n",
      "183.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1879\n",
      "Blended average after 5 repeats: 0.1830\n",
      "230.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=50, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1876\n",
      "Blended average after 6 repeats: 0.1825\n",
      "277.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=5,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=50, reg_alpha=0, reg_lambda=0.1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1874\n",
      "Blended average after 7 repeats: 0.1822\n",
      "324.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.05, max_depth=2,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=10, reg_lambda=0.0001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                     gain\n",
      "feature                  \n",
      "V2AH02b        133.285714\n",
      "V1AG07c         52.979592\n",
      "V1AG05b         47.795918\n",
      "V1AG07b         47.224490\n",
      "V1AG05c         46.591837\n",
      "PctFedPoverty   39.877551\n",
      "CLAA01c         20.551020\n",
      "V1AF13          15.693878\n",
      "V2AF13          15.571429\n",
      "V1AF14          15.142857\n",
      "         gain\n",
      "feature      \n",
      "S01Ver    0.0\n",
      "V2AF08d   0.0\n",
      "V1AF15b   0.0\n",
      "V2AF05h   0.0\n",
      "V2AF05g   0.0\n",
      "V2AF05d   0.0\n",
      "V2AF01f   0.0\n",
      "V2AF01e   0.0\n",
      "V2AF01b   0.0\n",
      "S01B05    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred\n",
      "0      00001U            2.348026            0.435350\n",
      "1      00004O            1.474683           -0.012537\n",
      "2      00007I           24.095593            1.722903\n",
      "3      00008G           -0.172039           -0.003570\n",
      "4      00015J            0.100838            0.022685\n",
      "...       ...                 ...                 ...\n",
      "9284   17349I            0.866327            0.006257\n",
      "9285   17350A            0.450175            0.392335\n",
      "9286   17351V           -0.153617           -0.000846\n",
      "9287   17352T            0.851284           -0.007500\n",
      "9288   17354P            1.434162            0.484234\n",
      "\n",
      "[9289 rows x 3 columns]\n",
      "lgb2d.csv (9289, 3)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "587/654 V2AI01 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8666, 4271) (623, 4271)\n",
      "(8666, 653) (8666,) (623, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0080\n",
      "Blended average after 1 repeats: 0.0080\n",
      "58.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=50, reg_alpha=0, reg_lambda=0.0001,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0078\n",
      "Blended average after 2 repeats: 0.0075\n",
      "122.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=50, reg_alpha=0.01,\n",
      "              reg_lambda=100, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0079\n",
      "Blended average after 3 repeats: 0.0074\n",
      "190.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=0, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0078\n",
      "Blended average after 4 repeats: 0.0072\n",
      "258.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.5, max_depth=5,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0078\n",
      "Blended average after 5 repeats: 0.0072\n",
      "313.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=50,\n",
      "              reg_alpha=10, reg_lambda=0.001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0078\n",
      "Blended average after 6 repeats: 0.0072\n",
      "376.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, max_depth=4,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.001, reg_lambda=0.01,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0078\n",
      "Blended average after 7 repeats: 0.0072\n",
      "432.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0.01, n_estimators=150,\n",
      "              num_leaves=20, reg_alpha=0.01, reg_lambda=0, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                gain\n",
      "feature             \n",
      "V2AI02     78.612245\n",
      "V2AI03     77.142857\n",
      "V1AF09     62.265306\n",
      "V2AI05     58.591837\n",
      "V2AI04     41.510204\n",
      "V2AI06     31.897959\n",
      "V1AF10     31.428571\n",
      "V2AI07     29.244898\n",
      "CLAB02f1b  23.775510\n",
      "V2BA02b1   23.755102\n",
      "         gain\n",
      "feature      \n",
      "V2AF05e   0.0\n",
      "S01A13    0.0\n",
      "V2AF01g   0.0\n",
      "V2AF01f   0.0\n",
      "V2AF01b   0.0\n",
      "V1AD13    0.0\n",
      "V1AD12d   0.0\n",
      "V1AD12c   0.0\n",
      "V1AD12b   0.0\n",
      "V2AF08g   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred\n",
      "0      00001U            2.348026            0.435350           0.992283\n",
      "1      00004O            1.474683           -0.012537           0.996685\n",
      "2      00007I           24.095593            1.722903           0.997104\n",
      "3      00008G           -0.172039           -0.003570           0.999620\n",
      "4      00015J            0.100838            0.022685           0.998037\n",
      "...       ...                 ...                 ...                ...\n",
      "9284   17349I            0.866327            0.006257           0.998894\n",
      "9285   17350A            0.450175            0.392335           1.000883\n",
      "9286   17351V           -0.153617           -0.000846           1.004393\n",
      "9287   17352T            0.851284           -0.007500           1.003374\n",
      "9288   17354P            1.434162            0.484234           1.000187\n",
      "\n",
      "[9289 rows x 4 columns]\n",
      "lgb2d.csv (9289, 4)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "588/654 V2AI02 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8666, 4271) (623, 4271)\n",
      "(8666, 653) (8666,) (623, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0100\n",
      "Blended average after 1 repeats: 0.0100\n",
      "69.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=50, reg_alpha=1, reg_lambda=100,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0100\n",
      "Blended average after 2 repeats: 0.0099\n",
      "127.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=1e-05, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0099\n",
      "Blended average after 3 repeats: 0.0097\n",
      "190.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=350, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0100\n",
      "Blended average after 4 repeats: 0.0098\n",
      "252.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0099\n",
      "Blended average after 5 repeats: 0.0097\n",
      "318.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, max_depth=2, min_child_samples=2,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=150,\n",
      "              num_leaves=30, reg_alpha=0.1, reg_lambda=0.0001, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0099\n",
      "Blended average after 6 repeats: 0.0097\n",
      "389.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.1, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0100\n",
      "Blended average after 7 repeats: 0.0097\n",
      "450.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                 gain\n",
      "feature              \n",
      "V2AI04      52.306122\n",
      "V2AI03      46.163265\n",
      "V2AI01      43.163265\n",
      "V2AI05      41.612245\n",
      "V2AI06      29.204082\n",
      "V2AI07      21.530612\n",
      "V1LA06a_HR  13.040816\n",
      "V2IA10       9.734694\n",
      "Education    9.714286\n",
      "S01B04       8.795918\n",
      "             gain\n",
      "feature          \n",
      "V2AF01g       0.0\n",
      "V1AE2_05f_1   0.0\n",
      "V2AE06e       0.0\n",
      "S02ECheck     0.0\n",
      "V2AE06h       0.0\n",
      "V2AE06i       0.0\n",
      "V1AI01        0.0\n",
      "S02E04        0.0\n",
      "V2AF01f       0.0\n",
      "V1AF12f       0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  \n",
      "0              1.004332  \n",
      "1              1.004756  \n",
      "2              1.008092  \n",
      "3              0.999381  \n",
      "4              0.999813  \n",
      "...                 ...  \n",
      "9284           0.999205  \n",
      "9285           0.992716  \n",
      "9286           0.999383  \n",
      "9287           0.999662  \n",
      "9288           1.001221  \n",
      "\n",
      "[9289 rows x 5 columns]\n",
      "lgb2d.csv (9289, 5)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "589/654 V2AI03 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8666, 4271) (623, 4271)\n",
      "(8666, 653) (8666,) (623, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0176\n",
      "Blended average after 1 repeats: 0.0176\n",
      "62.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=30, reg_alpha=0,\n",
      "              reg_lambda=0.0001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0173\n",
      "Blended average after 2 repeats: 0.0171\n",
      "125.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=20, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0174\n",
      "Blended average after 3 repeats: 0.0172\n",
      "192.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=100, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0175\n",
      "Blended average after 4 repeats: 0.0172\n",
      "254.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=5, min_child_weight=0, min_split_gain=0.001,\n",
      "              num_leaves=30, reg_alpha=0.01, reg_lambda=100, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0175\n",
      "Blended average after 5 repeats: 0.0172\n",
      "326.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, max_depth=4,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=100, reg_alpha=10, reg_lambda=0.01,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0175\n",
      "Blended average after 6 repeats: 0.0172\n",
      "384.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, max_depth=2,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=50, num_leaves=30, reg_alpha=1, reg_lambda=0.001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0175\n",
      "Blended average after 7 repeats: 0.0171\n",
      "451.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, max_depth=7,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=50,\n",
      "              num_leaves=100, reg_alpha=10, reg_lambda=0.0001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2AI04         40.795918\n",
      "V2AI05         35.693878\n",
      "V2AI07         35.510204\n",
      "V2AI02         26.102041\n",
      "V2AI06         22.489796\n",
      "V2AI01         22.020408\n",
      "V1AF09         16.306122\n",
      "PctFedPoverty  14.510204\n",
      "CLAA01c        12.102041\n",
      "Height_mean    10.265306\n",
      "             gain\n",
      "feature          \n",
      "V2AF05e       0.0\n",
      "V2AF01b       0.0\n",
      "V2AF01d       0.0\n",
      "V2AF01e       0.0\n",
      "V2AF01f       0.0\n",
      "V2AF01g       0.0\n",
      "V1AD18a1      0.0\n",
      "V1AD18a2      0.0\n",
      "V2AF05c       0.0\n",
      "V1AE2_05d_1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  \n",
      "0              1.004332           1.235634  \n",
      "1              1.004756           1.004982  \n",
      "2              1.008092           0.994186  \n",
      "3              0.999381           0.998314  \n",
      "4              0.999813           1.017472  \n",
      "...                 ...                ...  \n",
      "9284           0.999205           1.001113  \n",
      "9285           0.992716           1.052183  \n",
      "9286           0.999383           1.000165  \n",
      "9287           0.999662           1.003295  \n",
      "9288           1.001221           1.007896  \n",
      "\n",
      "[9289 rows x 6 columns]\n",
      "lgb2d.csv (9289, 6)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "590/654 V2AI04 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8666, 4271) (623, 4271)\n",
      "(8666, 653) (8666,) (623, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0420\n",
      "Blended average after 1 repeats: 0.0420\n",
      "64.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=30, reg_alpha=0,\n",
      "              reg_lambda=100, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0420\n",
      "Blended average after 2 repeats: 0.0417\n",
      "124.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=100, reg_alpha=0.001, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0421\n",
      "Blended average after 3 repeats: 0.0416\n",
      "190.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=1, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0421\n",
      "Blended average after 4 repeats: 0.0415\n",
      "251.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0419\n",
      "Blended average after 5 repeats: 0.0413\n",
      "320.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.07, max_depth=1,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=0.01, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0419\n",
      "Blended average after 6 repeats: 0.0413\n",
      "398.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=3,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.01, reg_lambda=10,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0419\n",
      "Blended average after 7 repeats: 0.0413\n",
      "466.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=1, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2AI07         52.020408\n",
      "V2AI06         36.326531\n",
      "V2AI03         26.408163\n",
      "V2AI05         20.510204\n",
      "V2AF13         16.102041\n",
      "Education      15.918367\n",
      "V2AI02         14.755102\n",
      "PctFedPoverty  14.693878\n",
      "CLAA01c        13.897959\n",
      "V2AF20         13.591837\n",
      "         gain\n",
      "feature      \n",
      "S01B05    0.0\n",
      "V2AF08d   0.0\n",
      "S01B03f   0.0\n",
      "V1AG11    0.0\n",
      "V2AF05d   0.0\n",
      "V2AF05e   0.0\n",
      "V2AF05g   0.0\n",
      "V2AF05h   0.0\n",
      "S01B03d   0.0\n",
      "S02G03    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \n",
      "0              1.004332           1.235634           1.531926  \n",
      "1              1.004756           1.004982           0.979120  \n",
      "2              1.008092           0.994186           1.042216  \n",
      "3              0.999381           0.998314           1.010470  \n",
      "4              0.999813           1.017472           1.055551  \n",
      "...                 ...                ...                ...  \n",
      "9284           0.999205           1.001113           0.988975  \n",
      "9285           0.992716           1.052183           1.355391  \n",
      "9286           0.999383           1.000165           0.999689  \n",
      "9287           0.999662           1.003295           0.998515  \n",
      "9288           1.001221           1.007896           1.030382  \n",
      "\n",
      "[9289 rows x 7 columns]\n",
      "lgb2d.csv (9289, 7)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "591/654 V2AI05 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8664, 4271) (625, 4271)\n",
      "(8664, 653) (8664,) (625, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0212\n",
      "Blended average after 1 repeats: 0.0212\n",
      "84.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=1, reg_lambda=100, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0209\n",
      "Blended average after 2 repeats: 0.0206\n",
      "142.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=100, reg_alpha=0.1, reg_lambda=0.01, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0211\n",
      "Blended average after 3 repeats: 0.0206\n",
      "202.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=4,\n",
      "              min_child_weight=0, min_split_gain=0.0001, num_leaves=30,\n",
      "              reg_alpha=0, reg_lambda=0.001, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0210\n",
      "Blended average after 4 repeats: 0.0205\n",
      "263.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, max_depth=2,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=30, reg_alpha=10, reg_lambda=0.01,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0210\n",
      "Blended average after 5 repeats: 0.0205\n",
      "318.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=0.1, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0210\n",
      "Blended average after 6 repeats: 0.0204\n",
      "383.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0210\n",
      "Blended average after 7 repeats: 0.0204\n",
      "452.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, max_depth=2, min_child_samples=7,\n",
      "              min_child_weight=0, min_split_gain=0.01, num_leaves=20,\n",
      "              reg_alpha=10, reg_lambda=0.001, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2AI06         67.612245\n",
      "V2AI04         56.448980\n",
      "V2AI07         50.693878\n",
      "V2AI03         38.265306\n",
      "PctFedPoverty  28.285714\n",
      "V2AF13         22.612245\n",
      "V2AI02         21.448980\n",
      "V1AF09         19.653061\n",
      "CLAA01d        18.673469\n",
      "V2IA02         16.775510\n",
      "         gain\n",
      "feature      \n",
      "S02G07    0.0\n",
      "S02G06    0.0\n",
      "V2AF25h   0.0\n",
      "S02G05    0.0\n",
      "S02G04    0.0\n",
      "S02G03    0.0\n",
      "S02G02    0.0\n",
      "S02E04    0.0\n",
      "S02C01    0.0\n",
      "S02G01    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  \n",
      "0              1.011470  \n",
      "1              1.012228  \n",
      "2              0.992822  \n",
      "3              0.998857  \n",
      "4              1.022873  \n",
      "...                 ...  \n",
      "9284           1.006103  \n",
      "9285           1.069873  \n",
      "9286           1.006484  \n",
      "9287           1.000656  \n",
      "9288           0.996453  \n",
      "\n",
      "[9289 rows x 8 columns]\n",
      "lgb2d.csv (9289, 8)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "592/654 V2AI06 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8666, 4271) (623, 4271)\n",
      "(8666, 653) (8666,) (623, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0586\n",
      "Blended average after 1 repeats: 0.0586\n",
      "65.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=350, num_leaves=20,\n",
      "              reg_alpha=10, reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0590\n",
      "Blended average after 2 repeats: 0.0586\n",
      "132.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=30, reg_alpha=0.1,\n",
      "              reg_lambda=0.01, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0589\n",
      "Blended average after 3 repeats: 0.0583\n",
      "206.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=10, reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0590\n",
      "Blended average after 4 repeats: 0.0584\n",
      "273.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=1,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=0.001,\n",
      "              reg_lambda=0.001, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0590\n",
      "Blended average after 5 repeats: 0.0583\n",
      "340.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=30, reg_alpha=0.1,\n",
      "              reg_lambda=0.1, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0590\n",
      "Blended average after 6 repeats: 0.0583\n",
      "409.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=50, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0590\n",
      "Blended average after 7 repeats: 0.0582\n",
      "473.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.07, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0.0001, n_estimators=225,\n",
      "              num_leaves=30, reg_alpha=10, reg_lambda=0.0001, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2AI07         58.306122\n",
      "V2AI04         38.142857\n",
      "V2AI05         32.673469\n",
      "CLAA01c        19.020408\n",
      "PctFedPoverty  18.877551\n",
      "S01B01         18.102041\n",
      "Age_at_V1      17.387755\n",
      "V1AG02c        13.040816\n",
      "V2AI03         12.714286\n",
      "V2AF13         12.693878\n",
      "             gain\n",
      "feature          \n",
      "V1AF12i       0.0\n",
      "V2AF05e       0.0\n",
      "V2AF01f       0.0\n",
      "V2AF01g       0.0\n",
      "S01A13        0.0\n",
      "V1AF12h       0.0\n",
      "S01A12        0.0\n",
      "V1AF12f       0.0\n",
      "V2AF05d       0.0\n",
      "V1AE2_04b_1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  \n",
      "0              1.011470           0.994452  \n",
      "1              1.012228           1.019569  \n",
      "2              0.992822           1.083187  \n",
      "3              0.998857           1.036859  \n",
      "4              1.022873           1.010900  \n",
      "...                 ...                ...  \n",
      "9284           1.006103           1.045727  \n",
      "9285           1.069873           1.347627  \n",
      "9286           1.006484           0.985544  \n",
      "9287           1.000656           1.001288  \n",
      "9288           0.996453           0.986186  \n",
      "\n",
      "[9289 rows x 9 columns]\n",
      "lgb2d.csv (9289, 9)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "593/654 V2AI07 3 0.067\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8664, 4271) (625, 4271)\n",
      "(8664, 653) (8664,) (625, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.1193\n",
      "Blended average after 1 repeats: 0.1193\n",
      "75.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=0.1,\n",
      "              reg_lambda=0.01, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.1190\n",
      "Blended average after 2 repeats: 0.1178\n",
      "144.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1193\n",
      "Blended average after 3 repeats: 0.1178\n",
      "213.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=0.0001, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1192\n",
      "Blended average after 4 repeats: 0.1175\n",
      "290.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=0.01, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1191\n",
      "Blended average after 5 repeats: 0.1173\n",
      "370.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=10, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1192\n",
      "Blended average after 6 repeats: 0.1173\n",
      "434.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=0.001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1191\n",
      "Blended average after 7 repeats: 0.1173\n",
      "508.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=0.1, reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2AI06         56.163265\n",
      "V1AF09         48.428571\n",
      "PctFedPoverty  38.775510\n",
      "V2AI04         38.265306\n",
      "V1BA01_LB      26.428571\n",
      "CLAA01d        23.632653\n",
      "CLAA01a        23.040816\n",
      "V2AF13         22.591837\n",
      "CLAA01c        20.673469\n",
      "V2BA01_LB      20.551020\n",
      "         gain\n",
      "feature      \n",
      "S02G11    0.0\n",
      "V1AF12i   0.0\n",
      "S02G12    0.0\n",
      "S02G13    0.0\n",
      "V1AF07f   0.0\n",
      "V2AF05h   0.0\n",
      "S01A08    0.0\n",
      "S02G14    0.0\n",
      "V1AF12h   0.0\n",
      "S02E04    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \n",
      "0              1.011470           0.994452           1.355741  \n",
      "1              1.012228           1.019569           1.125877  \n",
      "2              0.992822           1.083187           1.119065  \n",
      "3              0.998857           1.036859           0.975540  \n",
      "4              1.022873           1.010900           1.227488  \n",
      "...                 ...                ...                ...  \n",
      "9284           1.006103           1.045727           1.046157  \n",
      "9285           1.069873           1.347627           1.393278  \n",
      "9286           1.006484           0.985544           1.157548  \n",
      "9287           1.000656           1.001288           1.055910  \n",
      "9288           0.996453           0.986186           1.385738  \n",
      "\n",
      "[9289 rows x 10 columns]\n",
      "lgb2d.csv (9289, 10)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "595/654 V2AJ01a 26 0.305\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(6459, 4271) (2830, 4271)\n",
      "(6459, 653) (6459,) (2830, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 47.7936\n",
      "Blended average after 1 repeats: 47.7939\n",
      "68.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, max_depth=6, min_child_samples=100,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=150,\n",
      "              num_leaves=50, reg_alpha=1, reg_lambda=0, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 47.7000\n",
      "Blended average after 2 repeats: 47.0444\n",
      "125.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=50,\n",
      "              num_leaves=30, reg_alpha=0.01, reg_lambda=10, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 47.6092\n",
      "Blended average after 3 repeats: 46.7771\n",
      "184.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_weight=0, min_split_gain=0, num_leaves=100,\n",
      "              reg_alpha=0.1, reg_lambda=0.0001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 47.4570\n",
      "Blended average after 4 repeats: 46.5376\n",
      "248.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=0.1,\n",
      "              reg_lambda=1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 47.5524\n",
      "Blended average after 5 repeats: 46.5447\n",
      "311.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 47.5320\n",
      "Blended average after 6 repeats: 46.4559\n",
      "389.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=20, reg_alpha=0.1,\n",
      "              reg_lambda=0.001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 47.5272\n",
      "Blended average after 7 repeats: 46.4635\n",
      "460.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, max_depth=5,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=50, num_leaves=20, reg_alpha=0, reg_lambda=0.0001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                 gain\n",
      "feature              \n",
      "V2AJ01a3   246.183673\n",
      "V1AI01a    123.224490\n",
      "V2AJ02a    120.122449\n",
      "V2AJ01a1    91.877551\n",
      "V2AJ01a2    81.346939\n",
      "V1AI02a     67.734694\n",
      "CLAA01d     44.857143\n",
      "CLAE02a1    43.020408\n",
      "Neck_mean   36.836735\n",
      "V2AJ02a1    36.775510\n",
      "             gain\n",
      "feature          \n",
      "V1AE2_04h_1   0.0\n",
      "S01B05        0.0\n",
      "S01BCheck     0.0\n",
      "V2AJ01        0.0\n",
      "V1AE2_04g_1   0.0\n",
      "V1AE2_04f_1   0.0\n",
      "V1AE2_04e_1   0.0\n",
      "V2AF18h       0.0\n",
      "V2AF18i       0.0\n",
      "S02G10        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  \n",
      "0              14.005381  \n",
      "1              21.195964  \n",
      "2              27.070077  \n",
      "3              18.784722  \n",
      "4               9.653549  \n",
      "...                  ...  \n",
      "9284           18.039285  \n",
      "9285           16.502644  \n",
      "9286           24.950701  \n",
      "9287           20.013860  \n",
      "9288           25.124410  \n",
      "\n",
      "[9289 rows x 11 columns]\n",
      "lgb2d.csv (9289, 11)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "596/654 V2AJ01a1 15 0.306\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(6448, 4271) (2841, 4271)\n",
      "(6448, 653) (6448,) (2841, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 3.4321\n",
      "Blended average after 1 repeats: 3.4320\n",
      "64.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=10, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 3.4199\n",
      "Blended average after 2 repeats: 3.3880\n",
      "123.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=50, num_leaves=30, reg_alpha=0.1,\n",
      "              reg_lambda=1e-05, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 3.4266\n",
      "Blended average after 3 repeats: 3.3840\n",
      "184.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=50, reg_alpha=0.01, reg_lambda=0.001,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 3.4267\n",
      "Blended average after 4 repeats: 3.3786\n",
      "251.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 3.4281\n",
      "Blended average after 5 repeats: 3.3789\n",
      "312.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=5, min_child_weight=0, min_split_gain=0, num_leaves=30,\n",
      "              reg_alpha=1, reg_lambda=0, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 3.4316\n",
      "Blended average after 6 repeats: 3.3788\n",
      "378.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 3.4286\n",
      "Blended average after 7 repeats: 3.3757\n",
      "435.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=30, reg_alpha=0.01,\n",
      "              reg_lambda=100, subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                gain\n",
      "feature             \n",
      "V2AJ01a   102.244898\n",
      "V1AI01a1   91.244898\n",
      "V2AJ01a2   51.959184\n",
      "V1AI02a1   49.142857\n",
      "CLAA01d    37.755102\n",
      "V2AJ01a3   35.244898\n",
      "CLAE02a1   34.469388\n",
      "V1AI01a    32.632653\n",
      "V2AJ02a    28.775510\n",
      "CLAA01c    27.081633\n",
      "           gain\n",
      "feature        \n",
      "V2AF25h     0.0\n",
      "V2AF22h     0.0\n",
      "S02E02      0.0\n",
      "S02E04      0.0\n",
      "V2AF18i     0.0\n",
      "S02ECheck   0.0\n",
      "S02G01      0.0\n",
      "S02G02      0.0\n",
      "V1AD12d     0.0\n",
      "V1EVer      0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  \n",
      "0              14.005381             4.008431  \n",
      "1              21.195964             2.384130  \n",
      "2              27.070077             4.675453  \n",
      "3              18.784722             2.296674  \n",
      "4               9.653549             2.444379  \n",
      "...                  ...                  ...  \n",
      "9284           18.039285             2.043751  \n",
      "9285           16.502644             2.680248  \n",
      "9286           24.950701             2.841850  \n",
      "9287           20.013860             1.833254  \n",
      "9288           25.124410             3.972233  \n",
      "\n",
      "[9289 rows x 12 columns]\n",
      "lgb2d.csv (9289, 12)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "597/654 V2AJ01a2 60 0.315\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(6363, 4271) (2926, 4271)\n",
      "(6363, 653) (6363,) (2926, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 1525.9538\n",
      "Blended average after 1 repeats: 1525.9538\n",
      "54.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, max_depth=3,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=10, reg_lambda=100,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 1523.3510\n",
      "Blended average after 2 repeats: 1508.4922\n",
      "114.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, max_depth=7,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=50, reg_alpha=0.001, reg_lambda=100,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 1522.5032\n",
      "Blended average after 3 repeats: 1503.2238\n",
      "177.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=0.001, reg_lambda=10,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 1520.3260\n",
      "Blended average after 4 repeats: 1498.6509\n",
      "238.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=50, reg_alpha=1, reg_lambda=1e-05,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 1522.3713\n",
      "Blended average after 5 repeats: 1499.2406\n",
      "292.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, max_depth=3,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=50, num_leaves=20, reg_alpha=10, reg_lambda=0.1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 1522.8072\n",
      "Blended average after 6 repeats: 1499.2564\n",
      "354.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 1525.2673\n",
      "Blended average after 7 repeats: 1500.9677\n",
      "413.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                 gain\n",
      "feature              \n",
      "V2AJ01a3   132.816327\n",
      "V1AI01a2    96.897959\n",
      "V2AJ01a     93.346939\n",
      "CLAA01c     36.183673\n",
      "CLAA01d     34.877551\n",
      "CLAE02a1    34.653061\n",
      "CLAA01b     26.571429\n",
      "V1BA01_LB   26.448980\n",
      "CLAA01a     25.204082\n",
      "V2AJ01a1    24.979592\n",
      "             gain\n",
      "feature          \n",
      "S01A11        0.0\n",
      "S01A10        0.0\n",
      "V2AF18i       0.0\n",
      "S01A08        0.0\n",
      "V2BA01a       0.0\n",
      "V1AE2_04f_1   0.0\n",
      "S01A06        0.0\n",
      "V2BVer        0.0\n",
      "S01A05        0.0\n",
      "V1AF06g       0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \n",
      "0              14.005381             4.008431            42.558226  \n",
      "1              21.195964             2.384130            43.014995  \n",
      "2              27.070077             4.675453            44.404508  \n",
      "3              18.784722             2.296674            90.736427  \n",
      "4               9.653549             2.444379            43.790324  \n",
      "...                  ...                  ...                  ...  \n",
      "9284           18.039285             2.043751            50.168189  \n",
      "9285           16.502644             2.680248            71.890933  \n",
      "9286           24.950701             2.841850            42.432092  \n",
      "9287           20.013860             1.833254            59.854797  \n",
      "9288           25.124410             3.972233            57.434166  \n",
      "\n",
      "[9289 rows x 13 columns]\n",
      "lgb2d.csv (9289, 13)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "598/654 V2AJ01a3 57 0.618\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(3553, 4271) (5736, 4271)\n",
      "(3553, 653) (3553,) (5736, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 3.9826\n",
      "Blended average after 1 repeats: 3.9823\n",
      "42.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0.01, reg_lambda=0,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 4.0236\n",
      "Blended average after 2 repeats: 3.9755\n",
      "81.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=50, reg_alpha=0.01, reg_lambda=100, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 4.0152\n",
      "Blended average after 3 repeats: 3.9519\n",
      "120.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=20, reg_alpha=10, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 4.0157\n",
      "Blended average after 4 repeats: 3.9441\n",
      "159.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=0, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 4.0109\n",
      "Blended average after 5 repeats: 3.9334\n",
      "196.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=2,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=0.001, reg_lambda=10,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 4.0005\n",
      "Blended average after 6 repeats: 3.9196\n",
      "238.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=30,\n",
      "              reg_alpha=0.01, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 3.9953\n",
      "Blended average after 7 repeats: 3.9121\n",
      "285.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, max_depth=2,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=100, reg_alpha=0.001, reg_lambda=0.1, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2AJ01a2       81.163265\n",
      "V2AJ01a        61.612245\n",
      "V1AI01a3       34.244898\n",
      "CLAB02b_WKS    22.326531\n",
      "CLAB02d2       16.632653\n",
      "CLAB02c        15.897959\n",
      "CLAB02e2       14.897959\n",
      "PctFedPoverty  14.571429\n",
      "CLAA01c        13.163265\n",
      "CLAE02a1       11.734694\n",
      "             gain\n",
      "feature          \n",
      "V2AH05        0.0\n",
      "V2AH04        0.0\n",
      "V2AH03        0.0\n",
      "V1KA02_AMPM   0.0\n",
      "S01A05        0.0\n",
      "S02H01        0.0\n",
      "V2AF05g       0.0\n",
      "V2AF05h       0.0\n",
      "S01A06        0.0\n",
      "V1AE2_04e_1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  \n",
      "0                4.418429  \n",
      "1                2.552967  \n",
      "2                0.898839  \n",
      "3                1.525299  \n",
      "4                8.192344  \n",
      "...                   ...  \n",
      "9284             2.087319  \n",
      "9285             6.300943  \n",
      "9286             3.067061  \n",
      "9287             1.563420  \n",
      "9288             2.693097  \n",
      "\n",
      "[9289 rows x 14 columns]\n",
      "lgb2d.csv (9289, 14)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "600/654 V2AJ02a 25 0.715\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(2643, 4271) (6646, 4271)\n",
      "(2643, 653) (2643,) (6646, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 105.3067\n",
      "Blended average after 1 repeats: 105.3110\n",
      "27.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, max_depth=1,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=50, reg_alpha=0.1, reg_lambda=0.0001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 105.2414\n",
      "Blended average after 2 repeats: 104.3674\n",
      "63.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=30, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 104.8591\n",
      "Blended average after 3 repeats: 103.8324\n",
      "96.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=50, num_leaves=50, reg_alpha=0.1,\n",
      "              reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 105.0170\n",
      "Blended average after 4 repeats: 103.8888\n",
      "132.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=50, num_leaves=20, reg_alpha=0,\n",
      "              reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 104.8400\n",
      "Blended average after 5 repeats: 103.7515\n",
      "163.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=30, reg_alpha=0.001,\n",
      "              reg_lambda=0.01, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 104.9218\n",
      "Blended average after 6 repeats: 103.7802\n",
      "199.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, max_depth=2,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=30, reg_alpha=0.01, reg_lambda=0.0001, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 104.9766\n",
      "Blended average after 7 repeats: 103.8155\n",
      "233.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, max_depth=1,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.01,\n",
      "              num_leaves=30, reg_alpha=0.01, reg_lambda=100, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "               gain\n",
      "feature            \n",
      "V2AJ01a   48.061224\n",
      "V1AI02a   43.142857\n",
      "V1AI01a   30.122449\n",
      "V2AJ02a1  29.387755\n",
      "V2AJ02a2  21.489796\n",
      "V2AJ01a3  17.857143\n",
      "V2AJ03    12.102041\n",
      "CLAA01d    9.673469\n",
      "CLAE02a1   8.448980\n",
      "CLAB02c    7.571429\n",
      "           gain\n",
      "feature        \n",
      "V2AF18g     0.0\n",
      "V2AF18f     0.0\n",
      "V1AF15f     0.0\n",
      "V1AF15e     0.0\n",
      "V1AF15b     0.0\n",
      "V1AF12i     0.0\n",
      "V1AF12h     0.0\n",
      "V2AF17e     0.0\n",
      "V1AF12f     0.0\n",
      "AgeCat_V1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  \n",
      "0                4.418429           18.961968  \n",
      "1                2.552967           20.286149  \n",
      "2                0.898839           20.107628  \n",
      "3                1.525299           16.330709  \n",
      "4                8.192344           21.933615  \n",
      "...                   ...                 ...  \n",
      "9284             2.087319           20.855105  \n",
      "9285             6.300943           21.007826  \n",
      "9286             3.067061           23.000871  \n",
      "9287             1.563420           23.781733  \n",
      "9288             2.693097           19.803796  \n",
      "\n",
      "[9289 rows x 15 columns]\n",
      "lgb2d.csv (9289, 15)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "601/654 V2AJ02a1 18 0.717\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(2633, 4271) (6656, 4271)\n",
      "(2633, 653) (2633,) (6656, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 3.9352\n",
      "Blended average after 1 repeats: 3.9346\n",
      "34.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=100, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 3.9452\n",
      "Blended average after 2 repeats: 3.9129\n",
      "62.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.1, reg_lambda=100,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 3.9568\n",
      "Blended average after 3 repeats: 3.9081\n",
      "98.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=20, reg_alpha=0.1, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 3.9628\n",
      "Blended average after 4 repeats: 3.9016\n",
      "132.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=50, num_leaves=50, reg_alpha=0.001,\n",
      "              reg_lambda=0.01, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 3.9541\n",
      "Blended average after 5 repeats: 3.8919\n",
      "158.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=1,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 3.9477\n",
      "Blended average after 6 repeats: 3.8841\n",
      "187.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, max_depth=4,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0,\n",
      "              num_leaves=20, reg_alpha=0.1, reg_lambda=0, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 3.9461\n",
      "Blended average after 7 repeats: 3.8829\n",
      "222.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=2,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                gain\n",
      "feature             \n",
      "V2AJ02a    98.408163\n",
      "V2AJ02a2   51.877551\n",
      "V1AI02a1   47.510204\n",
      "V1AI01a1   40.714286\n",
      "CLAA01c    25.306122\n",
      "CLAE02a1   24.653061\n",
      "V2AF12_YR  24.326531\n",
      "CLAA01d    21.836735\n",
      "CLAA01b    20.469388\n",
      "V2AJ01a3   19.591837\n",
      "             gain\n",
      "feature          \n",
      "S02G02        0.0\n",
      "V1AF07e       0.0\n",
      "V2AF25e       0.0\n",
      "S02G01        0.0\n",
      "V2AF25c       0.0\n",
      "S02ECheck     0.0\n",
      "S02E04        0.0\n",
      "V2AF22h       0.0\n",
      "V2AF22g       0.0\n",
      "V1AE2_04h_1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  \n",
      "0                4.418429           18.961968             2.754658  \n",
      "1                2.552967           20.286149             2.416844  \n",
      "2                0.898839           20.107628             3.345272  \n",
      "3                1.525299           16.330709             1.813485  \n",
      "4                8.192344           21.933615             2.172912  \n",
      "...                   ...                 ...                  ...  \n",
      "9284             2.087319           20.855105             3.576788  \n",
      "9285             6.300943           21.007826             3.359234  \n",
      "9286             3.067061           23.000871             3.215336  \n",
      "9287             1.563420           23.781733             3.647880  \n",
      "9288             2.693097           19.803796             3.368538  \n",
      "\n",
      "[9289 rows x 16 columns]\n",
      "lgb2d.csv (9289, 16)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "602/654 V2AJ02a2 40 0.719\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(2606, 4271) (6683, 4271)\n",
      "(2606, 653) (2606,) (6683, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 967.9302\n",
      "Blended average after 1 repeats: 968.1031\n",
      "35.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=2, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=0, reg_lambda=0.01,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 970.1819\n",
      "Blended average after 2 repeats: 957.9282\n",
      "60.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=7, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=50, reg_alpha=0.01, reg_lambda=1, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 966.3222\n",
      "Blended average after 3 repeats: 950.8980\n",
      "96.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 967.5479\n",
      "Blended average after 4 repeats: 951.1179\n",
      "126.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=10, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 969.2511\n",
      "Blended average after 5 repeats: 951.9628\n",
      "160.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, learning_rate=0.07, max_depth=5,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.001, reg_lambda=100,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 969.4805\n",
      "Blended average after 6 repeats: 951.4626\n",
      "194.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30, reg_alpha=0.1,\n",
      "              reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 968.4643\n",
      "Blended average after 7 repeats: 950.0409\n",
      "224.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.05, max_depth=4,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0,\n",
      "              num_leaves=100, reg_alpha=0, reg_lambda=100, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                 gain\n",
      "feature              \n",
      "V2AJ02a     86.102041\n",
      "V1AI02a2    38.448980\n",
      "V1AI01a2    36.632653\n",
      "V2AJ01a2    29.408163\n",
      "CLAA01c     24.510204\n",
      "V2AJ02a1    23.285714\n",
      "CLAA01d     19.938776\n",
      "CLAA01b     17.387755\n",
      "V1AD19b_hr  14.836735\n",
      "CLAE02a1    14.734694\n",
      "         gain\n",
      "feature      \n",
      "V2AF22e   0.0\n",
      "V1LF01c   0.0\n",
      "V1LVer    0.0\n",
      "V2AA01    0.0\n",
      "S02C01    0.0\n",
      "V2AF18i   0.0\n",
      "V2AF18h   0.0\n",
      "V1AA01    0.0\n",
      "V2AF18e   0.0\n",
      "S02G14    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  \\\n",
      "0                4.418429           18.961968             2.754658   \n",
      "1                2.552967           20.286149             2.416844   \n",
      "2                0.898839           20.107628             3.345272   \n",
      "3                1.525299           16.330709             1.813485   \n",
      "4                8.192344           21.933615             2.172912   \n",
      "...                   ...                 ...                  ...   \n",
      "9284             2.087319           20.855105             3.576788   \n",
      "9285             6.300943           21.007826             3.359234   \n",
      "9286             3.067061           23.000871             3.215336   \n",
      "9287             1.563420           23.781733             3.647880   \n",
      "9288             2.693097           19.803796             3.368538   \n",
      "\n",
      "      V2AJ02a2_lgb2d_pred  \n",
      "0               63.037137  \n",
      "1               49.319974  \n",
      "2               38.226144  \n",
      "3               78.931292  \n",
      "4               40.705117  \n",
      "...                   ...  \n",
      "9284            38.910415  \n",
      "9285            50.207090  \n",
      "9286            45.951801  \n",
      "9287            32.424894  \n",
      "9288            55.816223  \n",
      "\n",
      "[9289 rows x 17 columns]\n",
      "lgb2d.csv (9289, 17)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "605/654 V2BA01_LB 1258 0.193\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(7494, 4271) (1795, 4271)\n",
      "(7494, 653) (7494,) (1795, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 39.9096\n",
      "Blended average after 1 repeats: 39.9098\n",
      "70.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, max_depth=5, min_child_samples=40,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=225,\n",
      "              num_leaves=100, reg_alpha=0.001, reg_lambda=10, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 39.5668\n",
      "Blended average after 2 repeats: 37.9156\n",
      "141.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=0.0001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 39.7438\n",
      "Blended average after 3 repeats: 37.3435\n",
      "214.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=100, reg_alpha=0, reg_lambda=0.1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 39.2849\n",
      "Blended average after 4 repeats: 36.6954\n",
      "288.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.05, max_depth=4,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.001, reg_lambda=1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 39.2130\n",
      "Blended average after 5 repeats: 36.4960\n",
      "366.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.07, max_depth=5,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 39.3059\n",
      "Blended average after 6 repeats: 36.4288\n",
      "438.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, max_depth=6,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=0, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 39.2964\n",
      "Blended average after 7 repeats: 36.2736\n",
      "505.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=7,\n",
      "              min_child_weight=0, min_split_gain=0.0001, n_estimators=350,\n",
      "              num_leaves=50, reg_alpha=0.1, reg_lambda=1e-05, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "V1BA01_LB    573.224490\n",
      "V1AD01b      275.367347\n",
      "BMI          126.816327\n",
      "Height_mean  104.693878\n",
      "CLAA01c       74.816327\n",
      "CLAA01d       73.857143\n",
      "Hip_mean      69.346939\n",
      "Height_max    64.244898\n",
      "CLAA01a       64.142857\n",
      "V2BA02a1      60.489796\n",
      "             gain\n",
      "feature          \n",
      "V2AF25h       0.0\n",
      "V1AE2_04g_1   0.0\n",
      "S02G05        0.0\n",
      "S02B03        0.0\n",
      "S02B02        0.0\n",
      "V1AF06g       0.0\n",
      "S01Ver        0.0\n",
      "S01B05        0.0\n",
      "S01A13        0.0\n",
      "S02H01        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  \\\n",
      "0                4.418429           18.961968             2.754658   \n",
      "1                2.552967           20.286149             2.416844   \n",
      "2                0.898839           20.107628             3.345272   \n",
      "3                1.525299           16.330709             1.813485   \n",
      "4                8.192344           21.933615             2.172912   \n",
      "...                   ...                 ...                  ...   \n",
      "9284             2.087319           20.855105             3.576788   \n",
      "9285             6.300943           21.007826             3.359234   \n",
      "9286             3.067061           23.000871             3.215336   \n",
      "9287             1.563420           23.781733             3.647880   \n",
      "9288             2.693097           19.803796             3.368538   \n",
      "\n",
      "      V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  \n",
      "0               63.037137            161.644659  \n",
      "1               49.319974            150.947813  \n",
      "2               38.226144            131.314817  \n",
      "3               78.931292            193.116653  \n",
      "4               40.705117            140.860778  \n",
      "...                   ...                   ...  \n",
      "9284            38.910415            180.517324  \n",
      "9285            50.207090            127.727895  \n",
      "9286            45.951801            160.503398  \n",
      "9287            32.424894            135.668325  \n",
      "9288            55.816223            190.366771  \n",
      "\n",
      "[9289 rows x 18 columns]\n",
      "lgb2d.csv (9289, 18)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "607/654 V2BA02a1 80 0.071\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8631, 4271) (658, 4271)\n",
      "(8631, 653) (8631,) (658, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 69.4747\n",
      "Blended average after 1 repeats: 69.4747\n",
      "71.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, max_depth=1,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.01, reg_lambda=0.1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 69.4340\n",
      "Blended average after 2 repeats: 69.0983\n",
      "147.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=1,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0.01, reg_lambda=0.1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 69.3687\n",
      "Blended average after 3 repeats: 68.9019\n",
      "226.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=0, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 69.3896\n",
      "Blended average after 4 repeats: 68.8478\n",
      "304.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=1,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=350,\n",
      "              num_leaves=30, reg_alpha=10, reg_lambda=0, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 69.4359\n",
      "Blended average after 5 repeats: 68.8543\n",
      "377.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=0.01, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 69.4756\n",
      "Blended average after 6 repeats: 68.8860\n",
      "453.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=10, reg_lambda=10, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 69.4828\n",
      "Blended average after 7 repeats: 68.8621\n",
      "528.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=20, reg_alpha=0.001,\n",
      "              reg_lambda=0.01, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "V2BA02b1     110.551020\n",
      "BP_Sys_max    47.000000\n",
      "BP_Sys_std    28.795918\n",
      "BP_Sys_mean   25.122449\n",
      "V2BA01_LB     23.326531\n",
      "V1BA01_LB     16.673469\n",
      "Waist_mean    12.040816\n",
      "BMI           11.510204\n",
      "V1AD01b       11.489796\n",
      "CLAE08        10.734694\n",
      "         gain\n",
      "feature      \n",
      "V2AF05g   0.0\n",
      "V2AF05e   0.0\n",
      "V2AF05c   0.0\n",
      "V2AF01g   0.0\n",
      "V2AF01f   0.0\n",
      "V2AF01e   0.0\n",
      "S01Ver    0.0\n",
      "S02B02    0.0\n",
      "S02B03    0.0\n",
      "S02G01    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  \\\n",
      "0                4.418429           18.961968             2.754658   \n",
      "1                2.552967           20.286149             2.416844   \n",
      "2                0.898839           20.107628             3.345272   \n",
      "3                1.525299           16.330709             1.813485   \n",
      "4                8.192344           21.933615             2.172912   \n",
      "...                   ...                 ...                  ...   \n",
      "9284             2.087319           20.855105             3.576788   \n",
      "9285             6.300943           21.007826             3.359234   \n",
      "9286             3.067061           23.000871             3.215336   \n",
      "9287             1.563420           23.781733             3.647880   \n",
      "9288             2.693097           19.803796             3.368538   \n",
      "\n",
      "      V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  \n",
      "0               63.037137            161.644659           100.785484  \n",
      "1               49.319974            150.947813           102.647583  \n",
      "2               38.226144            131.314817           108.420168  \n",
      "3               78.931292            193.116653           116.524543  \n",
      "4               40.705117            140.860778           106.971071  \n",
      "...                   ...                   ...                  ...  \n",
      "9284            38.910415            180.517324           114.790563  \n",
      "9285            50.207090            127.727895           112.811574  \n",
      "9286            45.951801            160.503398           118.191889  \n",
      "9287            32.424894            135.668325           102.198770  \n",
      "9288            55.816223            190.366771           106.100940  \n",
      "\n",
      "[9289 rows x 19 columns]\n",
      "lgb2d.csv (9289, 19)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "608/654 V2BA02b1 61 0.071\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8631, 4271) (658, 4271)\n",
      "(8631, 653) (8631,) (658, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 42.9955\n",
      "Blended average after 1 repeats: 42.9955\n",
      "73.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, max_depth=2,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=50, reg_alpha=0.1, reg_lambda=1, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 42.9239\n",
      "Blended average after 2 repeats: 42.6594\n",
      "145.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=100, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 42.8877\n",
      "Blended average after 3 repeats: 42.5423\n",
      "220.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=20, reg_alpha=0.1,\n",
      "              reg_lambda=0.1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 42.8258\n",
      "Blended average after 4 repeats: 42.4548\n",
      "287.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=0,\n",
      "              reg_lambda=10, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 42.8163\n",
      "Blended average after 5 repeats: 42.4250\n",
      "359.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=0, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 42.7892\n",
      "Blended average after 6 repeats: 42.3965\n",
      "443.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=1e-05, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 42.7662\n",
      "Blended average after 7 repeats: 42.3427\n",
      "518.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.7, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "V2BA02a1     144.795918\n",
      "BP_Dia_mean   38.040816\n",
      "BP_Dia_max    29.673469\n",
      "BP_Sys_std    26.469388\n",
      "V2BA01_LB     22.857143\n",
      "V1BA01_LB     20.530612\n",
      "CLAB01c       17.142857\n",
      "CLAA01b       16.000000\n",
      "CLAE02a1      15.653061\n",
      "BP_Sys_mean   14.938776\n",
      "           gain\n",
      "feature        \n",
      "V2AF18h     0.0\n",
      "V1GVer      0.0\n",
      "V2AF18f     0.0\n",
      "S01B05      0.0\n",
      "S01BCheck   0.0\n",
      "V1HVer      0.0\n",
      "S01Ver      0.0\n",
      "V1AD12d     0.0\n",
      "S02B02      0.0\n",
      "V1AF07f     0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  \\\n",
      "0              1.011470           0.994452           1.355741   \n",
      "1              1.012228           1.019569           1.125877   \n",
      "2              0.992822           1.083187           1.119065   \n",
      "3              0.998857           1.036859           0.975540   \n",
      "4              1.022873           1.010900           1.227488   \n",
      "...                 ...                ...                ...   \n",
      "9284           1.006103           1.045727           1.046157   \n",
      "9285           1.069873           1.347627           1.393278   \n",
      "9286           1.006484           0.985544           1.157548   \n",
      "9287           1.000656           1.001288           1.055910   \n",
      "9288           0.996453           0.986186           1.385738   \n",
      "\n",
      "      V2AJ01a_lgb2d_pred  V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  \\\n",
      "0              14.005381             4.008431            42.558226   \n",
      "1              21.195964             2.384130            43.014995   \n",
      "2              27.070077             4.675453            44.404508   \n",
      "3              18.784722             2.296674            90.736427   \n",
      "4               9.653549             2.444379            43.790324   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           18.039285             2.043751            50.168189   \n",
      "9285           16.502644             2.680248            71.890933   \n",
      "9286           24.950701             2.841850            42.432092   \n",
      "9287           20.013860             1.833254            59.854797   \n",
      "9288           25.124410             3.972233            57.434166   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  \\\n",
      "0                4.418429           18.961968             2.754658   \n",
      "1                2.552967           20.286149             2.416844   \n",
      "2                0.898839           20.107628             3.345272   \n",
      "3                1.525299           16.330709             1.813485   \n",
      "4                8.192344           21.933615             2.172912   \n",
      "...                   ...                 ...                  ...   \n",
      "9284             2.087319           20.855105             3.576788   \n",
      "9285             6.300943           21.007826             3.359234   \n",
      "9286             3.067061           23.000871             3.215336   \n",
      "9287             1.563420           23.781733             3.647880   \n",
      "9288             2.693097           19.803796             3.368538   \n",
      "\n",
      "      V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  \\\n",
      "0               63.037137            161.644659           100.785484   \n",
      "1               49.319974            150.947813           102.647583   \n",
      "2               38.226144            131.314817           108.420168   \n",
      "3               78.931292            193.116653           116.524543   \n",
      "4               40.705117            140.860778           106.971071   \n",
      "...                   ...                   ...                  ...   \n",
      "9284            38.910415            180.517324           114.790563   \n",
      "9285            50.207090            127.727895           112.811574   \n",
      "9286            45.951801            160.503398           118.191889   \n",
      "9287            32.424894            135.668325           102.198770   \n",
      "9288            55.816223            190.366771           106.100940   \n",
      "\n",
      "      V2BA02b1_lgb2d_pred  \n",
      "0               61.774390  \n",
      "1               58.609529  \n",
      "2               63.038783  \n",
      "3               68.382805  \n",
      "4               66.149402  \n",
      "...                   ...  \n",
      "9284            66.608928  \n",
      "9285            64.669460  \n",
      "9286            68.502210  \n",
      "9287            63.654537  \n",
      "9288            65.922997  \n",
      "\n",
      "[9289 rows x 20 columns]\n",
      "lgb2d.csv (9289, 20)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "610/654 V2IA01 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8654, 4271) (635, 4271)\n",
      "(8654, 653) (8654,) (635, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3334\n",
      "Blended average after 1 repeats: 0.3334\n",
      "73.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=4, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.001,\n",
      "              reg_lambda=1e-05, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3329\n",
      "Blended average after 2 repeats: 0.3308\n",
      "149.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=0.001, reg_lambda=0.01,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3327\n",
      "Blended average after 3 repeats: 0.3299\n",
      "221.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=30, reg_alpha=1, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3322\n",
      "Blended average after 4 repeats: 0.3292\n",
      "295.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=1e-05, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3324\n",
      "Blended average after 5 repeats: 0.3292\n",
      "366.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=50, num_leaves=30, reg_alpha=1, reg_lambda=0,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3322\n",
      "Blended average after 6 repeats: 0.3290\n",
      "445.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3322\n",
      "Blended average after 7 repeats: 0.3289\n",
      "520.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50, reg_alpha=0.01,\n",
      "              reg_lambda=10, subsample=0.7, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA08   35.000000\n",
      "V2IA02   33.530612\n",
      "V2IA04   33.306122\n",
      "V2IA06   25.102041\n",
      "V2IA05   22.551020\n",
      "V2IA07   20.775510\n",
      "V2IA19   20.163265\n",
      "V1HA09   14.775510\n",
      "V2IA14   14.591837\n",
      "V2IA16   12.081633\n",
      "         gain\n",
      "feature      \n",
      "V1AF15b   0.0\n",
      "V1AF15e   0.0\n",
      "V1AF15f   0.0\n",
      "S02G08    0.0\n",
      "V1AF15g   0.0\n",
      "S02G09    0.0\n",
      "V1AD12d   0.0\n",
      "S01A10    0.0\n",
      "V2AF18f   0.0\n",
      "S02E04    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2AJ01a1_lgb2d_pred  V2AJ01a2_lgb2d_pred  V2AJ01a3_lgb2d_pred  \\\n",
      "0                4.008431            42.558226             4.418429   \n",
      "1                2.384130            43.014995             2.552967   \n",
      "2                4.675453            44.404508             0.898839   \n",
      "3                2.296674            90.736427             1.525299   \n",
      "4                2.444379            43.790324             8.192344   \n",
      "...                   ...                  ...                  ...   \n",
      "9284             2.043751            50.168189             2.087319   \n",
      "9285             2.680248            71.890933             6.300943   \n",
      "9286             2.841850            42.432092             3.067061   \n",
      "9287             1.833254            59.854797             1.563420   \n",
      "9288             3.972233            57.434166             2.693097   \n",
      "\n",
      "      V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  V2AJ02a2_lgb2d_pred  \\\n",
      "0              18.961968             2.754658            63.037137   \n",
      "1              20.286149             2.416844            49.319974   \n",
      "2              20.107628             3.345272            38.226144   \n",
      "3              16.330709             1.813485            78.931292   \n",
      "4              21.933615             2.172912            40.705117   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           20.855105             3.576788            38.910415   \n",
      "9285           21.007826             3.359234            50.207090   \n",
      "9286           23.000871             3.215336            45.951801   \n",
      "9287           23.781733             3.647880            32.424894   \n",
      "9288           19.803796             3.368538            55.816223   \n",
      "\n",
      "      V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  V2BA02b1_lgb2d_pred  \\\n",
      "0               161.644659           100.785484            61.774390   \n",
      "1               150.947813           102.647583            58.609529   \n",
      "2               131.314817           108.420168            63.038783   \n",
      "3               193.116653           116.524543            68.382805   \n",
      "4               140.860778           106.971071            66.149402   \n",
      "...                    ...                  ...                  ...   \n",
      "9284            180.517324           114.790563            66.608928   \n",
      "9285            127.727895           112.811574            64.669460   \n",
      "9286            160.503398           118.191889            68.502210   \n",
      "9287            135.668325           102.198770            63.654537   \n",
      "9288            190.366771           106.100940            65.922997   \n",
      "\n",
      "      V2IA01_lgb2d_pred  \n",
      "0              3.036417  \n",
      "1              3.882161  \n",
      "2              4.118505  \n",
      "3              4.262279  \n",
      "4              4.890651  \n",
      "...                 ...  \n",
      "9284           3.697524  \n",
      "9285           4.715301  \n",
      "9286           4.362666  \n",
      "9287           4.224547  \n",
      "9288           4.699057  \n",
      "\n",
      "[9289 rows x 21 columns]\n",
      "lgb2d.csv (9289, 21)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "611/654 V2IA02 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8656, 4271) (633, 4271)\n",
      "(8656, 653) (8656,) (633, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.1921\n",
      "Blended average after 1 repeats: 0.1921\n",
      "78.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=0.0001, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.1917\n",
      "Blended average after 2 repeats: 0.1893\n",
      "155.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, max_depth=3,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=10, reg_lambda=0.001,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1921\n",
      "Blended average after 3 repeats: 0.1889\n",
      "231.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=100, reg_alpha=1,\n",
      "              reg_lambda=0.001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1919\n",
      "Blended average after 4 repeats: 0.1884\n",
      "308.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.1, reg_lambda=0.1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1920\n",
      "Blended average after 5 repeats: 0.1884\n",
      "387.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=4,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=1, reg_lambda=1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1918\n",
      "Blended average after 6 repeats: 0.1880\n",
      "471.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=20,\n",
      "              reg_alpha=10, reg_lambda=0.0001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1920\n",
      "Blended average after 7 repeats: 0.1881\n",
      "535.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, max_depth=7,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=50, num_leaves=30, reg_alpha=0, reg_lambda=1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2IA13         73.020408\n",
      "V2IA01         46.653061\n",
      "PctFedPoverty  38.714286\n",
      "V2AF13         31.918367\n",
      "V1GA02         31.081633\n",
      "V1GA10         27.877551\n",
      "V2IA04         25.265306\n",
      "V2IA03         23.306122\n",
      "CLAA01c        22.204082\n",
      "V1GA01         21.959184\n",
      "             gain\n",
      "feature          \n",
      "S02G02        0.0\n",
      "V1HVer        0.0\n",
      "V1AE2_04g_1   0.0\n",
      "S02G08        0.0\n",
      "S01A12        0.0\n",
      "V2AF08h       0.0\n",
      "V2BA01a       0.0\n",
      "V1AF15g       0.0\n",
      "V2AF08d       0.0\n",
      "S02G07        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2AJ01a2_lgb2d_pred  V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  \\\n",
      "0               42.558226             4.418429           18.961968   \n",
      "1               43.014995             2.552967           20.286149   \n",
      "2               44.404508             0.898839           20.107628   \n",
      "3               90.736427             1.525299           16.330709   \n",
      "4               43.790324             8.192344           21.933615   \n",
      "...                   ...                  ...                 ...   \n",
      "9284            50.168189             2.087319           20.855105   \n",
      "9285            71.890933             6.300943           21.007826   \n",
      "9286            42.432092             3.067061           23.000871   \n",
      "9287            59.854797             1.563420           23.781733   \n",
      "9288            57.434166             2.693097           19.803796   \n",
      "\n",
      "      V2AJ02a1_lgb2d_pred  V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  \\\n",
      "0                2.754658            63.037137            161.644659   \n",
      "1                2.416844            49.319974            150.947813   \n",
      "2                3.345272            38.226144            131.314817   \n",
      "3                1.813485            78.931292            193.116653   \n",
      "4                2.172912            40.705117            140.860778   \n",
      "...                   ...                  ...                   ...   \n",
      "9284             3.576788            38.910415            180.517324   \n",
      "9285             3.359234            50.207090            127.727895   \n",
      "9286             3.215336            45.951801            160.503398   \n",
      "9287             3.647880            32.424894            135.668325   \n",
      "9288             3.368538            55.816223            190.366771   \n",
      "\n",
      "      V2BA02a1_lgb2d_pred  V2BA02b1_lgb2d_pred  V2IA01_lgb2d_pred  \\\n",
      "0              100.785484            61.774390           3.036417   \n",
      "1              102.647583            58.609529           3.882161   \n",
      "2              108.420168            63.038783           4.118505   \n",
      "3              116.524543            68.382805           4.262279   \n",
      "4              106.971071            66.149402           4.890651   \n",
      "...                   ...                  ...                ...   \n",
      "9284           114.790563            66.608928           3.697524   \n",
      "9285           112.811574            64.669460           4.715301   \n",
      "9286           118.191889            68.502210           4.362666   \n",
      "9287           102.198770            63.654537           4.224547   \n",
      "9288           106.100940            65.922997           4.699057   \n",
      "\n",
      "      V2IA02_lgb2d_pred  \n",
      "0              2.918163  \n",
      "1              4.978659  \n",
      "2              4.937928  \n",
      "3              4.924633  \n",
      "4              5.047626  \n",
      "...                 ...  \n",
      "9284           4.831342  \n",
      "9285           4.940687  \n",
      "9286           4.610934  \n",
      "9287           4.965388  \n",
      "9288           4.966213  \n",
      "\n",
      "[9289 rows x 22 columns]\n",
      "lgb2d.csv (9289, 22)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "612/654 V2IA03 5 0.070\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8642, 4271) (647, 4271)\n",
      "(8642, 653) (8642,) (647, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.9255\n",
      "Blended average after 1 repeats: 0.9255\n",
      "75.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=20, reg_alpha=1, reg_lambda=1e-05,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.9251\n",
      "Blended average after 2 repeats: 0.9182\n",
      "159.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=30,\n",
      "              reg_alpha=0.1, reg_lambda=0.01, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.9263\n",
      "Blended average after 3 repeats: 0.9171\n",
      "238.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=30, reg_alpha=0,\n",
      "              reg_lambda=0.0001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.9269\n",
      "Blended average after 4 repeats: 0.9159\n",
      "313.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=350, num_leaves=20,\n",
      "              reg_alpha=0, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.9259\n",
      "Blended average after 5 repeats: 0.9145\n",
      "387.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.9267\n",
      "Blended average after 6 repeats: 0.9147\n",
      "465.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=20, reg_alpha=0.001, reg_lambda=0.0001, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.9271\n",
      "Blended average after 7 repeats: 0.9146\n",
      "532.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=10, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2IA09         88.510204\n",
      "V2IA21         30.346939\n",
      "V2AF13         26.591837\n",
      "CLAA01c        26.265306\n",
      "CLAB02g1b      25.448980\n",
      "CLAA01d        24.918367\n",
      "PctFedPoverty  24.836735\n",
      "S01B01         23.285714\n",
      "CLAE02a1       22.755102\n",
      "U02B03         22.489796\n",
      "           gain\n",
      "feature        \n",
      "S02ECheck   0.0\n",
      "S02G01      0.0\n",
      "S02G02      0.0\n",
      "S02G03      0.0\n",
      "S02G04      0.0\n",
      "S02G05      0.0\n",
      "V2AF08h     0.0\n",
      "V2AF08g     0.0\n",
      "V2AF08e     0.0\n",
      "V1AF15f     0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2AJ01a3_lgb2d_pred  V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  \\\n",
      "0                4.418429           18.961968             2.754658   \n",
      "1                2.552967           20.286149             2.416844   \n",
      "2                0.898839           20.107628             3.345272   \n",
      "3                1.525299           16.330709             1.813485   \n",
      "4                8.192344           21.933615             2.172912   \n",
      "...                   ...                 ...                  ...   \n",
      "9284             2.087319           20.855105             3.576788   \n",
      "9285             6.300943           21.007826             3.359234   \n",
      "9286             3.067061           23.000871             3.215336   \n",
      "9287             1.563420           23.781733             3.647880   \n",
      "9288             2.693097           19.803796             3.368538   \n",
      "\n",
      "      V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  \\\n",
      "0               63.037137            161.644659           100.785484   \n",
      "1               49.319974            150.947813           102.647583   \n",
      "2               38.226144            131.314817           108.420168   \n",
      "3               78.931292            193.116653           116.524543   \n",
      "4               40.705117            140.860778           106.971071   \n",
      "...                   ...                   ...                  ...   \n",
      "9284            38.910415            180.517324           114.790563   \n",
      "9285            50.207090            127.727895           112.811574   \n",
      "9286            45.951801            160.503398           118.191889   \n",
      "9287            32.424894            135.668325           102.198770   \n",
      "9288            55.816223            190.366771           106.100940   \n",
      "\n",
      "      V2BA02b1_lgb2d_pred  V2IA01_lgb2d_pred  V2IA02_lgb2d_pred  \\\n",
      "0               61.774390           3.036417           2.918163   \n",
      "1               58.609529           3.882161           4.978659   \n",
      "2               63.038783           4.118505           4.937928   \n",
      "3               68.382805           4.262279           4.924633   \n",
      "4               66.149402           4.890651           5.047626   \n",
      "...                   ...                ...                ...   \n",
      "9284            66.608928           3.697524           4.831342   \n",
      "9285            64.669460           4.715301           4.940687   \n",
      "9286            68.502210           4.362666           4.610934   \n",
      "9287            63.654537           4.224547           4.965388   \n",
      "9288            65.922997           4.699057           4.966213   \n",
      "\n",
      "      V2IA03_lgb2d_pred  \n",
      "0              3.719502  \n",
      "1              5.010279  \n",
      "2              3.112699  \n",
      "3              3.734532  \n",
      "4              4.069099  \n",
      "...                 ...  \n",
      "9284           4.633503  \n",
      "9285           4.511489  \n",
      "9286           3.301859  \n",
      "9287           3.865428  \n",
      "9288           4.382140  \n",
      "\n",
      "[9289 rows x 23 columns]\n",
      "lgb2d.csv (9289, 23)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "613/654 V2IA04 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8656, 4271) (633, 4271)\n",
      "(8656, 653) (8656,) (633, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2678\n",
      "Blended average after 1 repeats: 0.2678\n",
      "72.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=0.01, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2675\n",
      "Blended average after 2 repeats: 0.2660\n",
      "151.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=100, reg_alpha=0.1,\n",
      "              reg_lambda=0.0001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2676\n",
      "Blended average after 3 repeats: 0.2655\n",
      "229.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=30, reg_alpha=1, reg_lambda=100,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2678\n",
      "Blended average after 4 repeats: 0.2655\n",
      "306.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=0.01, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2675\n",
      "Blended average after 5 repeats: 0.2651\n",
      "370.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=100, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2676\n",
      "Blended average after 6 repeats: 0.2651\n",
      "443.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=20, reg_alpha=10,\n",
      "              reg_lambda=1e-05, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2676\n",
      "Blended average after 7 repeats: 0.2649\n",
      "531.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=4,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0.01,\n",
      "              reg_lambda=0.0001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA05   50.102041\n",
      "V2IA01   40.938776\n",
      "V2IA14   38.000000\n",
      "V2IA19   36.163265\n",
      "V2IA08   32.367347\n",
      "V2IA07   29.489796\n",
      "V2IA06   27.836735\n",
      "V1AH06   19.489796\n",
      "V2IA17   18.755102\n",
      "CLAA01d  18.183673\n",
      "         gain\n",
      "feature      \n",
      "V2AF25h   0.0\n",
      "S01A01    0.0\n",
      "V1AD13    0.0\n",
      "V1CVer    0.0\n",
      "V2AF22h   0.0\n",
      "S01B03d   0.0\n",
      "V1LF02    0.0\n",
      "V2AF18i   0.0\n",
      "V1AF12f   0.0\n",
      "V1KVer    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2AJ02a_lgb2d_pred  V2AJ02a1_lgb2d_pred  V2AJ02a2_lgb2d_pred  \\\n",
      "0              18.961968             2.754658            63.037137   \n",
      "1              20.286149             2.416844            49.319974   \n",
      "2              20.107628             3.345272            38.226144   \n",
      "3              16.330709             1.813485            78.931292   \n",
      "4              21.933615             2.172912            40.705117   \n",
      "...                  ...                  ...                  ...   \n",
      "9284           20.855105             3.576788            38.910415   \n",
      "9285           21.007826             3.359234            50.207090   \n",
      "9286           23.000871             3.215336            45.951801   \n",
      "9287           23.781733             3.647880            32.424894   \n",
      "9288           19.803796             3.368538            55.816223   \n",
      "\n",
      "      V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  V2BA02b1_lgb2d_pred  \\\n",
      "0               161.644659           100.785484            61.774390   \n",
      "1               150.947813           102.647583            58.609529   \n",
      "2               131.314817           108.420168            63.038783   \n",
      "3               193.116653           116.524543            68.382805   \n",
      "4               140.860778           106.971071            66.149402   \n",
      "...                    ...                  ...                  ...   \n",
      "9284            180.517324           114.790563            66.608928   \n",
      "9285            127.727895           112.811574            64.669460   \n",
      "9286            160.503398           118.191889            68.502210   \n",
      "9287            135.668325           102.198770            63.654537   \n",
      "9288            190.366771           106.100940            65.922997   \n",
      "\n",
      "      V2IA01_lgb2d_pred  V2IA02_lgb2d_pred  V2IA03_lgb2d_pred  \\\n",
      "0              3.036417           2.918163           3.719502   \n",
      "1              3.882161           4.978659           5.010279   \n",
      "2              4.118505           4.937928           3.112699   \n",
      "3              4.262279           4.924633           3.734532   \n",
      "4              4.890651           5.047626           4.069099   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.697524           4.831342           4.633503   \n",
      "9285           4.715301           4.940687           4.511489   \n",
      "9286           4.362666           4.610934           3.301859   \n",
      "9287           4.224547           4.965388           3.865428   \n",
      "9288           4.699057           4.966213           4.382140   \n",
      "\n",
      "      V2IA04_lgb2d_pred  \n",
      "0              3.278697  \n",
      "1              3.675114  \n",
      "2              4.021090  \n",
      "3              4.207852  \n",
      "4              4.910450  \n",
      "...                 ...  \n",
      "9284           3.671506  \n",
      "9285           4.843465  \n",
      "9286           4.149942  \n",
      "9287           4.002529  \n",
      "9288           4.763078  \n",
      "\n",
      "[9289 rows x 24 columns]\n",
      "lgb2d.csv (9289, 24)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "614/654 V2IA05 5 0.069\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8648, 4271) (641, 4271)\n",
      "(8648, 653) (8648,) (641, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2627\n",
      "Blended average after 1 repeats: 0.2627\n",
      "86.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.07, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=350,\n",
      "              num_leaves=50, reg_alpha=10, reg_lambda=0.1, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2616\n",
      "Blended average after 2 repeats: 0.2593\n",
      "162.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=30, reg_alpha=0.1, reg_lambda=0,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2608\n",
      "Blended average after 3 repeats: 0.2578\n",
      "253.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=100, reg_alpha=1,\n",
      "              reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2609\n",
      "Blended average after 4 repeats: 0.2577\n",
      "330.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=50, reg_alpha=1,\n",
      "              reg_lambda=1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2607\n",
      "Blended average after 5 repeats: 0.2573\n",
      "408.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=0.001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2608\n",
      "Blended average after 6 repeats: 0.2571\n",
      "481.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=20, reg_alpha=1, reg_lambda=100,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2607\n",
      "Blended average after 7 repeats: 0.2569\n",
      "552.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, max_depth=4,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=50, num_leaves=50, reg_alpha=0.1, reg_lambda=0.0001,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2IA04         60.081633\n",
      "V2IA06         53.265306\n",
      "V2IA07         43.081633\n",
      "V2IA01         31.285714\n",
      "V2IA25         29.040816\n",
      "V2IA21         23.163265\n",
      "V2IA11         22.428571\n",
      "PctFedPoverty  21.693878\n",
      "V1AI01a2       21.040816\n",
      "CLAA01c        20.755102\n",
      "             gain\n",
      "feature          \n",
      "S02G04        0.0\n",
      "S01A01        0.0\n",
      "V1AF12f       0.0\n",
      "S02G03        0.0\n",
      "V1KA03_AMPM   0.0\n",
      "S02G02        0.0\n",
      "S02Ver        0.0\n",
      "V1AF07f       0.0\n",
      "S02G01        0.0\n",
      "S02G06        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2AJ02a1_lgb2d_pred  V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  \\\n",
      "0                2.754658            63.037137            161.644659   \n",
      "1                2.416844            49.319974            150.947813   \n",
      "2                3.345272            38.226144            131.314817   \n",
      "3                1.813485            78.931292            193.116653   \n",
      "4                2.172912            40.705117            140.860778   \n",
      "...                   ...                  ...                   ...   \n",
      "9284             3.576788            38.910415            180.517324   \n",
      "9285             3.359234            50.207090            127.727895   \n",
      "9286             3.215336            45.951801            160.503398   \n",
      "9287             3.647880            32.424894            135.668325   \n",
      "9288             3.368538            55.816223            190.366771   \n",
      "\n",
      "      V2BA02a1_lgb2d_pred  V2BA02b1_lgb2d_pred  V2IA01_lgb2d_pred  \\\n",
      "0              100.785484            61.774390           3.036417   \n",
      "1              102.647583            58.609529           3.882161   \n",
      "2              108.420168            63.038783           4.118505   \n",
      "3              116.524543            68.382805           4.262279   \n",
      "4              106.971071            66.149402           4.890651   \n",
      "...                   ...                  ...                ...   \n",
      "9284           114.790563            66.608928           3.697524   \n",
      "9285           112.811574            64.669460           4.715301   \n",
      "9286           118.191889            68.502210           4.362666   \n",
      "9287           102.198770            63.654537           4.224547   \n",
      "9288           106.100940            65.922997           4.699057   \n",
      "\n",
      "      V2IA02_lgb2d_pred  V2IA03_lgb2d_pred  V2IA04_lgb2d_pred  \\\n",
      "0              2.918163           3.719502           3.278697   \n",
      "1              4.978659           5.010279           3.675114   \n",
      "2              4.937928           3.112699           4.021090   \n",
      "3              4.924633           3.734532           4.207852   \n",
      "4              5.047626           4.069099           4.910450   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.831342           4.633503           3.671506   \n",
      "9285           4.940687           4.511489           4.843465   \n",
      "9286           4.610934           3.301859           4.149942   \n",
      "9287           4.965388           3.865428           4.002529   \n",
      "9288           4.966213           4.382140           4.763078   \n",
      "\n",
      "      V2IA05_lgb2d_pred  \n",
      "0              3.035380  \n",
      "1              4.119606  \n",
      "2              4.326744  \n",
      "3              4.434909  \n",
      "4              5.017999  \n",
      "...                 ...  \n",
      "9284           3.875935  \n",
      "9285           4.968398  \n",
      "9286           4.565734  \n",
      "9287           4.199377  \n",
      "9288           5.005424  \n",
      "\n",
      "[9289 rows x 25 columns]\n",
      "lgb2d.csv (9289, 25)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "615/654 V2IA06 5 0.069\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8652, 4271) (637, 4271)\n",
      "(8652, 653) (8652,) (637, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4909\n",
      "Blended average after 1 repeats: 0.4909\n",
      "79.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, max_depth=2, min_child_samples=7,\n",
      "              min_child_weight=0, min_split_gain=0.1, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=0.1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4921\n",
      "Blended average after 2 repeats: 0.4898\n",
      "144.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.001, reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4917\n",
      "Blended average after 3 repeats: 0.4888\n",
      "219.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=50, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4910\n",
      "Blended average after 4 repeats: 0.4879\n",
      "281.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.1, reg_lambda=0.0001,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4911\n",
      "Blended average after 5 repeats: 0.4879\n",
      "353.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, max_depth=2, min_child_samples=10,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=225,\n",
      "              num_leaves=20, reg_alpha=10, reg_lambda=1, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4913\n",
      "Blended average after 6 repeats: 0.4877\n",
      "424.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4913\n",
      "Blended average after 7 repeats: 0.4874\n",
      "504.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=50, reg_alpha=0.1,\n",
      "              reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA07   48.795918\n",
      "V2IA05   24.346939\n",
      "V2IA01   21.204082\n",
      "V2IA20   20.653061\n",
      "V2IA19   16.428571\n",
      "V2IA23   15.448980\n",
      "V2IA12   15.265306\n",
      "V2IA04   15.122449\n",
      "V2IA14   14.040816\n",
      "V1CA01   13.428571\n",
      "           gain\n",
      "feature        \n",
      "V2AF08c     0.0\n",
      "S01B05      0.0\n",
      "V2AF05h     0.0\n",
      "V2AF05g     0.0\n",
      "V2AF05e     0.0\n",
      "V2AF05d     0.0\n",
      "V2AF05c     0.0\n",
      "S01BCheck   0.0\n",
      "U02C02      0.0\n",
      "S02G04      0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2AJ02a2_lgb2d_pred  V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  \\\n",
      "0               63.037137            161.644659           100.785484   \n",
      "1               49.319974            150.947813           102.647583   \n",
      "2               38.226144            131.314817           108.420168   \n",
      "3               78.931292            193.116653           116.524543   \n",
      "4               40.705117            140.860778           106.971071   \n",
      "...                   ...                   ...                  ...   \n",
      "9284            38.910415            180.517324           114.790563   \n",
      "9285            50.207090            127.727895           112.811574   \n",
      "9286            45.951801            160.503398           118.191889   \n",
      "9287            32.424894            135.668325           102.198770   \n",
      "9288            55.816223            190.366771           106.100940   \n",
      "\n",
      "      V2BA02b1_lgb2d_pred  V2IA01_lgb2d_pred  V2IA02_lgb2d_pred  \\\n",
      "0               61.774390           3.036417           2.918163   \n",
      "1               58.609529           3.882161           4.978659   \n",
      "2               63.038783           4.118505           4.937928   \n",
      "3               68.382805           4.262279           4.924633   \n",
      "4               66.149402           4.890651           5.047626   \n",
      "...                   ...                ...                ...   \n",
      "9284            66.608928           3.697524           4.831342   \n",
      "9285            64.669460           4.715301           4.940687   \n",
      "9286            68.502210           4.362666           4.610934   \n",
      "9287            63.654537           4.224547           4.965388   \n",
      "9288            65.922997           4.699057           4.966213   \n",
      "\n",
      "      V2IA03_lgb2d_pred  V2IA04_lgb2d_pred  V2IA05_lgb2d_pred  \\\n",
      "0              3.719502           3.278697           3.035380   \n",
      "1              5.010279           3.675114           4.119606   \n",
      "2              3.112699           4.021090           4.326744   \n",
      "3              3.734532           4.207852           4.434909   \n",
      "4              4.069099           4.910450           5.017999   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.633503           3.671506           3.875935   \n",
      "9285           4.511489           4.843465           4.968398   \n",
      "9286           3.301859           4.149942           4.565734   \n",
      "9287           3.865428           4.002529           4.199377   \n",
      "9288           4.382140           4.763078           5.005424   \n",
      "\n",
      "      V2IA06_lgb2d_pred  \n",
      "0              3.508593  \n",
      "1              3.197629  \n",
      "2              3.954662  \n",
      "3              4.060576  \n",
      "4              4.620653  \n",
      "...                 ...  \n",
      "9284           3.528829  \n",
      "9285           4.791448  \n",
      "9286           4.028005  \n",
      "9287           3.744032  \n",
      "9288           4.491417  \n",
      "\n",
      "[9289 rows x 26 columns]\n",
      "lgb2d.csv (9289, 26)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "616/654 V2IA07 5 0.069\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8651, 4271) (638, 4271)\n",
      "(8651, 653) (8651,) (638, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4231\n",
      "Blended average after 1 repeats: 0.4231\n",
      "85.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=0.1, reg_lambda=0.0001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4232\n",
      "Blended average after 2 repeats: 0.4214\n",
      "165.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4232\n",
      "Blended average after 3 repeats: 0.4208\n",
      "242.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=4, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=150, num_leaves=50, reg_alpha=10, reg_lambda=0.01,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4235\n",
      "Blended average after 4 repeats: 0.4207\n",
      "314.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0,\n",
      "              num_leaves=50, reg_alpha=0.001, reg_lambda=0.1, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4237\n",
      "Blended average after 5 repeats: 0.4205\n",
      "388.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=2,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=50, num_leaves=30, reg_alpha=0.1, reg_lambda=1e-05,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4237\n",
      "Blended average after 6 repeats: 0.4203\n",
      "462.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=50, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=0.01, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4236\n",
      "Blended average after 7 repeats: 0.4203\n",
      "537.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=50, reg_alpha=0.1,\n",
      "              reg_lambda=0.0001, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA06   51.346939\n",
      "V2IA08   38.061224\n",
      "V2IA09   29.367347\n",
      "V2IA20   25.836735\n",
      "V2IA05   21.285714\n",
      "V2IA23   19.591837\n",
      "V2IA04   16.755102\n",
      "V2IA03   16.734694\n",
      "V2IA01   16.653061\n",
      "V2IA19   14.673469\n",
      "         gain\n",
      "feature      \n",
      "S02E04    0.0\n",
      "V2AF25e   0.0\n",
      "S02E02    0.0\n",
      "V2AF25c   0.0\n",
      "S01A12    0.0\n",
      "V2AF22h   0.0\n",
      "V1LF01a   0.0\n",
      "V2AF22e   0.0\n",
      "V1LF02    0.0\n",
      "V1AF06g   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2BA01_LB_lgb2d_pred  V2BA02a1_lgb2d_pred  V2BA02b1_lgb2d_pred  \\\n",
      "0               161.644659           100.785484            61.774390   \n",
      "1               150.947813           102.647583            58.609529   \n",
      "2               131.314817           108.420168            63.038783   \n",
      "3               193.116653           116.524543            68.382805   \n",
      "4               140.860778           106.971071            66.149402   \n",
      "...                    ...                  ...                  ...   \n",
      "9284            180.517324           114.790563            66.608928   \n",
      "9285            127.727895           112.811574            64.669460   \n",
      "9286            160.503398           118.191889            68.502210   \n",
      "9287            135.668325           102.198770            63.654537   \n",
      "9288            190.366771           106.100940            65.922997   \n",
      "\n",
      "      V2IA01_lgb2d_pred  V2IA02_lgb2d_pred  V2IA03_lgb2d_pred  \\\n",
      "0              3.036417           2.918163           3.719502   \n",
      "1              3.882161           4.978659           5.010279   \n",
      "2              4.118505           4.937928           3.112699   \n",
      "3              4.262279           4.924633           3.734532   \n",
      "4              4.890651           5.047626           4.069099   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.697524           4.831342           4.633503   \n",
      "9285           4.715301           4.940687           4.511489   \n",
      "9286           4.362666           4.610934           3.301859   \n",
      "9287           4.224547           4.965388           3.865428   \n",
      "9288           4.699057           4.966213           4.382140   \n",
      "\n",
      "      V2IA04_lgb2d_pred  V2IA05_lgb2d_pred  V2IA06_lgb2d_pred  \\\n",
      "0              3.278697           3.035380           3.508593   \n",
      "1              3.675114           4.119606           3.197629   \n",
      "2              4.021090           4.326744           3.954662   \n",
      "3              4.207852           4.434909           4.060576   \n",
      "4              4.910450           5.017999           4.620653   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.671506           3.875935           3.528829   \n",
      "9285           4.843465           4.968398           4.791448   \n",
      "9286           4.149942           4.565734           4.028005   \n",
      "9287           4.002529           4.199377           3.744032   \n",
      "9288           4.763078           5.005424           4.491417   \n",
      "\n",
      "      V2IA07_lgb2d_pred  \n",
      "0              2.727299  \n",
      "1              3.721817  \n",
      "2              3.761251  \n",
      "3              3.937103  \n",
      "4              4.713279  \n",
      "...                 ...  \n",
      "9284           3.707253  \n",
      "9285           4.744238  \n",
      "9286           3.881843  \n",
      "9287           3.509662  \n",
      "9288           4.562553  \n",
      "\n",
      "[9289 rows x 27 columns]\n",
      "lgb2d.csv (9289, 27)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "617/654 V2IA08 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8653, 4271) (636, 4271)\n",
      "(8653, 653) (8653,) (636, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3946\n",
      "Blended average after 1 repeats: 0.3946\n",
      "72.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=1,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=150, num_leaves=50, reg_alpha=1, reg_lambda=0.001,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3940\n",
      "Blended average after 2 repeats: 0.3912\n",
      "158.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=2, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.1, reg_lambda=0.1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3934\n",
      "Blended average after 3 repeats: 0.3897\n",
      "233.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30, reg_alpha=0.01,\n",
      "              reg_lambda=0.1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3935\n",
      "Blended average after 4 repeats: 0.3894\n",
      "314.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.1, reg_lambda=100, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3939\n",
      "Blended average after 5 repeats: 0.3893\n",
      "387.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.07, max_depth=2,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=0.01, reg_lambda=10,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3943\n",
      "Blended average after 6 repeats: 0.3894\n",
      "477.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=1, reg_lambda=0.01, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3942\n",
      "Blended average after 7 repeats: 0.3892\n",
      "552.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, max_depth=2,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=0, reg_lambda=10,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                    gain\n",
      "feature                 \n",
      "V2IA07         47.979592\n",
      "V1AF09         40.510204\n",
      "V2IA01         34.816327\n",
      "V2IA09         33.693878\n",
      "V2AF20         31.387755\n",
      "V2IA19         30.673469\n",
      "V2IA04         27.040816\n",
      "PctFedPoverty  24.204082\n",
      "CLAE02a1       19.387755\n",
      "V2IA17         18.897959\n",
      "         gain\n",
      "feature      \n",
      "S02Ver    0.0\n",
      "S02H01    0.0\n",
      "S02G14    0.0\n",
      "S02G13    0.0\n",
      "S01A04    0.0\n",
      "S01A05    0.0\n",
      "S02G12    0.0\n",
      "S01A06    0.0\n",
      "V1LVer    0.0\n",
      "V2AF08e   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2BA02a1_lgb2d_pred  V2BA02b1_lgb2d_pred  V2IA01_lgb2d_pred  \\\n",
      "0              100.785484            61.774390           3.036417   \n",
      "1              102.647583            58.609529           3.882161   \n",
      "2              108.420168            63.038783           4.118505   \n",
      "3              116.524543            68.382805           4.262279   \n",
      "4              106.971071            66.149402           4.890651   \n",
      "...                   ...                  ...                ...   \n",
      "9284           114.790563            66.608928           3.697524   \n",
      "9285           112.811574            64.669460           4.715301   \n",
      "9286           118.191889            68.502210           4.362666   \n",
      "9287           102.198770            63.654537           4.224547   \n",
      "9288           106.100940            65.922997           4.699057   \n",
      "\n",
      "      V2IA02_lgb2d_pred  V2IA03_lgb2d_pred  V2IA04_lgb2d_pred  \\\n",
      "0              2.918163           3.719502           3.278697   \n",
      "1              4.978659           5.010279           3.675114   \n",
      "2              4.937928           3.112699           4.021090   \n",
      "3              4.924633           3.734532           4.207852   \n",
      "4              5.047626           4.069099           4.910450   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.831342           4.633503           3.671506   \n",
      "9285           4.940687           4.511489           4.843465   \n",
      "9286           4.610934           3.301859           4.149942   \n",
      "9287           4.965388           3.865428           4.002529   \n",
      "9288           4.966213           4.382140           4.763078   \n",
      "\n",
      "      V2IA05_lgb2d_pred  V2IA06_lgb2d_pred  V2IA07_lgb2d_pred  \\\n",
      "0              3.035380           3.508593           2.727299   \n",
      "1              4.119606           3.197629           3.721817   \n",
      "2              4.326744           3.954662           3.761251   \n",
      "3              4.434909           4.060576           3.937103   \n",
      "4              5.017999           4.620653           4.713279   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.875935           3.528829           3.707253   \n",
      "9285           4.968398           4.791448           4.744238   \n",
      "9286           4.565734           4.028005           3.881843   \n",
      "9287           4.199377           3.744032           3.509662   \n",
      "9288           5.005424           4.491417           4.562553   \n",
      "\n",
      "      V2IA08_lgb2d_pred  \n",
      "0              3.021008  \n",
      "1              3.719616  \n",
      "2              4.098253  \n",
      "3              4.268814  \n",
      "4              4.995779  \n",
      "...                 ...  \n",
      "9284           3.952086  \n",
      "9285           4.760661  \n",
      "9286           4.231556  \n",
      "9287           4.241605  \n",
      "9288           4.540123  \n",
      "\n",
      "[9289 rows x 28 columns]\n",
      "lgb2d.csv (9289, 28)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "618/654 V2IA09 5 0.069\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8649, 4271) (640, 4271)\n",
      "(8649, 653) (8649,) (640, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4981\n",
      "Blended average after 1 repeats: 0.4981\n",
      "72.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30, reg_alpha=0.1,\n",
      "              reg_lambda=0.1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.5015\n",
      "Blended average after 2 repeats: 0.4976\n",
      "152.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=6, min_child_weight=0, min_split_gain=0, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.5024\n",
      "Blended average after 3 repeats: 0.4969\n",
      "238.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=50, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.5020\n",
      "Blended average after 4 repeats: 0.4962\n",
      "314.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.01, reg_lambda=100,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.5018\n",
      "Blended average after 5 repeats: 0.4959\n",
      "389.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0, reg_lambda=0,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.5025\n",
      "Blended average after 6 repeats: 0.4961\n",
      "475.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.5025\n",
      "Blended average after 7 repeats: 0.4960\n",
      "550.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                 gain\n",
      "feature              \n",
      "V2IA03     103.102041\n",
      "V2IA20      61.979592\n",
      "V2IA10      40.918367\n",
      "V2IA08      39.265306\n",
      "V2IA07      39.163265\n",
      "V2IA21      26.795918\n",
      "CLAB01c     25.551020\n",
      "V1AF02      23.693878\n",
      "CLAA01d     21.795918\n",
      "V2AF12_YR   20.979592\n",
      "         gain\n",
      "feature      \n",
      "V1LF01a   0.0\n",
      "S02G09    0.0\n",
      "V1LVer    0.0\n",
      "V2AA01    0.0\n",
      "V2AF25h   0.0\n",
      "S02G12    0.0\n",
      "V2AF25e   0.0\n",
      "S02G11    0.0\n",
      "S01B05    0.0\n",
      "S02G10    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2BA02b1_lgb2d_pred  V2IA01_lgb2d_pred  V2IA02_lgb2d_pred  \\\n",
      "0               61.774390           3.036417           2.918163   \n",
      "1               58.609529           3.882161           4.978659   \n",
      "2               63.038783           4.118505           4.937928   \n",
      "3               68.382805           4.262279           4.924633   \n",
      "4               66.149402           4.890651           5.047626   \n",
      "...                   ...                ...                ...   \n",
      "9284            66.608928           3.697524           4.831342   \n",
      "9285            64.669460           4.715301           4.940687   \n",
      "9286            68.502210           4.362666           4.610934   \n",
      "9287            63.654537           4.224547           4.965388   \n",
      "9288            65.922997           4.699057           4.966213   \n",
      "\n",
      "      V2IA03_lgb2d_pred  V2IA04_lgb2d_pred  V2IA05_lgb2d_pred  \\\n",
      "0              3.719502           3.278697           3.035380   \n",
      "1              5.010279           3.675114           4.119606   \n",
      "2              3.112699           4.021090           4.326744   \n",
      "3              3.734532           4.207852           4.434909   \n",
      "4              4.069099           4.910450           5.017999   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.633503           3.671506           3.875935   \n",
      "9285           4.511489           4.843465           4.968398   \n",
      "9286           3.301859           4.149942           4.565734   \n",
      "9287           3.865428           4.002529           4.199377   \n",
      "9288           4.382140           4.763078           5.005424   \n",
      "\n",
      "      V2IA06_lgb2d_pred  V2IA07_lgb2d_pred  V2IA08_lgb2d_pred  \\\n",
      "0              3.508593           2.727299           3.021008   \n",
      "1              3.197629           3.721817           3.719616   \n",
      "2              3.954662           3.761251           4.098253   \n",
      "3              4.060576           3.937103           4.268814   \n",
      "4              4.620653           4.713279           4.995779   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.528829           3.707253           3.952086   \n",
      "9285           4.791448           4.744238           4.760661   \n",
      "9286           4.028005           3.881843           4.231556   \n",
      "9287           3.744032           3.509662           4.241605   \n",
      "9288           4.491417           4.562553           4.540123   \n",
      "\n",
      "      V2IA09_lgb2d_pred  \n",
      "0              3.569372  \n",
      "1              4.686346  \n",
      "2              4.183408  \n",
      "3              4.652390  \n",
      "4              4.875206  \n",
      "...                 ...  \n",
      "9284           4.301251  \n",
      "9285           4.672325  \n",
      "9286           3.149403  \n",
      "9287           4.234005  \n",
      "9288           4.822374  \n",
      "\n",
      "[9289 rows x 29 columns]\n",
      "lgb2d.csv (9289, 29)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "619/654 V2IA10 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8656, 4271) (633, 4271)\n",
      "(8656, 653) (8656,) (633, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2471\n",
      "Blended average after 1 repeats: 0.2471\n",
      "71.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2469\n",
      "Blended average after 2 repeats: 0.2454\n",
      "146.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.001, reg_lambda=100, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2470\n",
      "Blended average after 3 repeats: 0.2452\n",
      "221.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=1, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=1, reg_lambda=0.0001,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2470\n",
      "Blended average after 4 repeats: 0.2450\n",
      "295.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=100, reg_alpha=0.01, reg_lambda=0,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2469\n",
      "Blended average after 5 repeats: 0.2449\n",
      "360.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=50, reg_alpha=0.01, reg_lambda=1,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2466\n",
      "Blended average after 6 repeats: 0.2445\n",
      "438.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=10, reg_lambda=1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2466\n",
      "Blended average after 7 repeats: 0.2443\n",
      "514.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "               gain\n",
      "feature            \n",
      "V2IA11    57.857143\n",
      "V2IA09    48.795918\n",
      "V2IA24    36.183673\n",
      "V2IA12    29.081633\n",
      "V2IA14    24.714286\n",
      "V2IA25    19.734694\n",
      "CLAE02a1  17.244898\n",
      "V2IA02    16.122449\n",
      "V2IA05    15.673469\n",
      "CLAA01c   14.979592\n",
      "             gain\n",
      "feature          \n",
      "V1AF12i       0.0\n",
      "V2AF05h       0.0\n",
      "V2AF05g       0.0\n",
      "V2AF05e       0.0\n",
      "V1AE2_04f_1   0.0\n",
      "V1KA02_AMPM   0.0\n",
      "V2AF01g       0.0\n",
      "V2AF01f       0.0\n",
      "V2AF01e       0.0\n",
      "S02E04        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA01_lgb2d_pred  V2IA02_lgb2d_pred  V2IA03_lgb2d_pred  \\\n",
      "0              3.036417           2.918163           3.719502   \n",
      "1              3.882161           4.978659           5.010279   \n",
      "2              4.118505           4.937928           3.112699   \n",
      "3              4.262279           4.924633           3.734532   \n",
      "4              4.890651           5.047626           4.069099   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.697524           4.831342           4.633503   \n",
      "9285           4.715301           4.940687           4.511489   \n",
      "9286           4.362666           4.610934           3.301859   \n",
      "9287           4.224547           4.965388           3.865428   \n",
      "9288           4.699057           4.966213           4.382140   \n",
      "\n",
      "      V2IA04_lgb2d_pred  V2IA05_lgb2d_pred  V2IA06_lgb2d_pred  \\\n",
      "0              3.278697           3.035380           3.508593   \n",
      "1              3.675114           4.119606           3.197629   \n",
      "2              4.021090           4.326744           3.954662   \n",
      "3              4.207852           4.434909           4.060576   \n",
      "4              4.910450           5.017999           4.620653   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.671506           3.875935           3.528829   \n",
      "9285           4.843465           4.968398           4.791448   \n",
      "9286           4.149942           4.565734           4.028005   \n",
      "9287           4.002529           4.199377           3.744032   \n",
      "9288           4.763078           5.005424           4.491417   \n",
      "\n",
      "      V2IA07_lgb2d_pred  V2IA08_lgb2d_pred  V2IA09_lgb2d_pred  \\\n",
      "0              2.727299           3.021008           3.569372   \n",
      "1              3.721817           3.719616           4.686346   \n",
      "2              3.761251           4.098253           4.183408   \n",
      "3              3.937103           4.268814           4.652390   \n",
      "4              4.713279           4.995779           4.875206   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.707253           3.952086           4.301251   \n",
      "9285           4.744238           4.760661           4.672325   \n",
      "9286           3.881843           4.231556           3.149403   \n",
      "9287           3.509662           4.241605           4.234005   \n",
      "9288           4.562553           4.540123           4.822374   \n",
      "\n",
      "      V2IA10_lgb2d_pred  \n",
      "0              3.687051  \n",
      "1              4.149227  \n",
      "2              4.423756  \n",
      "3              4.655637  \n",
      "4              4.917108  \n",
      "...                 ...  \n",
      "9284           4.167568  \n",
      "9285           4.961264  \n",
      "9286           4.607412  \n",
      "9287           4.278653  \n",
      "9288           4.949376  \n",
      "\n",
      "[9289 rows x 30 columns]\n",
      "lgb2d.csv (9289, 30)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "620/654 V2IA11 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8654, 4271) (635, 4271)\n",
      "(8654, 653) (8654,) (635, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2031\n",
      "Blended average after 1 repeats: 0.2031\n",
      "70.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=30, reg_alpha=0, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2033\n",
      "Blended average after 2 repeats: 0.2019\n",
      "150.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=50, reg_alpha=0.001,\n",
      "              reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2033\n",
      "Blended average after 3 repeats: 0.2014\n",
      "218.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=20, reg_alpha=0.1, reg_lambda=0,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2036\n",
      "Blended average after 4 repeats: 0.2011\n",
      "295.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, max_depth=4, min_child_samples=2,\n",
      "              min_child_weight=0, min_split_gain=0.01, n_estimators=50,\n",
      "              num_leaves=30, reg_alpha=0.001, reg_lambda=0.0001, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2035\n",
      "Blended average after 5 repeats: 0.2009\n",
      "369.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=50, reg_alpha=10, reg_lambda=0,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2036\n",
      "Blended average after 6 repeats: 0.2008\n",
      "448.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.1, reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2038\n",
      "Blended average after 7 repeats: 0.2009\n",
      "529.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.05, max_depth=7,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "               gain\n",
      "feature            \n",
      "V2IA12    76.020408\n",
      "V2IA10    66.367347\n",
      "V2IA24    53.897959\n",
      "V2IA05    29.632653\n",
      "V2IA17    22.979592\n",
      "CLAA01d   22.979592\n",
      "V2IA21    22.795918\n",
      "CLAE02a1  22.755102\n",
      "V2IA09    22.142857\n",
      "V2IA25    21.448980\n",
      "             gain\n",
      "feature          \n",
      "V1AE2_05d_1   0.0\n",
      "V2AF25h       0.0\n",
      "S02H01        0.0\n",
      "S02G14        0.0\n",
      "S02G13        0.0\n",
      "S02G12        0.0\n",
      "V1AE2_04g_1   0.0\n",
      "S02G10        0.0\n",
      "V1GVer        0.0\n",
      "S02E02        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA02_lgb2d_pred  V2IA03_lgb2d_pred  V2IA04_lgb2d_pred  \\\n",
      "0              2.918163           3.719502           3.278697   \n",
      "1              4.978659           5.010279           3.675114   \n",
      "2              4.937928           3.112699           4.021090   \n",
      "3              4.924633           3.734532           4.207852   \n",
      "4              5.047626           4.069099           4.910450   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.831342           4.633503           3.671506   \n",
      "9285           4.940687           4.511489           4.843465   \n",
      "9286           4.610934           3.301859           4.149942   \n",
      "9287           4.965388           3.865428           4.002529   \n",
      "9288           4.966213           4.382140           4.763078   \n",
      "\n",
      "      V2IA05_lgb2d_pred  V2IA06_lgb2d_pred  V2IA07_lgb2d_pred  \\\n",
      "0              3.035380           3.508593           2.727299   \n",
      "1              4.119606           3.197629           3.721817   \n",
      "2              4.326744           3.954662           3.761251   \n",
      "3              4.434909           4.060576           3.937103   \n",
      "4              5.017999           4.620653           4.713279   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.875935           3.528829           3.707253   \n",
      "9285           4.968398           4.791448           4.744238   \n",
      "9286           4.565734           4.028005           3.881843   \n",
      "9287           4.199377           3.744032           3.509662   \n",
      "9288           5.005424           4.491417           4.562553   \n",
      "\n",
      "      V2IA08_lgb2d_pred  V2IA09_lgb2d_pred  V2IA10_lgb2d_pred  \\\n",
      "0              3.021008           3.569372           3.687051   \n",
      "1              3.719616           4.686346           4.149227   \n",
      "2              4.098253           4.183408           4.423756   \n",
      "3              4.268814           4.652390           4.655637   \n",
      "4              4.995779           4.875206           4.917108   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.952086           4.301251           4.167568   \n",
      "9285           4.760661           4.672325           4.961264   \n",
      "9286           4.231556           3.149403           4.607412   \n",
      "9287           4.241605           4.234005           4.278653   \n",
      "9288           4.540123           4.822374           4.949376   \n",
      "\n",
      "      V2IA11_lgb2d_pred  \n",
      "0              2.847031  \n",
      "1              4.555882  \n",
      "2              4.288550  \n",
      "3              4.709987  \n",
      "4              4.979695  \n",
      "...                 ...  \n",
      "9284           4.402781  \n",
      "9285           5.028767  \n",
      "9286           4.612361  \n",
      "9287           4.390432  \n",
      "9288           5.073425  \n",
      "\n",
      "[9289 rows x 31 columns]\n",
      "lgb2d.csv (9289, 31)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "621/654 V2IA12 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8656, 4271) (633, 4271)\n",
      "(8656, 653) (8656,) (633, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2689\n",
      "Blended average after 1 repeats: 0.2689\n",
      "70.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, max_depth=2,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=50, num_leaves=50, reg_alpha=0.1, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2686\n",
      "Blended average after 2 repeats: 0.2672\n",
      "155.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2688\n",
      "Blended average after 3 repeats: 0.2669\n",
      "233.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.5, max_depth=3,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.001,\n",
      "              num_leaves=100, reg_alpha=1, reg_lambda=1, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2693\n",
      "Blended average after 4 repeats: 0.2670\n",
      "306.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2692\n",
      "Blended average after 5 repeats: 0.2668\n",
      "378.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=7, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=50, num_leaves=20, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2692\n",
      "Blended average after 6 repeats: 0.2667\n",
      "460.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=10, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2692\n",
      "Blended average after 7 repeats: 0.2667\n",
      "541.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA11   46.714286\n",
      "V2IA16   31.530612\n",
      "V2IA10   26.816327\n",
      "V2IA14   26.163265\n",
      "V2IA13   23.836735\n",
      "V2IA06   22.959184\n",
      "V2IA24   22.183673\n",
      "V2IA09   15.959184\n",
      "V2IA07   15.224490\n",
      "V2IA17   14.510204\n",
      "         gain\n",
      "feature      \n",
      "V1AF15b   0.0\n",
      "V2AF22e   0.0\n",
      "S02H01    0.0\n",
      "S02D07    0.0\n",
      "V1AF12i   0.0\n",
      "V2AF18i   0.0\n",
      "V2AF18h   0.0\n",
      "S02E04    0.0\n",
      "S02G14    0.0\n",
      "U02C02    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA03_lgb2d_pred  V2IA04_lgb2d_pred  V2IA05_lgb2d_pred  \\\n",
      "0              3.719502           3.278697           3.035380   \n",
      "1              5.010279           3.675114           4.119606   \n",
      "2              3.112699           4.021090           4.326744   \n",
      "3              3.734532           4.207852           4.434909   \n",
      "4              4.069099           4.910450           5.017999   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.633503           3.671506           3.875935   \n",
      "9285           4.511489           4.843465           4.968398   \n",
      "9286           3.301859           4.149942           4.565734   \n",
      "9287           3.865428           4.002529           4.199377   \n",
      "9288           4.382140           4.763078           5.005424   \n",
      "\n",
      "      V2IA06_lgb2d_pred  V2IA07_lgb2d_pred  V2IA08_lgb2d_pred  \\\n",
      "0              3.508593           2.727299           3.021008   \n",
      "1              3.197629           3.721817           3.719616   \n",
      "2              3.954662           3.761251           4.098253   \n",
      "3              4.060576           3.937103           4.268814   \n",
      "4              4.620653           4.713279           4.995779   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.528829           3.707253           3.952086   \n",
      "9285           4.791448           4.744238           4.760661   \n",
      "9286           4.028005           3.881843           4.231556   \n",
      "9287           3.744032           3.509662           4.241605   \n",
      "9288           4.491417           4.562553           4.540123   \n",
      "\n",
      "      V2IA09_lgb2d_pred  V2IA10_lgb2d_pred  V2IA11_lgb2d_pred  \\\n",
      "0              3.569372           3.687051           2.847031   \n",
      "1              4.686346           4.149227           4.555882   \n",
      "2              4.183408           4.423756           4.288550   \n",
      "3              4.652390           4.655637           4.709987   \n",
      "4              4.875206           4.917108           4.979695   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.301251           4.167568           4.402781   \n",
      "9285           4.672325           4.961264           5.028767   \n",
      "9286           3.149403           4.607412           4.612361   \n",
      "9287           4.234005           4.278653           4.390432   \n",
      "9288           4.822374           4.949376           5.073425   \n",
      "\n",
      "      V2IA12_lgb2d_pred  \n",
      "0              3.641039  \n",
      "1              4.024508  \n",
      "2              4.470814  \n",
      "3              4.404192  \n",
      "4              4.897966  \n",
      "...                 ...  \n",
      "9284           3.847057  \n",
      "9285           4.767924  \n",
      "9286           4.527747  \n",
      "9287           3.917590  \n",
      "9288           5.014667  \n",
      "\n",
      "[9289 rows x 32 columns]\n",
      "lgb2d.csv (9289, 32)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "622/654 V2IA13 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8655, 4271) (634, 4271)\n",
      "(8655, 653) (8655,) (634, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2757\n",
      "Blended average after 1 repeats: 0.2757\n",
      "76.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, max_depth=2,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=1, reg_lambda=0,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2754\n",
      "Blended average after 2 repeats: 0.2736\n",
      "153.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2755\n",
      "Blended average after 3 repeats: 0.2730\n",
      "219.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=50, reg_alpha=1, reg_lambda=0.01,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2750\n",
      "Blended average after 4 repeats: 0.2721\n",
      "293.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=100, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2751\n",
      "Blended average after 5 repeats: 0.2720\n",
      "363.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=1, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2752\n",
      "Blended average after 6 repeats: 0.2719\n",
      "421.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.1, reg_lambda=0.0001, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2755\n",
      "Blended average after 7 repeats: 0.2721\n",
      "495.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=1, reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA02   49.591837\n",
      "V2IA14   47.591837\n",
      "V2IA21   31.224490\n",
      "V2IA12   27.510204\n",
      "V2IA22   21.469388\n",
      "V2IA11   20.142857\n",
      "V2IA03   19.795918\n",
      "V1AF09   18.612245\n",
      "V1GA04   17.081633\n",
      "V2IA05   15.204082\n",
      "             gain\n",
      "feature          \n",
      "V1KVer        0.0\n",
      "V2AF18i       0.0\n",
      "S01A01        0.0\n",
      "V1AF15b       0.0\n",
      "S02ECheck     0.0\n",
      "S02G01        0.0\n",
      "V1AE2_05d_1   0.0\n",
      "V2BVer        0.0\n",
      "V1AF12i       0.0\n",
      "V2AF01f       0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA04_lgb2d_pred  V2IA05_lgb2d_pred  V2IA06_lgb2d_pred  \\\n",
      "0              3.278697           3.035380           3.508593   \n",
      "1              3.675114           4.119606           3.197629   \n",
      "2              4.021090           4.326744           3.954662   \n",
      "3              4.207852           4.434909           4.060576   \n",
      "4              4.910450           5.017999           4.620653   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.671506           3.875935           3.528829   \n",
      "9285           4.843465           4.968398           4.791448   \n",
      "9286           4.149942           4.565734           4.028005   \n",
      "9287           4.002529           4.199377           3.744032   \n",
      "9288           4.763078           5.005424           4.491417   \n",
      "\n",
      "      V2IA07_lgb2d_pred  V2IA08_lgb2d_pred  V2IA09_lgb2d_pred  \\\n",
      "0              2.727299           3.021008           3.569372   \n",
      "1              3.721817           3.719616           4.686346   \n",
      "2              3.761251           4.098253           4.183408   \n",
      "3              3.937103           4.268814           4.652390   \n",
      "4              4.713279           4.995779           4.875206   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.707253           3.952086           4.301251   \n",
      "9285           4.744238           4.760661           4.672325   \n",
      "9286           3.881843           4.231556           3.149403   \n",
      "9287           3.509662           4.241605           4.234005   \n",
      "9288           4.562553           4.540123           4.822374   \n",
      "\n",
      "      V2IA10_lgb2d_pred  V2IA11_lgb2d_pred  V2IA12_lgb2d_pred  \\\n",
      "0              3.687051           2.847031           3.641039   \n",
      "1              4.149227           4.555882           4.024508   \n",
      "2              4.423756           4.288550           4.470814   \n",
      "3              4.655637           4.709987           4.404192   \n",
      "4              4.917108           4.979695           4.897966   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.167568           4.402781           3.847057   \n",
      "9285           4.961264           5.028767           4.767924   \n",
      "9286           4.607412           4.612361           4.527747   \n",
      "9287           4.278653           4.390432           3.917590   \n",
      "9288           4.949376           5.073425           5.014667   \n",
      "\n",
      "      V2IA13_lgb2d_pred  \n",
      "0              3.453735  \n",
      "1              4.535342  \n",
      "2              4.290469  \n",
      "3              4.736425  \n",
      "4              5.014496  \n",
      "...                 ...  \n",
      "9284           4.027162  \n",
      "9285           5.031926  \n",
      "9286           4.383056  \n",
      "9287           4.603074  \n",
      "9288           4.910660  \n",
      "\n",
      "[9289 rows x 33 columns]\n",
      "lgb2d.csv (9289, 33)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "623/654 V2IA14 5 0.068\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8655, 4271) (634, 4271)\n",
      "(8655, 653) (8655,) (634, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3636\n",
      "Blended average after 1 repeats: 0.3636\n",
      "77.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, max_depth=6, min_child_samples=7,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=50,\n",
      "              num_leaves=20, reg_alpha=1, reg_lambda=0, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3627\n",
      "Blended average after 2 repeats: 0.3601\n",
      "154.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, max_depth=2,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=1, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3625\n",
      "Blended average after 3 repeats: 0.3592\n",
      "237.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=1, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3623\n",
      "Blended average after 4 repeats: 0.3591\n",
      "298.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=100, reg_alpha=1, reg_lambda=10,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3620\n",
      "Blended average after 5 repeats: 0.3586\n",
      "366.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=0.0001, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3617\n",
      "Blended average after 6 repeats: 0.3582\n",
      "441.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=20, reg_alpha=1, reg_lambda=0.1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3616\n",
      "Blended average after 7 repeats: 0.3581\n",
      "523.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA13   37.714286\n",
      "V2IA15   36.489796\n",
      "V2IA23   28.734694\n",
      "V2IA16   26.551020\n",
      "V2IA19   25.367347\n",
      "V1HA14   21.734694\n",
      "V2IA04   20.714286\n",
      "V2IA12   20.122449\n",
      "V2IA10   19.551020\n",
      "V2IA17   17.591837\n",
      "         gain\n",
      "feature      \n",
      "S02G10    0.0\n",
      "V2AF22h   0.0\n",
      "S02G09    0.0\n",
      "S02G08    0.0\n",
      "S02G07    0.0\n",
      "S02G06    0.0\n",
      "S02G05    0.0\n",
      "S02G04    0.0\n",
      "S02G03    0.0\n",
      "S02E04    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA05_lgb2d_pred  V2IA06_lgb2d_pred  V2IA07_lgb2d_pred  \\\n",
      "0              3.035380           3.508593           2.727299   \n",
      "1              4.119606           3.197629           3.721817   \n",
      "2              4.326744           3.954662           3.761251   \n",
      "3              4.434909           4.060576           3.937103   \n",
      "4              5.017999           4.620653           4.713279   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.875935           3.528829           3.707253   \n",
      "9285           4.968398           4.791448           4.744238   \n",
      "9286           4.565734           4.028005           3.881843   \n",
      "9287           4.199377           3.744032           3.509662   \n",
      "9288           5.005424           4.491417           4.562553   \n",
      "\n",
      "      V2IA08_lgb2d_pred  V2IA09_lgb2d_pred  V2IA10_lgb2d_pred  \\\n",
      "0              3.021008           3.569372           3.687051   \n",
      "1              3.719616           4.686346           4.149227   \n",
      "2              4.098253           4.183408           4.423756   \n",
      "3              4.268814           4.652390           4.655637   \n",
      "4              4.995779           4.875206           4.917108   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.952086           4.301251           4.167568   \n",
      "9285           4.760661           4.672325           4.961264   \n",
      "9286           4.231556           3.149403           4.607412   \n",
      "9287           4.241605           4.234005           4.278653   \n",
      "9288           4.540123           4.822374           4.949376   \n",
      "\n",
      "      V2IA11_lgb2d_pred  V2IA12_lgb2d_pred  V2IA13_lgb2d_pred  \\\n",
      "0              2.847031           3.641039           3.453735   \n",
      "1              4.555882           4.024508           4.535342   \n",
      "2              4.288550           4.470814           4.290469   \n",
      "3              4.709987           4.404192           4.736425   \n",
      "4              4.979695           4.897966           5.014496   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.402781           3.847057           4.027162   \n",
      "9285           5.028767           4.767924           5.031926   \n",
      "9286           4.612361           4.527747           4.383056   \n",
      "9287           4.390432           3.917590           4.603074   \n",
      "9288           5.073425           5.014667           4.910660   \n",
      "\n",
      "      V2IA14_lgb2d_pred  \n",
      "0              3.106938  \n",
      "1              3.390022  \n",
      "2              4.071139  \n",
      "3              3.977929  \n",
      "4              4.749195  \n",
      "...                 ...  \n",
      "9284           3.696118  \n",
      "9285           4.500819  \n",
      "9286           4.286346  \n",
      "9287           3.804019  \n",
      "9288           4.820020  \n",
      "\n",
      "[9289 rows x 34 columns]\n",
      "lgb2d.csv (9289, 34)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "624/654 V2IA15 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8614, 4271) (675, 4271)\n",
      "(8614, 653) (8614,) (675, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4612\n",
      "Blended average after 1 repeats: 0.4612\n",
      "88.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=50, reg_alpha=1, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4597\n",
      "Blended average after 2 repeats: 0.4575\n",
      "162.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.01, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4592\n",
      "Blended average after 3 repeats: 0.4564\n",
      "237.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.1, reg_lambda=1, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4597\n",
      "Blended average after 4 repeats: 0.4565\n",
      "313.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=100, reg_alpha=0.1, reg_lambda=10,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4598\n",
      "Blended average after 5 repeats: 0.4562\n",
      "401.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=0, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4595\n",
      "Blended average after 6 repeats: 0.4553\n",
      "476.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=0.01,\n",
      "              reg_lambda=0, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4596\n",
      "Blended average after 7 repeats: 0.4553\n",
      "548.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=10, reg_lambda=1e-05,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA18   50.693878\n",
      "V2IA23   43.346939\n",
      "V2IA16   41.204082\n",
      "V1HA14   39.285714\n",
      "V2IA14   38.693878\n",
      "V2IA17   26.836735\n",
      "V2AG01   24.204082\n",
      "V1AF09   23.673469\n",
      "BMI      18.346939\n",
      "CLAA01b  17.857143\n",
      "         gain\n",
      "feature      \n",
      "V2AF22h   0.0\n",
      "V1HVer    0.0\n",
      "S02Ver    0.0\n",
      "V2AF25h   0.0\n",
      "S02H01    0.0\n",
      "S01A12    0.0\n",
      "S02G14    0.0\n",
      "S02G13    0.0\n",
      "S02G12    0.0\n",
      "V2AF25e   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA06_lgb2d_pred  V2IA07_lgb2d_pred  V2IA08_lgb2d_pred  \\\n",
      "0              3.508593           2.727299           3.021008   \n",
      "1              3.197629           3.721817           3.719616   \n",
      "2              3.954662           3.761251           4.098253   \n",
      "3              4.060576           3.937103           4.268814   \n",
      "4              4.620653           4.713279           4.995779   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.528829           3.707253           3.952086   \n",
      "9285           4.791448           4.744238           4.760661   \n",
      "9286           4.028005           3.881843           4.231556   \n",
      "9287           3.744032           3.509662           4.241605   \n",
      "9288           4.491417           4.562553           4.540123   \n",
      "\n",
      "      V2IA09_lgb2d_pred  V2IA10_lgb2d_pred  V2IA11_lgb2d_pred  \\\n",
      "0              3.569372           3.687051           2.847031   \n",
      "1              4.686346           4.149227           4.555882   \n",
      "2              4.183408           4.423756           4.288550   \n",
      "3              4.652390           4.655637           4.709987   \n",
      "4              4.875206           4.917108           4.979695   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.301251           4.167568           4.402781   \n",
      "9285           4.672325           4.961264           5.028767   \n",
      "9286           3.149403           4.607412           4.612361   \n",
      "9287           4.234005           4.278653           4.390432   \n",
      "9288           4.822374           4.949376           5.073425   \n",
      "\n",
      "      V2IA12_lgb2d_pred  V2IA13_lgb2d_pred  V2IA14_lgb2d_pred  \\\n",
      "0              3.641039           3.453735           3.106938   \n",
      "1              4.024508           4.535342           3.390022   \n",
      "2              4.470814           4.290469           4.071139   \n",
      "3              4.404192           4.736425           3.977929   \n",
      "4              4.897966           5.014496           4.749195   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.847057           4.027162           3.696118   \n",
      "9285           4.767924           5.031926           4.500819   \n",
      "9286           4.527747           4.383056           4.286346   \n",
      "9287           3.917590           4.603074           3.804019   \n",
      "9288           5.014667           4.910660           4.820020   \n",
      "\n",
      "      V2IA15_lgb2d_pred  \n",
      "0              3.931456  \n",
      "1              3.519714  \n",
      "2              4.380653  \n",
      "3              4.008000  \n",
      "4              4.049455  \n",
      "...                 ...  \n",
      "9284           3.505270  \n",
      "9285           4.251276  \n",
      "9286           4.267633  \n",
      "9287           3.306847  \n",
      "9288           4.605154  \n",
      "\n",
      "[9289 rows x 35 columns]\n",
      "lgb2d.csv (9289, 35)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "625/654 V2IA16 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8612, 4271) (677, 4271)\n",
      "(8612, 653) (8612,) (677, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4351\n",
      "Blended average after 1 repeats: 0.4351\n",
      "73.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=2,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.01,\n",
      "              reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4347\n",
      "Blended average after 2 repeats: 0.4328\n",
      "147.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=4,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.01,\n",
      "              num_leaves=20, reg_alpha=0.01, reg_lambda=1e-05, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4361\n",
      "Blended average after 3 repeats: 0.4328\n",
      "231.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4365\n",
      "Blended average after 4 repeats: 0.4327\n",
      "315.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=1, reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4367\n",
      "Blended average after 5 repeats: 0.4327\n",
      "392.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=0.1, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4365\n",
      "Blended average after 6 repeats: 0.4324\n",
      "471.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4366\n",
      "Blended average after 7 repeats: 0.4324\n",
      "542.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.1, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA15   58.448980\n",
      "V2IA17   54.714286\n",
      "V2IA12   41.755102\n",
      "V2IA14   39.653061\n",
      "V2IA18   32.102041\n",
      "V2IA19   29.061224\n",
      "V2IA23   27.306122\n",
      "V2IA24   19.816327\n",
      "V2IA07   18.795918\n",
      "V2IA01   16.000000\n",
      "             gain\n",
      "feature          \n",
      "S02E02        0.0\n",
      "V1AE2_04h_1   0.0\n",
      "V2AF25e       0.0\n",
      "S02E04        0.0\n",
      "S02ECheck     0.0\n",
      "V2AF22h       0.0\n",
      "V1AE2_04e_1   0.0\n",
      "S02G01        0.0\n",
      "S02G02        0.0\n",
      "V1GVer        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA07_lgb2d_pred  V2IA08_lgb2d_pred  V2IA09_lgb2d_pred  \\\n",
      "0              2.727299           3.021008           3.569372   \n",
      "1              3.721817           3.719616           4.686346   \n",
      "2              3.761251           4.098253           4.183408   \n",
      "3              3.937103           4.268814           4.652390   \n",
      "4              4.713279           4.995779           4.875206   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.707253           3.952086           4.301251   \n",
      "9285           4.744238           4.760661           4.672325   \n",
      "9286           3.881843           4.231556           3.149403   \n",
      "9287           3.509662           4.241605           4.234005   \n",
      "9288           4.562553           4.540123           4.822374   \n",
      "\n",
      "      V2IA10_lgb2d_pred  V2IA11_lgb2d_pred  V2IA12_lgb2d_pred  \\\n",
      "0              3.687051           2.847031           3.641039   \n",
      "1              4.149227           4.555882           4.024508   \n",
      "2              4.423756           4.288550           4.470814   \n",
      "3              4.655637           4.709987           4.404192   \n",
      "4              4.917108           4.979695           4.897966   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.167568           4.402781           3.847057   \n",
      "9285           4.961264           5.028767           4.767924   \n",
      "9286           4.607412           4.612361           4.527747   \n",
      "9287           4.278653           4.390432           3.917590   \n",
      "9288           4.949376           5.073425           5.014667   \n",
      "\n",
      "      V2IA13_lgb2d_pred  V2IA14_lgb2d_pred  V2IA15_lgb2d_pred  \\\n",
      "0              3.453735           3.106938           3.931456   \n",
      "1              4.535342           3.390022           3.519714   \n",
      "2              4.290469           4.071139           4.380653   \n",
      "3              4.736425           3.977929           4.008000   \n",
      "4              5.014496           4.749195           4.049455   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.027162           3.696118           3.505270   \n",
      "9285           5.031926           4.500819           4.251276   \n",
      "9286           4.383056           4.286346           4.267633   \n",
      "9287           4.603074           3.804019           3.306847   \n",
      "9288           4.910660           4.820020           4.605154   \n",
      "\n",
      "      V2IA16_lgb2d_pred  \n",
      "0              2.863263  \n",
      "1              3.140796  \n",
      "2              3.951817  \n",
      "3              3.797032  \n",
      "4              4.376749  \n",
      "...                 ...  \n",
      "9284           3.426230  \n",
      "9285           4.326383  \n",
      "9286           4.393058  \n",
      "9287           3.436942  \n",
      "9288           4.556985  \n",
      "\n",
      "[9289 rows x 36 columns]\n",
      "lgb2d.csv (9289, 36)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "626/654 V2IA17 5 0.075\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8596, 4271) (693, 4271)\n",
      "(8596, 653) (8596,) (693, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2689\n",
      "Blended average after 1 repeats: 0.2689\n",
      "74.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2689\n",
      "Blended average after 2 repeats: 0.2667\n",
      "151.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, max_depth=4,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=100, reg_alpha=0, reg_lambda=1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2686\n",
      "Blended average after 3 repeats: 0.2659\n",
      "226.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=4, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=100, reg_alpha=1, reg_lambda=100, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2687\n",
      "Blended average after 4 repeats: 0.2656\n",
      "299.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=30, reg_alpha=0.01,\n",
      "              reg_lambda=0.0001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2689\n",
      "Blended average after 5 repeats: 0.2655\n",
      "367.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=50, reg_alpha=0.001,\n",
      "              reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2690\n",
      "Blended average after 6 repeats: 0.2655\n",
      "448.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=5,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=50, num_leaves=100, reg_alpha=1, reg_lambda=0.01,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2691\n",
      "Blended average after 7 repeats: 0.2654\n",
      "523.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, max_depth=5,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA16   61.081633\n",
      "V2IA18   58.734694\n",
      "V2IA19   49.877551\n",
      "V2IA15   45.938776\n",
      "V2IA14   37.918367\n",
      "V2IA07   32.897959\n",
      "CLAA01d  30.857143\n",
      "V2IA25   30.448980\n",
      "V2IA21   25.428571\n",
      "CLAA01b  24.326531\n",
      "         gain\n",
      "feature      \n",
      "V2AF22h   0.0\n",
      "S02G10    0.0\n",
      "V1AF12i   0.0\n",
      "S02B02    0.0\n",
      "V2AF25h   0.0\n",
      "S02G09    0.0\n",
      "S02G08    0.0\n",
      "V2AF25e   0.0\n",
      "S02B03    0.0\n",
      "V2AF08e   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA08_lgb2d_pred  V2IA09_lgb2d_pred  V2IA10_lgb2d_pred  \\\n",
      "0              3.021008           3.569372           3.687051   \n",
      "1              3.719616           4.686346           4.149227   \n",
      "2              4.098253           4.183408           4.423756   \n",
      "3              4.268814           4.652390           4.655637   \n",
      "4              4.995779           4.875206           4.917108   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.952086           4.301251           4.167568   \n",
      "9285           4.760661           4.672325           4.961264   \n",
      "9286           4.231556           3.149403           4.607412   \n",
      "9287           4.241605           4.234005           4.278653   \n",
      "9288           4.540123           4.822374           4.949376   \n",
      "\n",
      "      V2IA11_lgb2d_pred  V2IA12_lgb2d_pred  V2IA13_lgb2d_pred  \\\n",
      "0              2.847031           3.641039           3.453735   \n",
      "1              4.555882           4.024508           4.535342   \n",
      "2              4.288550           4.470814           4.290469   \n",
      "3              4.709987           4.404192           4.736425   \n",
      "4              4.979695           4.897966           5.014496   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.402781           3.847057           4.027162   \n",
      "9285           5.028767           4.767924           5.031926   \n",
      "9286           4.612361           4.527747           4.383056   \n",
      "9287           4.390432           3.917590           4.603074   \n",
      "9288           5.073425           5.014667           4.910660   \n",
      "\n",
      "      V2IA14_lgb2d_pred  V2IA15_lgb2d_pred  V2IA16_lgb2d_pred  \\\n",
      "0              3.106938           3.931456           2.863263   \n",
      "1              3.390022           3.519714           3.140796   \n",
      "2              4.071139           4.380653           3.951817   \n",
      "3              3.977929           4.008000           3.797032   \n",
      "4              4.749195           4.049455           4.376749   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.696118           3.505270           3.426230   \n",
      "9285           4.500819           4.251276           4.326383   \n",
      "9286           4.286346           4.267633           4.393058   \n",
      "9287           3.804019           3.306847           3.436942   \n",
      "9288           4.820020           4.605154           4.556985   \n",
      "\n",
      "      V2IA17_lgb2d_pred  \n",
      "0              3.323889  \n",
      "1              4.064306  \n",
      "2              4.424092  \n",
      "3              4.234761  \n",
      "4              4.962215  \n",
      "...                 ...  \n",
      "9284           3.721073  \n",
      "9285           4.848112  \n",
      "9286           4.556620  \n",
      "9287           3.806184  \n",
      "9288           5.022039  \n",
      "\n",
      "[9289 rows x 37 columns]\n",
      "lgb2d.csv (9289, 37)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "627/654 V2IA18 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8611, 4271) (678, 4271)\n",
      "(8611, 653) (8611,) (678, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.6001\n",
      "Blended average after 1 repeats: 0.6001\n",
      "77.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=50, reg_alpha=0,\n",
      "              reg_lambda=0.0001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.6006\n",
      "Blended average after 2 repeats: 0.5969\n",
      "159.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.6008\n",
      "Blended average after 3 repeats: 0.5960\n",
      "243.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=30, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.6010\n",
      "Blended average after 4 repeats: 0.5958\n",
      "318.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.07, max_depth=2,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=10, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.6003\n",
      "Blended average after 5 repeats: 0.5951\n",
      "394.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=100, reg_alpha=10,\n",
      "              reg_lambda=0.0001, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.6005\n",
      "Blended average after 6 repeats: 0.5949\n",
      "463.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=10,\n",
      "              reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.6001\n",
      "Blended average after 7 repeats: 0.5944\n",
      "548.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=20, reg_alpha=0,\n",
      "              reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA20   70.489796\n",
      "V2IA15   55.857143\n",
      "V2IA19   42.061224\n",
      "V2IA17   34.795918\n",
      "V2IA16   31.387755\n",
      "V2AF20   24.285714\n",
      "CLAA01c  19.163265\n",
      "V1HA14   16.714286\n",
      "CLAA01d  16.673469\n",
      "V1AF09   15.938776\n",
      "         gain\n",
      "feature      \n",
      "S02G11    0.0\n",
      "S02G10    0.0\n",
      "S02G09    0.0\n",
      "S01A12    0.0\n",
      "V1AF12f   0.0\n",
      "S01A13    0.0\n",
      "V2AF25h   0.0\n",
      "S02G08    0.0\n",
      "S02G07    0.0\n",
      "V2AH06    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA09_lgb2d_pred  V2IA10_lgb2d_pred  V2IA11_lgb2d_pred  \\\n",
      "0              3.569372           3.687051           2.847031   \n",
      "1              4.686346           4.149227           4.555882   \n",
      "2              4.183408           4.423756           4.288550   \n",
      "3              4.652390           4.655637           4.709987   \n",
      "4              4.875206           4.917108           4.979695   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.301251           4.167568           4.402781   \n",
      "9285           4.672325           4.961264           5.028767   \n",
      "9286           3.149403           4.607412           4.612361   \n",
      "9287           4.234005           4.278653           4.390432   \n",
      "9288           4.822374           4.949376           5.073425   \n",
      "\n",
      "      V2IA12_lgb2d_pred  V2IA13_lgb2d_pred  V2IA14_lgb2d_pred  \\\n",
      "0              3.641039           3.453735           3.106938   \n",
      "1              4.024508           4.535342           3.390022   \n",
      "2              4.470814           4.290469           4.071139   \n",
      "3              4.404192           4.736425           3.977929   \n",
      "4              4.897966           5.014496           4.749195   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.847057           4.027162           3.696118   \n",
      "9285           4.767924           5.031926           4.500819   \n",
      "9286           4.527747           4.383056           4.286346   \n",
      "9287           3.917590           4.603074           3.804019   \n",
      "9288           5.014667           4.910660           4.820020   \n",
      "\n",
      "      V2IA15_lgb2d_pred  V2IA16_lgb2d_pred  V2IA17_lgb2d_pred  \\\n",
      "0              3.931456           2.863263           3.323889   \n",
      "1              3.519714           3.140796           4.064306   \n",
      "2              4.380653           3.951817           4.424092   \n",
      "3              4.008000           3.797032           4.234761   \n",
      "4              4.049455           4.376749           4.962215   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.505270           3.426230           3.721073   \n",
      "9285           4.251276           4.326383           4.848112   \n",
      "9286           4.267633           4.393058           4.556620   \n",
      "9287           3.306847           3.436942           3.806184   \n",
      "9288           4.605154           4.556985           5.022039   \n",
      "\n",
      "      V2IA18_lgb2d_pred  \n",
      "0              3.050639  \n",
      "1              3.396756  \n",
      "2              3.469022  \n",
      "3              4.065837  \n",
      "4              4.560027  \n",
      "...                 ...  \n",
      "9284           3.614854  \n",
      "9285           4.159484  \n",
      "9286           4.158358  \n",
      "9287           3.151507  \n",
      "9288           3.612031  \n",
      "\n",
      "[9289 rows x 38 columns]\n",
      "lgb2d.csv (9289, 38)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "628/654 V2IA19 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8611, 4271) (678, 4271)\n",
      "(8611, 653) (8611,) (678, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3810\n",
      "Blended average after 1 repeats: 0.3810\n",
      "62.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=10,\n",
      "              reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3821\n",
      "Blended average after 2 repeats: 0.3800\n",
      "133.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, max_depth=3,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=100, reg_alpha=0, reg_lambda=0.0001, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3824\n",
      "Blended average after 3 repeats: 0.3797\n",
      "214.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.07, max_depth=2,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=0, reg_lambda=0.1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3823\n",
      "Blended average after 4 repeats: 0.3794\n",
      "293.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=1,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3820\n",
      "Blended average after 5 repeats: 0.3789\n",
      "363.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=0.1,\n",
      "              reg_lambda=0.001, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3818\n",
      "Blended average after 6 repeats: 0.3787\n",
      "431.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=30, reg_alpha=0,\n",
      "              reg_lambda=100, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3819\n",
      "Blended average after 7 repeats: 0.3787\n",
      "502.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, max_depth=1,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=50, reg_alpha=10, reg_lambda=0.1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA18   35.387755\n",
      "V2IA20   34.469388\n",
      "V2IA04   19.530612\n",
      "V2IA07   17.918367\n",
      "V2IA16   17.653061\n",
      "V2IA17   17.632653\n",
      "V2IA01   17.081633\n",
      "V2IA14   16.510204\n",
      "V2IA08   15.183673\n",
      "V2IA06   13.306122\n",
      "             gain\n",
      "feature          \n",
      "V2AF08d       0.0\n",
      "V2AF08h       0.0\n",
      "V2AF17d       0.0\n",
      "V2AF10        0.0\n",
      "S02D07        0.0\n",
      "V1AE2_04b_1   0.0\n",
      "V1KA02_AMPM   0.0\n",
      "V2AF17b       0.0\n",
      "V1AE2_04c_1   0.0\n",
      "V2AD01        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA10_lgb2d_pred  V2IA11_lgb2d_pred  V2IA12_lgb2d_pred  \\\n",
      "0              3.687051           2.847031           3.641039   \n",
      "1              4.149227           4.555882           4.024508   \n",
      "2              4.423756           4.288550           4.470814   \n",
      "3              4.655637           4.709987           4.404192   \n",
      "4              4.917108           4.979695           4.897966   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.167568           4.402781           3.847057   \n",
      "9285           4.961264           5.028767           4.767924   \n",
      "9286           4.607412           4.612361           4.527747   \n",
      "9287           4.278653           4.390432           3.917590   \n",
      "9288           4.949376           5.073425           5.014667   \n",
      "\n",
      "      V2IA13_lgb2d_pred  V2IA14_lgb2d_pred  V2IA15_lgb2d_pred  \\\n",
      "0              3.453735           3.106938           3.931456   \n",
      "1              4.535342           3.390022           3.519714   \n",
      "2              4.290469           4.071139           4.380653   \n",
      "3              4.736425           3.977929           4.008000   \n",
      "4              5.014496           4.749195           4.049455   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.027162           3.696118           3.505270   \n",
      "9285           5.031926           4.500819           4.251276   \n",
      "9286           4.383056           4.286346           4.267633   \n",
      "9287           4.603074           3.804019           3.306847   \n",
      "9288           4.910660           4.820020           4.605154   \n",
      "\n",
      "      V2IA16_lgb2d_pred  V2IA17_lgb2d_pred  V2IA18_lgb2d_pred  \\\n",
      "0              2.863263           3.323889           3.050639   \n",
      "1              3.140796           4.064306           3.396756   \n",
      "2              3.951817           4.424092           3.469022   \n",
      "3              3.797032           4.234761           4.065837   \n",
      "4              4.376749           4.962215           4.560027   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.426230           3.721073           3.614854   \n",
      "9285           4.326383           4.848112           4.159484   \n",
      "9286           4.393058           4.556620           4.158358   \n",
      "9287           3.436942           3.806184           3.151507   \n",
      "9288           4.556985           5.022039           3.612031   \n",
      "\n",
      "      V2IA19_lgb2d_pred  \n",
      "0              3.031903  \n",
      "1              3.281445  \n",
      "2              4.031415  \n",
      "3              4.237428  \n",
      "4              4.658599  \n",
      "...                 ...  \n",
      "9284           3.195634  \n",
      "9285           4.627473  \n",
      "9286           4.230359  \n",
      "9287           3.514431  \n",
      "9288           4.245505  \n",
      "\n",
      "[9289 rows x 39 columns]\n",
      "lgb2d.csv (9289, 39)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "629/654 V2IA20 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8610, 4271) (679, 4271)\n",
      "(8610, 653) (8610,) (679, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.5048\n",
      "Blended average after 1 repeats: 0.5048\n",
      "80.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=20, reg_alpha=0,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.5053\n",
      "Blended average after 2 repeats: 0.5027\n",
      "146.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=50, reg_alpha=10, reg_lambda=10,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.5041\n",
      "Blended average after 3 repeats: 0.5011\n",
      "227.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.05, max_depth=2,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.1, reg_lambda=0,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.5044\n",
      "Blended average after 4 repeats: 0.5010\n",
      "303.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=0, reg_lambda=0.01, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.5043\n",
      "Blended average after 5 repeats: 0.5005\n",
      "378.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=30, reg_alpha=10, reg_lambda=1, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.5041\n",
      "Blended average after 6 repeats: 0.5001\n",
      "459.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, max_depth=1,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=225,\n",
      "              num_leaves=50, reg_alpha=0.01, reg_lambda=100, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.5043\n",
      "Blended average after 7 repeats: 0.5002\n",
      "534.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=0, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "               gain\n",
      "feature            \n",
      "V2IA18    56.551020\n",
      "V2IA09    49.102041\n",
      "V2IA19    34.408163\n",
      "V2IA21    28.857143\n",
      "V2IA07    21.571429\n",
      "V2IA06    19.428571\n",
      "V2IA03    17.979592\n",
      "V2IA23    16.877551\n",
      "V1AH10    12.571429\n",
      "CLAE02a1  11.224490\n",
      "             gain\n",
      "feature          \n",
      "V2AH05        0.0\n",
      "S02G12        0.0\n",
      "S02G11        0.0\n",
      "V2AF08c       0.0\n",
      "S02E04        0.0\n",
      "V2AF08e       0.0\n",
      "S02ECheck     0.0\n",
      "S02G10        0.0\n",
      "V1AE2_04h_1   0.0\n",
      "V1AE2_04g_1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA11_lgb2d_pred  V2IA12_lgb2d_pred  V2IA13_lgb2d_pred  \\\n",
      "0              2.847031           3.641039           3.453735   \n",
      "1              4.555882           4.024508           4.535342   \n",
      "2              4.288550           4.470814           4.290469   \n",
      "3              4.709987           4.404192           4.736425   \n",
      "4              4.979695           4.897966           5.014496   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.402781           3.847057           4.027162   \n",
      "9285           5.028767           4.767924           5.031926   \n",
      "9286           4.612361           4.527747           4.383056   \n",
      "9287           4.390432           3.917590           4.603074   \n",
      "9288           5.073425           5.014667           4.910660   \n",
      "\n",
      "      V2IA14_lgb2d_pred  V2IA15_lgb2d_pred  V2IA16_lgb2d_pred  \\\n",
      "0              3.106938           3.931456           2.863263   \n",
      "1              3.390022           3.519714           3.140796   \n",
      "2              4.071139           4.380653           3.951817   \n",
      "3              3.977929           4.008000           3.797032   \n",
      "4              4.749195           4.049455           4.376749   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.696118           3.505270           3.426230   \n",
      "9285           4.500819           4.251276           4.326383   \n",
      "9286           4.286346           4.267633           4.393058   \n",
      "9287           3.804019           3.306847           3.436942   \n",
      "9288           4.820020           4.605154           4.556985   \n",
      "\n",
      "      V2IA17_lgb2d_pred  V2IA18_lgb2d_pred  V2IA19_lgb2d_pred  \\\n",
      "0              3.323889           3.050639           3.031903   \n",
      "1              4.064306           3.396756           3.281445   \n",
      "2              4.424092           3.469022           4.031415   \n",
      "3              4.234761           4.065837           4.237428   \n",
      "4              4.962215           4.560027           4.658599   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.721073           3.614854           3.195634   \n",
      "9285           4.848112           4.159484           4.627473   \n",
      "9286           4.556620           4.158358           4.230359   \n",
      "9287           3.806184           3.151507           3.514431   \n",
      "9288           5.022039           3.612031           4.245505   \n",
      "\n",
      "      V2IA20_lgb2d_pred  \n",
      "0              2.952912  \n",
      "1              4.196418  \n",
      "2              3.538537  \n",
      "3              3.848621  \n",
      "4              4.065863  \n",
      "...                 ...  \n",
      "9284           3.767677  \n",
      "9285           4.656540  \n",
      "9286           3.790593  \n",
      "9287           3.536387  \n",
      "9288           4.040868  \n",
      "\n",
      "[9289 rows x 40 columns]\n",
      "lgb2d.csv (9289, 40)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "630/654 V2IA21 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8611, 4271) (678, 4271)\n",
      "(8611, 653) (8611,) (678, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2782\n",
      "Blended average after 1 repeats: 0.2782\n",
      "81.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=10, reg_lambda=0.1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2789\n",
      "Blended average after 2 repeats: 0.2768\n",
      "153.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=350, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=0.1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2785\n",
      "Blended average after 3 repeats: 0.2757\n",
      "219.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50, reg_alpha=0.1,\n",
      "              reg_lambda=100, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2790\n",
      "Blended average after 4 repeats: 0.2759\n",
      "302.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, learning_rate=0.05, max_depth=5,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.01,\n",
      "              num_leaves=30, reg_alpha=0.1, reg_lambda=100, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2790\n",
      "Blended average after 5 repeats: 0.2757\n",
      "370.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=10, reg_lambda=0,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2789\n",
      "Blended average after 6 repeats: 0.2755\n",
      "441.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=30, reg_alpha=0.1, reg_lambda=10,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2789\n",
      "Blended average after 7 repeats: 0.2753\n",
      "509.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=20, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA22   78.734694\n",
      "V2IA03   56.673469\n",
      "V2IA20   45.142857\n",
      "V2IA24   37.591837\n",
      "V2IA09   35.693878\n",
      "V2IA13   27.306122\n",
      "V2IA17   26.653061\n",
      "V2IA19   20.918367\n",
      "V2IA05   20.551020\n",
      "V1HA03   19.346939\n",
      "         gain\n",
      "feature      \n",
      "S02G09    0.0\n",
      "V2AF25h   0.0\n",
      "S02G08    0.0\n",
      "S02G07    0.0\n",
      "S02G06    0.0\n",
      "S02G05    0.0\n",
      "S02G04    0.0\n",
      "S02G03    0.0\n",
      "S02G02    0.0\n",
      "V1AF15f   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA12_lgb2d_pred  V2IA13_lgb2d_pred  V2IA14_lgb2d_pred  \\\n",
      "0              3.641039           3.453735           3.106938   \n",
      "1              4.024508           4.535342           3.390022   \n",
      "2              4.470814           4.290469           4.071139   \n",
      "3              4.404192           4.736425           3.977929   \n",
      "4              4.897966           5.014496           4.749195   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.847057           4.027162           3.696118   \n",
      "9285           4.767924           5.031926           4.500819   \n",
      "9286           4.527747           4.383056           4.286346   \n",
      "9287           3.917590           4.603074           3.804019   \n",
      "9288           5.014667           4.910660           4.820020   \n",
      "\n",
      "      V2IA15_lgb2d_pred  V2IA16_lgb2d_pred  V2IA17_lgb2d_pred  \\\n",
      "0              3.931456           2.863263           3.323889   \n",
      "1              3.519714           3.140796           4.064306   \n",
      "2              4.380653           3.951817           4.424092   \n",
      "3              4.008000           3.797032           4.234761   \n",
      "4              4.049455           4.376749           4.962215   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.505270           3.426230           3.721073   \n",
      "9285           4.251276           4.326383           4.848112   \n",
      "9286           4.267633           4.393058           4.556620   \n",
      "9287           3.306847           3.436942           3.806184   \n",
      "9288           4.605154           4.556985           5.022039   \n",
      "\n",
      "      V2IA18_lgb2d_pred  V2IA19_lgb2d_pred  V2IA20_lgb2d_pred  \\\n",
      "0              3.050639           3.031903           2.952912   \n",
      "1              3.396756           3.281445           4.196418   \n",
      "2              3.469022           4.031415           3.538537   \n",
      "3              4.065837           4.237428           3.848621   \n",
      "4              4.560027           4.658599           4.065863   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.614854           3.195634           3.767677   \n",
      "9285           4.159484           4.627473           4.656540   \n",
      "9286           4.158358           4.230359           3.790593   \n",
      "9287           3.151507           3.514431           3.536387   \n",
      "9288           3.612031           4.245505           4.040868   \n",
      "\n",
      "      V2IA21_lgb2d_pred  \n",
      "0              4.014307  \n",
      "1              4.787561  \n",
      "2              4.427811  \n",
      "3              4.478790  \n",
      "4              5.021653  \n",
      "...                 ...  \n",
      "9284           4.466472  \n",
      "9285           4.913910  \n",
      "9286           4.409862  \n",
      "9287           4.239118  \n",
      "9288           4.901067  \n",
      "\n",
      "[9289 rows x 41 columns]\n",
      "lgb2d.csv (9289, 41)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "631/654 V2IA22 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8613, 4271) (676, 4271)\n",
      "(8613, 653) (8613,) (676, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2817\n",
      "Blended average after 1 repeats: 0.2817\n",
      "65.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=100, reg_alpha=0, reg_lambda=0.01,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2813\n",
      "Blended average after 2 repeats: 0.2792\n",
      "142.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=50, reg_alpha=0.001, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2814\n",
      "Blended average after 3 repeats: 0.2785\n",
      "214.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=20, reg_alpha=0.001,\n",
      "              reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2813\n",
      "Blended average after 4 repeats: 0.2782\n",
      "284.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, max_depth=2,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=10, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2817\n",
      "Blended average after 5 repeats: 0.2780\n",
      "357.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, max_depth=1,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=20, reg_alpha=0.001, reg_lambda=1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2818\n",
      "Blended average after 6 repeats: 0.2779\n",
      "427.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=0, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2818\n",
      "Blended average after 7 repeats: 0.2779\n",
      "499.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.07, max_depth=1,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=10, reg_lambda=0.0001,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA21   54.591837\n",
      "V2IA23   50.897959\n",
      "V2IA25   27.142857\n",
      "V1AH02   25.795918\n",
      "V1EA02j  17.346939\n",
      "V2IA13   16.816327\n",
      "V1LE04   16.408163\n",
      "V1AH08   16.081633\n",
      "V2IA14   15.612245\n",
      "CLAA01d  15.040816\n",
      "         gain\n",
      "feature      \n",
      "V1AD12e   0.0\n",
      "V1AD12d   0.0\n",
      "V1AD12c   0.0\n",
      "V1AD12b   0.0\n",
      "V2AF18i   0.0\n",
      "V2AF18h   0.0\n",
      "V1AD05    0.0\n",
      "U02C02    0.0\n",
      "V1LF02    0.0\n",
      "S02G12    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA13_lgb2d_pred  V2IA14_lgb2d_pred  V2IA15_lgb2d_pred  \\\n",
      "0              3.453735           3.106938           3.931456   \n",
      "1              4.535342           3.390022           3.519714   \n",
      "2              4.290469           4.071139           4.380653   \n",
      "3              4.736425           3.977929           4.008000   \n",
      "4              5.014496           4.749195           4.049455   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.027162           3.696118           3.505270   \n",
      "9285           5.031926           4.500819           4.251276   \n",
      "9286           4.383056           4.286346           4.267633   \n",
      "9287           4.603074           3.804019           3.306847   \n",
      "9288           4.910660           4.820020           4.605154   \n",
      "\n",
      "      V2IA16_lgb2d_pred  V2IA17_lgb2d_pred  V2IA18_lgb2d_pred  \\\n",
      "0              2.863263           3.323889           3.050639   \n",
      "1              3.140796           4.064306           3.396756   \n",
      "2              3.951817           4.424092           3.469022   \n",
      "3              3.797032           4.234761           4.065837   \n",
      "4              4.376749           4.962215           4.560027   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.426230           3.721073           3.614854   \n",
      "9285           4.326383           4.848112           4.159484   \n",
      "9286           4.393058           4.556620           4.158358   \n",
      "9287           3.436942           3.806184           3.151507   \n",
      "9288           4.556985           5.022039           3.612031   \n",
      "\n",
      "      V2IA19_lgb2d_pred  V2IA20_lgb2d_pred  V2IA21_lgb2d_pred  \\\n",
      "0              3.031903           2.952912           4.014307   \n",
      "1              3.281445           4.196418           4.787561   \n",
      "2              4.031415           3.538537           4.427811   \n",
      "3              4.237428           3.848621           4.478790   \n",
      "4              4.658599           4.065863           5.021653   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.195634           3.767677           4.466472   \n",
      "9285           4.627473           4.656540           4.913910   \n",
      "9286           4.230359           3.790593           4.409862   \n",
      "9287           3.514431           3.536387           4.239118   \n",
      "9288           4.245505           4.040868           4.901067   \n",
      "\n",
      "      V2IA22_lgb2d_pred  \n",
      "0              3.527286  \n",
      "1              4.005398  \n",
      "2              4.530441  \n",
      "3              4.183159  \n",
      "4              4.838427  \n",
      "...                 ...  \n",
      "9284           3.715120  \n",
      "9285           4.887447  \n",
      "9286           4.493075  \n",
      "9287           4.176339  \n",
      "9288           4.662976  \n",
      "\n",
      "[9289 rows x 42 columns]\n",
      "lgb2d.csv (9289, 42)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "632/654 V2IA23 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8610, 4271) (679, 4271)\n",
      "(8610, 653) (8610,) (679, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4594\n",
      "Blended average after 1 repeats: 0.4594\n",
      "66.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=350,\n",
      "              num_leaves=100, reg_alpha=0, reg_lambda=100, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4589\n",
      "Blended average after 2 repeats: 0.4566\n",
      "148.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=0.01, reg_lambda=0.1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4586\n",
      "Blended average after 3 repeats: 0.4553\n",
      "231.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=4,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=30, reg_alpha=0, reg_lambda=0.01, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4582\n",
      "Blended average after 4 repeats: 0.4544\n",
      "304.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, max_depth=2,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=10, reg_lambda=100,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4586\n",
      "Blended average after 5 repeats: 0.4545\n",
      "377.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=100, reg_alpha=0, reg_lambda=0,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4585\n",
      "Blended average after 6 repeats: 0.4543\n",
      "448.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4587\n",
      "Blended average after 7 repeats: 0.4542\n",
      "528.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=7, min_child_weight=0, min_split_gain=0.001,\n",
      "              num_leaves=20, reg_alpha=0.1, reg_lambda=0.0001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                gain\n",
      "feature             \n",
      "V2IA15     44.326531\n",
      "V2IA24     41.755102\n",
      "V2IA22     37.979592\n",
      "V2IA14     30.061224\n",
      "V2IA07     24.755102\n",
      "V2IA16     19.040816\n",
      "V2IA06     18.061224\n",
      "V2IA20     16.775510\n",
      "V1HA14     16.775510\n",
      "Neck_mean  15.469388\n",
      "         gain\n",
      "feature      \n",
      "S02B03    0.0\n",
      "V1AF07d   0.0\n",
      "V2AF17e   0.0\n",
      "V1AF06g   0.0\n",
      "V2AF10    0.0\n",
      "V2AF08h   0.0\n",
      "V1GVer    0.0\n",
      "V2AF05h   0.0\n",
      "V2AF05g   0.0\n",
      "S02G03    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA14_lgb2d_pred  V2IA15_lgb2d_pred  V2IA16_lgb2d_pred  \\\n",
      "0              3.106938           3.931456           2.863263   \n",
      "1              3.390022           3.519714           3.140796   \n",
      "2              4.071139           4.380653           3.951817   \n",
      "3              3.977929           4.008000           3.797032   \n",
      "4              4.749195           4.049455           4.376749   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.696118           3.505270           3.426230   \n",
      "9285           4.500819           4.251276           4.326383   \n",
      "9286           4.286346           4.267633           4.393058   \n",
      "9287           3.804019           3.306847           3.436942   \n",
      "9288           4.820020           4.605154           4.556985   \n",
      "\n",
      "      V2IA17_lgb2d_pred  V2IA18_lgb2d_pred  V2IA19_lgb2d_pred  \\\n",
      "0              3.323889           3.050639           3.031903   \n",
      "1              4.064306           3.396756           3.281445   \n",
      "2              4.424092           3.469022           4.031415   \n",
      "3              4.234761           4.065837           4.237428   \n",
      "4              4.962215           4.560027           4.658599   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.721073           3.614854           3.195634   \n",
      "9285           4.848112           4.159484           4.627473   \n",
      "9286           4.556620           4.158358           4.230359   \n",
      "9287           3.806184           3.151507           3.514431   \n",
      "9288           5.022039           3.612031           4.245505   \n",
      "\n",
      "      V2IA20_lgb2d_pred  V2IA21_lgb2d_pred  V2IA22_lgb2d_pred  \\\n",
      "0              2.952912           4.014307           3.527286   \n",
      "1              4.196418           4.787561           4.005398   \n",
      "2              3.538537           4.427811           4.530441   \n",
      "3              3.848621           4.478790           4.183159   \n",
      "4              4.065863           5.021653           4.838427   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.767677           4.466472           3.715120   \n",
      "9285           4.656540           4.913910           4.887447   \n",
      "9286           3.790593           4.409862           4.493075   \n",
      "9287           3.536387           4.239118           4.176339   \n",
      "9288           4.040868           4.901067           4.662976   \n",
      "\n",
      "      V2IA23_lgb2d_pred  \n",
      "0              2.772844  \n",
      "1              3.564243  \n",
      "2              4.068708  \n",
      "3              3.973097  \n",
      "4              4.670542  \n",
      "...                 ...  \n",
      "9284           3.403406  \n",
      "9285           4.642883  \n",
      "9286           4.586488  \n",
      "9287           3.677629  \n",
      "9288           4.634715  \n",
      "\n",
      "[9289 rows x 43 columns]\n",
      "lgb2d.csv (9289, 43)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "633/654 V2IA24 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8613, 4271) (676, 4271)\n",
      "(8613, 653) (8613,) (676, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2287\n",
      "Blended average after 1 repeats: 0.2287\n",
      "75.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, max_depth=7,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=50, num_leaves=100, reg_alpha=0.01,\n",
      "              reg_lambda=0.0001, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2284\n",
      "Blended average after 2 repeats: 0.2267\n",
      "138.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=0.01, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2280\n",
      "Blended average after 3 repeats: 0.2258\n",
      "206.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.1, reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2280\n",
      "Blended average after 4 repeats: 0.2256\n",
      "287.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=2,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=10, reg_lambda=0.0001,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2282\n",
      "Blended average after 5 repeats: 0.2256\n",
      "358.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.05, max_depth=1,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.001, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2281\n",
      "Blended average after 6 repeats: 0.2255\n",
      "437.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, max_depth=3, min_child_samples=70,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=150,\n",
      "              num_leaves=20, reg_alpha=10, reg_lambda=0.1, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2280\n",
      "Blended average after 7 repeats: 0.2254\n",
      "507.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=20, reg_alpha=10,\n",
      "              reg_lambda=0.001, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "              gain\n",
      "feature           \n",
      "V2IA23   71.020408\n",
      "V2IA25   56.387755\n",
      "V2IA10   35.102041\n",
      "V2IA21   34.510204\n",
      "V2IA11   32.448980\n",
      "V2IA12   29.632653\n",
      "V2IA17   25.469388\n",
      "V2IA16   21.428571\n",
      "V2IA22   19.959184\n",
      "V2IA15   19.653061\n",
      "         gain\n",
      "feature      \n",
      "Ins_Mil   0.0\n",
      "S02G11    0.0\n",
      "S02G12    0.0\n",
      "S02G13    0.0\n",
      "S02G14    0.0\n",
      "S02H01    0.0\n",
      "S02Ver    0.0\n",
      "V2AF25h   0.0\n",
      "V1HVer    0.0\n",
      "S01A01    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA15_lgb2d_pred  V2IA16_lgb2d_pred  V2IA17_lgb2d_pred  \\\n",
      "0              3.931456           2.863263           3.323889   \n",
      "1              3.519714           3.140796           4.064306   \n",
      "2              4.380653           3.951817           4.424092   \n",
      "3              4.008000           3.797032           4.234761   \n",
      "4              4.049455           4.376749           4.962215   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.505270           3.426230           3.721073   \n",
      "9285           4.251276           4.326383           4.848112   \n",
      "9286           4.267633           4.393058           4.556620   \n",
      "9287           3.306847           3.436942           3.806184   \n",
      "9288           4.605154           4.556985           5.022039   \n",
      "\n",
      "      V2IA18_lgb2d_pred  V2IA19_lgb2d_pred  V2IA20_lgb2d_pred  \\\n",
      "0              3.050639           3.031903           2.952912   \n",
      "1              3.396756           3.281445           4.196418   \n",
      "2              3.469022           4.031415           3.538537   \n",
      "3              4.065837           4.237428           3.848621   \n",
      "4              4.560027           4.658599           4.065863   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.614854           3.195634           3.767677   \n",
      "9285           4.159484           4.627473           4.656540   \n",
      "9286           4.158358           4.230359           3.790593   \n",
      "9287           3.151507           3.514431           3.536387   \n",
      "9288           3.612031           4.245505           4.040868   \n",
      "\n",
      "      V2IA21_lgb2d_pred  V2IA22_lgb2d_pred  V2IA23_lgb2d_pred  \\\n",
      "0              4.014307           3.527286           2.772844   \n",
      "1              4.787561           4.005398           3.564243   \n",
      "2              4.427811           4.530441           4.068708   \n",
      "3              4.478790           4.183159           3.973097   \n",
      "4              5.021653           4.838427           4.670542   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.466472           3.715120           3.403406   \n",
      "9285           4.913910           4.887447           4.642883   \n",
      "9286           4.409862           4.493075           4.586488   \n",
      "9287           4.239118           4.176339           3.677629   \n",
      "9288           4.901067           4.662976           4.634715   \n",
      "\n",
      "      V2IA24_lgb2d_pred  \n",
      "0              3.893282  \n",
      "1              3.974833  \n",
      "2              4.669150  \n",
      "3              4.139214  \n",
      "4              4.759040  \n",
      "...                 ...  \n",
      "9284           3.974833  \n",
      "9285           4.870740  \n",
      "9286           4.345400  \n",
      "9287           4.013332  \n",
      "9288           4.970099  \n",
      "\n",
      "[9289 rows x 44 columns]\n",
      "lgb2d.csv (9289, 44)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "634/654 V2IA25 5 0.073\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8612, 4271) (677, 4271)\n",
      "(8612, 653) (8612,) (677, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2034\n",
      "Blended average after 1 repeats: 0.2034\n",
      "75.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.001, reg_lambda=0,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2027\n",
      "Blended average after 2 repeats: 0.2009\n",
      "145.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.07, max_depth=6,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=100, reg_alpha=10, reg_lambda=0.1, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2033\n",
      "Blended average after 3 repeats: 0.2010\n",
      "211.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=0.1, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2035\n",
      "Blended average after 4 repeats: 0.2008\n",
      "291.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2032\n",
      "Blended average after 5 repeats: 0.2004\n",
      "358.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=30,\n",
      "              reg_alpha=0.1, reg_lambda=0.1, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2030\n",
      "Blended average after 6 repeats: 0.2002\n",
      "427.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30, reg_alpha=0.01,\n",
      "              reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2028\n",
      "Blended average after 7 repeats: 0.1999\n",
      "500.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=150, num_leaves=50, reg_alpha=1,\n",
      "              reg_lambda=10, subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "               gain\n",
      "feature            \n",
      "V2IA24   109.428571\n",
      "V2IA22    63.918367\n",
      "V2IA17    42.795918\n",
      "V2IA05    40.571429\n",
      "V1AF09    38.591837\n",
      "V2IA21    38.081633\n",
      "V2IA10    34.755102\n",
      "CLAA01c   34.571429\n",
      "V2IA11    33.979592\n",
      "CLAA01d   30.816327\n",
      "           gain\n",
      "feature        \n",
      "V1GVer      0.0\n",
      "S02ECheck   0.0\n",
      "V2AG03d     0.0\n",
      "V2AF05g     0.0\n",
      "V1HVer      0.0\n",
      "V2AF25h     0.0\n",
      "V2AF25e     0.0\n",
      "S02G01      0.0\n",
      "V2AF22h     0.0\n",
      "S02B03      0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA16_lgb2d_pred  V2IA17_lgb2d_pred  V2IA18_lgb2d_pred  \\\n",
      "0              2.863263           3.323889           3.050639   \n",
      "1              3.140796           4.064306           3.396756   \n",
      "2              3.951817           4.424092           3.469022   \n",
      "3              3.797032           4.234761           4.065837   \n",
      "4              4.376749           4.962215           4.560027   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.426230           3.721073           3.614854   \n",
      "9285           4.326383           4.848112           4.159484   \n",
      "9286           4.393058           4.556620           4.158358   \n",
      "9287           3.436942           3.806184           3.151507   \n",
      "9288           4.556985           5.022039           3.612031   \n",
      "\n",
      "      V2IA19_lgb2d_pred  V2IA20_lgb2d_pred  V2IA21_lgb2d_pred  \\\n",
      "0              3.031903           2.952912           4.014307   \n",
      "1              3.281445           4.196418           4.787561   \n",
      "2              4.031415           3.538537           4.427811   \n",
      "3              4.237428           3.848621           4.478790   \n",
      "4              4.658599           4.065863           5.021653   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.195634           3.767677           4.466472   \n",
      "9285           4.627473           4.656540           4.913910   \n",
      "9286           4.230359           3.790593           4.409862   \n",
      "9287           3.514431           3.536387           4.239118   \n",
      "9288           4.245505           4.040868           4.901067   \n",
      "\n",
      "      V2IA22_lgb2d_pred  V2IA23_lgb2d_pred  V2IA24_lgb2d_pred  \\\n",
      "0              3.527286           2.772844           3.893282   \n",
      "1              4.005398           3.564243           3.974833   \n",
      "2              4.530441           4.068708           4.669150   \n",
      "3              4.183159           3.973097           4.139214   \n",
      "4              4.838427           4.670542           4.759040   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.715120           3.403406           3.974833   \n",
      "9285           4.887447           4.642883           4.870740   \n",
      "9286           4.493075           4.586488           4.345400   \n",
      "9287           4.176339           3.677629           4.013332   \n",
      "9288           4.662976           4.634715           4.970099   \n",
      "\n",
      "      V2IA25_lgb2d_pred  \n",
      "0              3.710022  \n",
      "1              4.813471  \n",
      "2              4.826686  \n",
      "3              4.718632  \n",
      "4              5.019340  \n",
      "...                 ...  \n",
      "9284           4.420971  \n",
      "9285           4.970893  \n",
      "9286           4.760608  \n",
      "9287           4.490196  \n",
      "9288           4.949663  \n",
      "\n",
      "[9289 rows x 45 columns]\n",
      "lgb2d.csv (9289, 45)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "635/654 Height_mean 758 0.021\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9093, 4271) (196, 4271)\n",
      "(9093, 653) (9093,) (196, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4626\n",
      "Blended average after 1 repeats: 0.4626\n",
      "85.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=7, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=1, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4126\n",
      "Blended average after 2 repeats: 0.3580\n",
      "168.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=350, num_leaves=30, reg_alpha=10,\n",
      "              reg_lambda=1e-05, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4026\n",
      "Blended average after 3 repeats: 0.3251\n",
      "241.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4011\n",
      "Blended average after 4 repeats: 0.3182\n",
      "313.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=0.1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3980\n",
      "Blended average after 5 repeats: 0.3144\n",
      "389.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.001, reg_lambda=0.01, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3943\n",
      "Blended average after 6 repeats: 0.3073\n",
      "455.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, max_depth=4, min_child_samples=4,\n",
      "              min_child_weight=0, min_split_gain=0.0001, num_leaves=30,\n",
      "              reg_alpha=10, reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3972\n",
      "Blended average after 7 repeats: 0.3059\n",
      "530.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                     gain\n",
      "feature                  \n",
      "Height_max     910.326531\n",
      "BMI            313.142857\n",
      "V1AD01b        220.551020\n",
      "V1BA01_LB      201.816327\n",
      "Height_std     163.224490\n",
      "V2BA01_LB       87.061224\n",
      "BMI_Cat         64.693878\n",
      "PctFedPoverty   27.244898\n",
      "Hip_mean        25.979592\n",
      "Waist_mean      23.693878\n",
      "             gain\n",
      "feature          \n",
      "V1AE2_04g_1   0.0\n",
      "V1AE2_04f_1   0.0\n",
      "V1AE2_04e_1   0.0\n",
      "V1HVer        0.0\n",
      "V1AE2_04d_1   0.0\n",
      "S02G03        0.0\n",
      "V1LVer        0.0\n",
      "S01A13        0.0\n",
      "S01A12        0.0\n",
      "S02Ver        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA17_lgb2d_pred  V2IA18_lgb2d_pred  V2IA19_lgb2d_pred  \\\n",
      "0              3.323889           3.050639           3.031903   \n",
      "1              4.064306           3.396756           3.281445   \n",
      "2              4.424092           3.469022           4.031415   \n",
      "3              4.234761           4.065837           4.237428   \n",
      "4              4.962215           4.560027           4.658599   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.721073           3.614854           3.195634   \n",
      "9285           4.848112           4.159484           4.627473   \n",
      "9286           4.556620           4.158358           4.230359   \n",
      "9287           3.806184           3.151507           3.514431   \n",
      "9288           5.022039           3.612031           4.245505   \n",
      "\n",
      "      V2IA20_lgb2d_pred  V2IA21_lgb2d_pred  V2IA22_lgb2d_pred  \\\n",
      "0              2.952912           4.014307           3.527286   \n",
      "1              4.196418           4.787561           4.005398   \n",
      "2              3.538537           4.427811           4.530441   \n",
      "3              3.848621           4.478790           4.183159   \n",
      "4              4.065863           5.021653           4.838427   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.767677           4.466472           3.715120   \n",
      "9285           4.656540           4.913910           4.887447   \n",
      "9286           3.790593           4.409862           4.493075   \n",
      "9287           3.536387           4.239118           4.176339   \n",
      "9288           4.040868           4.901067           4.662976   \n",
      "\n",
      "      V2IA23_lgb2d_pred  V2IA24_lgb2d_pred  V2IA25_lgb2d_pred  \\\n",
      "0              2.772844           3.893282           3.710022   \n",
      "1              3.564243           3.974833           4.813471   \n",
      "2              4.068708           4.669150           4.826686   \n",
      "3              3.973097           4.139214           4.718632   \n",
      "4              4.670542           4.759040           5.019340   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.403406           3.974833           4.420971   \n",
      "9285           4.642883           4.870740           4.970893   \n",
      "9286           4.586488           4.345400           4.760608   \n",
      "9287           3.677629           4.013332           4.490196   \n",
      "9288           4.634715           4.970099           4.949663   \n",
      "\n",
      "      Height_mean_lgb2d_pred  \n",
      "0                 154.695279  \n",
      "1                 166.982064  \n",
      "2                 160.020190  \n",
      "3                 175.122315  \n",
      "4                 174.014453  \n",
      "...                      ...  \n",
      "9284              169.537135  \n",
      "9285              156.687095  \n",
      "9286              168.002014  \n",
      "9287              136.082293  \n",
      "9288              160.400018  \n",
      "\n",
      "[9289 rows x 46 columns]\n",
      "lgb2d.csv (9289, 46)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "636/654 Waist_mean 1448 0.030\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9014, 4271) (275, 4271)\n",
      "(9014, 653) (9014,) (275, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3763\n",
      "Blended average after 1 repeats: 0.3763\n",
      "88.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=1, reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4411\n",
      "Blended average after 2 repeats: 0.3655\n",
      "174.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=1, reg_lambda=0.0001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.5684\n",
      "Blended average after 3 repeats: 0.4275\n",
      "251.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.07, max_depth=4,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=225,\n",
      "              num_leaves=50, reg_alpha=0, reg_lambda=0.01, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.6130\n",
      "Blended average after 4 repeats: 0.4401\n",
      "344.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.05, max_depth=1,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.6017\n",
      "Blended average after 5 repeats: 0.4257\n",
      "417.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=350, num_leaves=30,\n",
      "              reg_alpha=1, reg_lambda=0, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.6345\n",
      "Blended average after 6 repeats: 0.4365\n",
      "483.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=0.1, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.6286\n",
      "Blended average after 7 repeats: 0.4294\n",
      "553.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=225, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                         gain\n",
      "feature                      \n",
      "Waist_max         1139.448980\n",
      "Waist_iliac_mean   258.142857\n",
      "BMI                223.408163\n",
      "Waist_iliac_max    220.448980\n",
      "Waist_std          169.142857\n",
      "Neck_mean           89.204082\n",
      "V1AD01b             76.367347\n",
      "Hip_mean            75.285714\n",
      "Hip_max             69.857143\n",
      "V1BA01_LB           64.265306\n",
      "         gain\n",
      "feature      \n",
      "S02G07    0.0\n",
      "S02G08    0.0\n",
      "S02G09    0.0\n",
      "S02G10    0.0\n",
      "S02G11    0.0\n",
      "S02G12    0.0\n",
      "S02G13    0.0\n",
      "S02G14    0.0\n",
      "S02H01    0.0\n",
      "V1AF15f   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA18_lgb2d_pred  V2IA19_lgb2d_pred  V2IA20_lgb2d_pred  \\\n",
      "0              3.050639           3.031903           2.952912   \n",
      "1              3.396756           3.281445           4.196418   \n",
      "2              3.469022           4.031415           3.538537   \n",
      "3              4.065837           4.237428           3.848621   \n",
      "4              4.560027           4.658599           4.065863   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.614854           3.195634           3.767677   \n",
      "9285           4.159484           4.627473           4.656540   \n",
      "9286           4.158358           4.230359           3.790593   \n",
      "9287           3.151507           3.514431           3.536387   \n",
      "9288           3.612031           4.245505           4.040868   \n",
      "\n",
      "      V2IA21_lgb2d_pred  V2IA22_lgb2d_pred  V2IA23_lgb2d_pred  \\\n",
      "0              4.014307           3.527286           2.772844   \n",
      "1              4.787561           4.005398           3.564243   \n",
      "2              4.427811           4.530441           4.068708   \n",
      "3              4.478790           4.183159           3.973097   \n",
      "4              5.021653           4.838427           4.670542   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.466472           3.715120           3.403406   \n",
      "9285           4.913910           4.887447           4.642883   \n",
      "9286           4.409862           4.493075           4.586488   \n",
      "9287           4.239118           4.176339           3.677629   \n",
      "9288           4.901067           4.662976           4.634715   \n",
      "\n",
      "      V2IA24_lgb2d_pred  V2IA25_lgb2d_pred  Height_mean_lgb2d_pred  \\\n",
      "0              3.893282           3.710022              154.695279   \n",
      "1              3.974833           4.813471              166.982064   \n",
      "2              4.669150           4.826686              160.020190   \n",
      "3              4.139214           4.718632              175.122315   \n",
      "4              4.759040           5.019340              174.014453   \n",
      "...                 ...                ...                     ...   \n",
      "9284           3.974833           4.420971              169.537135   \n",
      "9285           4.870740           4.970893              156.687095   \n",
      "9286           4.345400           4.760608              168.002014   \n",
      "9287           4.013332           4.490196              136.082293   \n",
      "9288           4.970099           4.949663              160.400018   \n",
      "\n",
      "      Waist_mean_lgb2d_pred  \n",
      "0                 86.477571  \n",
      "1                 71.096942  \n",
      "2                 75.102741  \n",
      "3                 90.047908  \n",
      "4                 82.850209  \n",
      "...                     ...  \n",
      "9284              79.956838  \n",
      "9285              80.912099  \n",
      "9286              97.374471  \n",
      "9287              61.008549  \n",
      "9288              94.896944  \n",
      "\n",
      "[9289 rows x 47 columns]\n",
      "lgb2d.csv (9289, 47)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "637/654 Waist_iliac_mean 1577 0.030\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9014, 4271) (275, 4271)\n",
      "(9014, 653) (9014,) (275, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 1.1492\n",
      "Blended average after 1 repeats: 1.1489\n",
      "79.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=0.0001, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 1.1518\n",
      "Blended average after 2 repeats: 0.9530\n",
      "146.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, max_depth=3, min_child_samples=10,\n",
      "              min_child_weight=0, min_split_gain=0, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=0.01, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 1.1610\n",
      "Blended average after 3 repeats: 0.8911\n",
      "221.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.05, max_depth=7,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=350,\n",
      "              num_leaves=50, reg_alpha=10, reg_lambda=0.0001, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 1.0826\n",
      "Blended average after 4 repeats: 0.8047\n",
      "291.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.05, max_depth=5,\n",
      "              min_child_weight=0, min_split_gain=0.0001, n_estimators=350,\n",
      "              num_leaves=30, reg_alpha=0.1, reg_lambda=0.001, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 1.0009\n",
      "Blended average after 5 repeats: 0.7325\n",
      "375.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, max_depth=6, min_child_samples=4,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=150,\n",
      "              num_leaves=100, reg_alpha=0.1, reg_lambda=0.0001, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.9988\n",
      "Blended average after 6 repeats: 0.7200\n",
      "444.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, max_depth=5,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.9632\n",
      "Blended average after 7 repeats: 0.6800\n",
      "528.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=50, reg_alpha=0.01,\n",
      "              reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                       gain\n",
      "feature                    \n",
      "Waist_iliac_max  933.877551\n",
      "Hip_mean         179.020408\n",
      "Waist_iliac_std  162.306122\n",
      "Hip_max          157.857143\n",
      "Waist_mean       154.326531\n",
      "Waist_max        136.510204\n",
      "BMI               67.306122\n",
      "V1AD01b           62.591837\n",
      "V1BA01_LB         57.204082\n",
      "V2BA01_LB         34.918367\n",
      "             gain\n",
      "feature          \n",
      "V1AE2_04g_1   0.0\n",
      "S02G05        0.0\n",
      "S02G04        0.0\n",
      "V2AH03        0.0\n",
      "V2AH04        0.0\n",
      "S02B02        0.0\n",
      "S01A05        0.0\n",
      "V1AF06g       0.0\n",
      "S02G03        0.0\n",
      "S02G02        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA19_lgb2d_pred  V2IA20_lgb2d_pred  V2IA21_lgb2d_pred  \\\n",
      "0              3.031903           2.952912           4.014307   \n",
      "1              3.281445           4.196418           4.787561   \n",
      "2              4.031415           3.538537           4.427811   \n",
      "3              4.237428           3.848621           4.478790   \n",
      "4              4.658599           4.065863           5.021653   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.195634           3.767677           4.466472   \n",
      "9285           4.627473           4.656540           4.913910   \n",
      "9286           4.230359           3.790593           4.409862   \n",
      "9287           3.514431           3.536387           4.239118   \n",
      "9288           4.245505           4.040868           4.901067   \n",
      "\n",
      "      V2IA22_lgb2d_pred  V2IA23_lgb2d_pred  V2IA24_lgb2d_pred  \\\n",
      "0              3.527286           2.772844           3.893282   \n",
      "1              4.005398           3.564243           3.974833   \n",
      "2              4.530441           4.068708           4.669150   \n",
      "3              4.183159           3.973097           4.139214   \n",
      "4              4.838427           4.670542           4.759040   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.715120           3.403406           3.974833   \n",
      "9285           4.887447           4.642883           4.870740   \n",
      "9286           4.493075           4.586488           4.345400   \n",
      "9287           4.176339           3.677629           4.013332   \n",
      "9288           4.662976           4.634715           4.970099   \n",
      "\n",
      "      V2IA25_lgb2d_pred  Height_mean_lgb2d_pred  Waist_mean_lgb2d_pred  \\\n",
      "0              3.710022              154.695279              86.477571   \n",
      "1              4.813471              166.982064              71.096942   \n",
      "2              4.826686              160.020190              75.102741   \n",
      "3              4.718632              175.122315              90.047908   \n",
      "4              5.019340              174.014453              82.850209   \n",
      "...                 ...                     ...                    ...   \n",
      "9284           4.420971              169.537135              79.956838   \n",
      "9285           4.970893              156.687095              80.912099   \n",
      "9286           4.760608              168.002014              97.374471   \n",
      "9287           4.490196              136.082293              61.008549   \n",
      "9288           4.949663              160.400018              94.896944   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  \n",
      "0                      106.095585  \n",
      "1                       79.850034  \n",
      "2                       88.960430  \n",
      "3                      101.988971  \n",
      "4                       94.336494  \n",
      "...                           ...  \n",
      "9284                    90.706608  \n",
      "9285                    90.059695  \n",
      "9286                    99.153321  \n",
      "9287                    62.518523  \n",
      "9288                   105.402003  \n",
      "\n",
      "[9289 rows x 48 columns]\n",
      "lgb2d.csv (9289, 48)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "638/654 Hip_mean 1416 0.030\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9010, 4271) (279, 4271)\n",
      "(9010, 653) (9010,) (279, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.7452\n",
      "Blended average after 1 repeats: 0.7453\n",
      "74.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=7,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=1, reg_lambda=0,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.8283\n",
      "Blended average after 2 repeats: 0.6990\n",
      "157.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=1, reg_lambda=100,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.8378\n",
      "Blended average after 3 repeats: 0.6702\n",
      "228.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=0.01,\n",
      "              reg_lambda=0.001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.8992\n",
      "Blended average after 4 repeats: 0.6831\n",
      "306.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.07, max_depth=7,\n",
      "              min_child_weight=0, min_split_gain=0.01, n_estimators=150,\n",
      "              num_leaves=30, reg_alpha=1, reg_lambda=0.01, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.9761\n",
      "Blended average after 5 repeats: 0.7287\n",
      "380.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=2,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.01, reg_lambda=1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 1.0334\n",
      "Blended average after 6 repeats: 0.7376\n",
      "451.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=20, reg_alpha=0.1,\n",
      "              reg_lambda=0.0001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 1.0511\n",
      "Blended average after 7 repeats: 0.7495\n",
      "525.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, max_depth=5,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=50, num_leaves=50, reg_alpha=0.001, reg_lambda=0,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                        gain\n",
      "feature                     \n",
      "Hip_max           952.938776\n",
      "Waist_iliac_max   180.530612\n",
      "Waist_iliac_mean  176.163265\n",
      "V1BA01_LB         135.591837\n",
      "V1AD01b           125.326531\n",
      "Hip_std           100.142857\n",
      "BMI                97.816327\n",
      "V2BA01_LB          60.857143\n",
      "Waist_mean         45.510204\n",
      "Waist_max          42.591837\n",
      "         gain\n",
      "feature      \n",
      "V2AF05h   0.0\n",
      "V2AH04    0.0\n",
      "S02G03    0.0\n",
      "V2AF01g   0.0\n",
      "S01A05    0.0\n",
      "S01A01    0.0\n",
      "S02G01    0.0\n",
      "V2AF01b   0.0\n",
      "S02B03    0.0\n",
      "S02G08    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA20_lgb2d_pred  V2IA21_lgb2d_pred  V2IA22_lgb2d_pred  \\\n",
      "0              2.952912           4.014307           3.527286   \n",
      "1              4.196418           4.787561           4.005398   \n",
      "2              3.538537           4.427811           4.530441   \n",
      "3              3.848621           4.478790           4.183159   \n",
      "4              4.065863           5.021653           4.838427   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.767677           4.466472           3.715120   \n",
      "9285           4.656540           4.913910           4.887447   \n",
      "9286           3.790593           4.409862           4.493075   \n",
      "9287           3.536387           4.239118           4.176339   \n",
      "9288           4.040868           4.901067           4.662976   \n",
      "\n",
      "      V2IA23_lgb2d_pred  V2IA24_lgb2d_pred  V2IA25_lgb2d_pred  \\\n",
      "0              2.772844           3.893282           3.710022   \n",
      "1              3.564243           3.974833           4.813471   \n",
      "2              4.068708           4.669150           4.826686   \n",
      "3              3.973097           4.139214           4.718632   \n",
      "4              4.670542           4.759040           5.019340   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.403406           3.974833           4.420971   \n",
      "9285           4.642883           4.870740           4.970893   \n",
      "9286           4.586488           4.345400           4.760608   \n",
      "9287           3.677629           4.013332           4.490196   \n",
      "9288           4.634715           4.970099           4.949663   \n",
      "\n",
      "      Height_mean_lgb2d_pred  Waist_mean_lgb2d_pred  \\\n",
      "0                 154.695279              86.477571   \n",
      "1                 166.982064              71.096942   \n",
      "2                 160.020190              75.102741   \n",
      "3                 175.122315              90.047908   \n",
      "4                 174.014453              82.850209   \n",
      "...                      ...                    ...   \n",
      "9284              169.537135              79.956838   \n",
      "9285              156.687095              80.912099   \n",
      "9286              168.002014              97.374471   \n",
      "9287              136.082293              61.008549   \n",
      "9288              160.400018              94.896944   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \n",
      "0                      106.095585           113.612766  \n",
      "1                       79.850034            98.098173  \n",
      "2                       88.960430            96.672578  \n",
      "3                      101.988971           111.922213  \n",
      "4                       94.336494            96.426516  \n",
      "...                           ...                  ...  \n",
      "9284                    90.706608           108.033284  \n",
      "9285                    90.059695            91.389706  \n",
      "9286                    99.153321           101.511207  \n",
      "9287                    62.518523            72.863082  \n",
      "9288                   105.402003           114.809245  \n",
      "\n",
      "[9289 rows x 49 columns]\n",
      "lgb2d.csv (9289, 49)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "639/654 BP_Sys_mean 116 0.022\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9087, 4271) (202, 4271)\n",
      "(9087, 653) (9087,) (202, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.1970\n",
      "Blended average after 1 repeats: 0.1970\n",
      "71.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, max_depth=1,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.001, reg_lambda=100,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.1893\n",
      "Blended average after 2 repeats: 0.1417\n",
      "145.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=50,\n",
      "              reg_alpha=0.1, reg_lambda=0.1, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1944\n",
      "Blended average after 3 repeats: 0.1336\n",
      "216.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.01, reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1878\n",
      "Blended average after 4 repeats: 0.1208\n",
      "300.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=0.0001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1928\n",
      "Blended average after 5 repeats: 0.1181\n",
      "376.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=30,\n",
      "              reg_alpha=0.1, reg_lambda=1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1811\n",
      "Blended average after 6 repeats: 0.1107\n",
      "461.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=10, reg_lambda=1e-05, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1828\n",
      "Blended average after 7 repeats: 0.1116\n",
      "525.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, max_depth=1,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0, reg_lambda=10,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "BP_Sys_max   665.836735\n",
      "BP_Dia_mean  461.918367\n",
      "BP_Dia_max   341.693878\n",
      "BP_Sys_std   279.938776\n",
      "V2BA02a1      72.346939\n",
      "V2BA02b1      50.489796\n",
      "V1BA01_LB     40.387755\n",
      "BMI           34.959184\n",
      "V2BA01_LB     33.428571\n",
      "Waist_mean    31.959184\n",
      "             gain\n",
      "feature          \n",
      "V1HVer        0.0\n",
      "V1AF15g       0.0\n",
      "S02G03        0.0\n",
      "S02G04        0.0\n",
      "S02G05        0.0\n",
      "S02G06        0.0\n",
      "V1AE2_04g_1   0.0\n",
      "V2AF05h       0.0\n",
      "V1AF15f       0.0\n",
      "V2AF25h       0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA21_lgb2d_pred  V2IA22_lgb2d_pred  V2IA23_lgb2d_pred  \\\n",
      "0              4.014307           3.527286           2.772844   \n",
      "1              4.787561           4.005398           3.564243   \n",
      "2              4.427811           4.530441           4.068708   \n",
      "3              4.478790           4.183159           3.973097   \n",
      "4              5.021653           4.838427           4.670542   \n",
      "...                 ...                ...                ...   \n",
      "9284           4.466472           3.715120           3.403406   \n",
      "9285           4.913910           4.887447           4.642883   \n",
      "9286           4.409862           4.493075           4.586488   \n",
      "9287           4.239118           4.176339           3.677629   \n",
      "9288           4.901067           4.662976           4.634715   \n",
      "\n",
      "      V2IA24_lgb2d_pred  V2IA25_lgb2d_pred  Height_mean_lgb2d_pred  \\\n",
      "0              3.893282           3.710022              154.695279   \n",
      "1              3.974833           4.813471              166.982064   \n",
      "2              4.669150           4.826686              160.020190   \n",
      "3              4.139214           4.718632              175.122315   \n",
      "4              4.759040           5.019340              174.014453   \n",
      "...                 ...                ...                     ...   \n",
      "9284           3.974833           4.420971              169.537135   \n",
      "9285           4.870740           4.970893              156.687095   \n",
      "9286           4.345400           4.760608              168.002014   \n",
      "9287           4.013332           4.490196              136.082293   \n",
      "9288           4.970099           4.949663              160.400018   \n",
      "\n",
      "      Waist_mean_lgb2d_pred  Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                 86.477571                   106.095585           113.612766   \n",
      "1                 71.096942                    79.850034            98.098173   \n",
      "2                 75.102741                    88.960430            96.672578   \n",
      "3                 90.047908                   101.988971           111.922213   \n",
      "4                 82.850209                    94.336494            96.426516   \n",
      "...                     ...                          ...                  ...   \n",
      "9284              79.956838                    90.706608           108.033284   \n",
      "9285              80.912099                    90.059695            91.389706   \n",
      "9286              97.374471                    99.153321           101.511207   \n",
      "9287              61.008549                    62.518523            72.863082   \n",
      "9288              94.896944                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  \n",
      "0                  89.952794  \n",
      "1                  77.897491  \n",
      "2                  91.013300  \n",
      "3                  85.137558  \n",
      "4                  88.113994  \n",
      "...                      ...  \n",
      "9284               84.031085  \n",
      "9285               89.116733  \n",
      "9286               90.869248  \n",
      "9287               60.178849  \n",
      "9288               83.099290  \n",
      "\n",
      "[9289 rows x 50 columns]\n",
      "lgb2d.csv (9289, 50)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "640/654 BP_Dia_mean 77 0.022\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9087, 4271) (202, 4271)\n",
      "(9087, 653) (9087,) (202, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2855\n",
      "Blended average after 1 repeats: 0.2855\n",
      "72.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=6,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.01,\n",
      "              num_leaves=20, reg_alpha=0, reg_lambda=0.0001, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3131\n",
      "Blended average after 2 repeats: 0.2665\n",
      "140.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=50, reg_alpha=1,\n",
      "              reg_lambda=0.1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.2878\n",
      "Blended average after 3 repeats: 0.2368\n",
      "223.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=0.01, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.2886\n",
      "Blended average after 4 repeats: 0.2307\n",
      "297.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=50, reg_alpha=10, reg_lambda=0.1,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.2850\n",
      "Blended average after 5 repeats: 0.2264\n",
      "366.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, max_depth=3,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=20, reg_alpha=10, reg_lambda=0.0001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.2954\n",
      "Blended average after 6 repeats: 0.2320\n",
      "434.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=50, reg_alpha=0.1,\n",
      "              reg_lambda=1e-05, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.2874\n",
      "Blended average after 7 repeats: 0.2255\n",
      "501.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=0.0001, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "BP_Dia_max   742.734694\n",
      "BP_Sys_mean  318.142857\n",
      "BP_Sys_std   289.102041\n",
      "BP_Sys_max   117.551020\n",
      "V2BA02b1      49.163265\n",
      "V2BA02a1      38.591837\n",
      "CLAA01b       25.795918\n",
      "CLAA01c       23.959184\n",
      "V1BA01_LB     23.775510\n",
      "CLAA01a       22.816327\n",
      "           gain\n",
      "feature        \n",
      "S01A08      0.0\n",
      "V2AF25h     0.0\n",
      "S02Ver      0.0\n",
      "V2AF22h     0.0\n",
      "S02H01      0.0\n",
      "V2AF22e     0.0\n",
      "S02G14      0.0\n",
      "S02G13      0.0\n",
      "S02G12      0.0\n",
      "S02ECheck   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA22_lgb2d_pred  V2IA23_lgb2d_pred  V2IA24_lgb2d_pred  \\\n",
      "0              3.527286           2.772844           3.893282   \n",
      "1              4.005398           3.564243           3.974833   \n",
      "2              4.530441           4.068708           4.669150   \n",
      "3              4.183159           3.973097           4.139214   \n",
      "4              4.838427           4.670542           4.759040   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.715120           3.403406           3.974833   \n",
      "9285           4.887447           4.642883           4.870740   \n",
      "9286           4.493075           4.586488           4.345400   \n",
      "9287           4.176339           3.677629           4.013332   \n",
      "9288           4.662976           4.634715           4.970099   \n",
      "\n",
      "      V2IA25_lgb2d_pred  Height_mean_lgb2d_pred  Waist_mean_lgb2d_pred  \\\n",
      "0              3.710022              154.695279              86.477571   \n",
      "1              4.813471              166.982064              71.096942   \n",
      "2              4.826686              160.020190              75.102741   \n",
      "3              4.718632              175.122315              90.047908   \n",
      "4              5.019340              174.014453              82.850209   \n",
      "...                 ...                     ...                    ...   \n",
      "9284           4.420971              169.537135              79.956838   \n",
      "9285           4.970893              156.687095              80.912099   \n",
      "9286           4.760608              168.002014              97.374471   \n",
      "9287           4.490196              136.082293              61.008549   \n",
      "9288           4.949663              160.400018              94.896944   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                      106.095585           113.612766   \n",
      "1                       79.850034            98.098173   \n",
      "2                       88.960430            96.672578   \n",
      "3                      101.988971           111.922213   \n",
      "4                       94.336494            96.426516   \n",
      "...                           ...                  ...   \n",
      "9284                    90.706608           108.033284   \n",
      "9285                    90.059695            91.389706   \n",
      "9286                    99.153321           101.511207   \n",
      "9287                    62.518523            72.863082   \n",
      "9288                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  \n",
      "0                  89.952794               69.844140  \n",
      "1                  77.897491               61.978064  \n",
      "2                  91.013300               60.104043  \n",
      "3                  85.137558               62.107580  \n",
      "4                  88.113994               73.979982  \n",
      "...                      ...                     ...  \n",
      "9284               84.031085               68.057116  \n",
      "9285               89.116733               67.914896  \n",
      "9286               90.869248               72.108074  \n",
      "9287               60.178849               43.501362  \n",
      "9288               83.099290               64.402220  \n",
      "\n",
      "[9289 rows x 51 columns]\n",
      "lgb2d.csv (9289, 51)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "641/654 Neck_mean 470 0.145\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(7944, 4271) (1345, 4271)\n",
      "(7944, 653) (7944,) (1345, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.1601\n",
      "Blended average after 1 repeats: 0.1601\n",
      "75.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0, reg_lambda=1e-05,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.1838\n",
      "Blended average after 2 repeats: 0.1705\n",
      "145.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, num_leaves=30, reg_alpha=0.001,\n",
      "              reg_lambda=0.01, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1800\n",
      "Blended average after 3 repeats: 0.1598\n",
      "209.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=50, num_leaves=100,\n",
      "              reg_alpha=0.1, reg_lambda=0.0001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1860\n",
      "Blended average after 4 repeats: 0.1599\n",
      "279.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0.001,\n",
      "              num_leaves=30, reg_alpha=0.1, reg_lambda=0.0001, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1815\n",
      "Blended average after 5 repeats: 0.1551\n",
      "341.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, max_depth=7,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.001, reg_lambda=0.1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1854\n",
      "Blended average after 6 repeats: 0.1577\n",
      "401.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, max_depth=3,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=0, reg_lambda=100,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1833\n",
      "Blended average after 7 repeats: 0.1551\n",
      "467.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, learning_rate=0.07, max_depth=6,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.01,\n",
      "              reg_lambda=0.0001, subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                        gain\n",
      "feature                     \n",
      "Neck_max          904.857143\n",
      "Neck_std          181.836735\n",
      "Waist_mean        155.183673\n",
      "Waist_max         132.469388\n",
      "Waist_iliac_mean   65.755102\n",
      "V1BA01_LB          61.979592\n",
      "BMI                59.346939\n",
      "V1AD01b            58.612245\n",
      "Waist_iliac_max    57.122449\n",
      "Hip_mean           50.265306\n",
      "         gain\n",
      "feature      \n",
      "S02G02    0.0\n",
      "S02G11    0.0\n",
      "S02G03    0.0\n",
      "S02G04    0.0\n",
      "S02G05    0.0\n",
      "S02G06    0.0\n",
      "S02G08    0.0\n",
      "S02G09    0.0\n",
      "S02G10    0.0\n",
      "S02E04    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA23_lgb2d_pred  V2IA24_lgb2d_pred  V2IA25_lgb2d_pred  \\\n",
      "0              2.772844           3.893282           3.710022   \n",
      "1              3.564243           3.974833           4.813471   \n",
      "2              4.068708           4.669150           4.826686   \n",
      "3              3.973097           4.139214           4.718632   \n",
      "4              4.670542           4.759040           5.019340   \n",
      "...                 ...                ...                ...   \n",
      "9284           3.403406           3.974833           4.420971   \n",
      "9285           4.642883           4.870740           4.970893   \n",
      "9286           4.586488           4.345400           4.760608   \n",
      "9287           3.677629           4.013332           4.490196   \n",
      "9288           4.634715           4.970099           4.949663   \n",
      "\n",
      "      Height_mean_lgb2d_pred  Waist_mean_lgb2d_pred  \\\n",
      "0                 154.695279              86.477571   \n",
      "1                 166.982064              71.096942   \n",
      "2                 160.020190              75.102741   \n",
      "3                 175.122315              90.047908   \n",
      "4                 174.014453              82.850209   \n",
      "...                      ...                    ...   \n",
      "9284              169.537135              79.956838   \n",
      "9285              156.687095              80.912099   \n",
      "9286              168.002014              97.374471   \n",
      "9287              136.082293              61.008549   \n",
      "9288              160.400018              94.896944   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                      106.095585           113.612766   \n",
      "1                       79.850034            98.098173   \n",
      "2                       88.960430            96.672578   \n",
      "3                      101.988971           111.922213   \n",
      "4                       94.336494            96.426516   \n",
      "...                           ...                  ...   \n",
      "9284                    90.706608           108.033284   \n",
      "9285                    90.059695            91.389706   \n",
      "9286                    99.153321           101.511207   \n",
      "9287                    62.518523            72.863082   \n",
      "9288                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \n",
      "0                  89.952794               69.844140             32.659866  \n",
      "1                  77.897491               61.978064             27.723693  \n",
      "2                  91.013300               60.104043             32.101309  \n",
      "3                  85.137558               62.107580             34.384121  \n",
      "4                  88.113994               73.979982             31.502494  \n",
      "...                      ...                     ...                   ...  \n",
      "9284               84.031085               68.057116             28.132116  \n",
      "9285               89.116733               67.914896             33.865633  \n",
      "9286               90.869248               72.108074             34.866149  \n",
      "9287               60.178849               43.501362             23.147521  \n",
      "9288               83.099290               64.402220             37.850102  \n",
      "\n",
      "[9289 rows x 52 columns]\n",
      "lgb2d.csv (9289, 52)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "642/654 Height_std 58 0.034\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8969, 4271) (320, 4271)\n",
      "(8969, 653) (8969,) (320, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2012\n",
      "Blended average after 1 repeats: 0.2012\n",
      "65.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.001,\n",
      "              num_leaves=20, reg_alpha=1, reg_lambda=10, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.1983\n",
      "Blended average after 2 repeats: 0.1977\n",
      "129.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=50, num_leaves=100,\n",
      "              reg_alpha=0, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1990\n",
      "Blended average after 3 repeats: 0.1980\n",
      "194.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=20,\n",
      "              reg_alpha=1, reg_lambda=0.01, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1994\n",
      "Blended average after 4 repeats: 0.1985\n",
      "262.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1997\n",
      "Blended average after 5 repeats: 0.1987\n",
      "333.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=50, num_leaves=50,\n",
      "              reg_alpha=1, reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1997\n",
      "Blended average after 6 repeats: 0.1987\n",
      "392.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, max_depth=7,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=150,\n",
      "              num_leaves=30, reg_alpha=10, reg_lambda=100, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1985\n",
      "Blended average after 7 repeats: 0.1974\n",
      "464.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=50,\n",
      "              reg_alpha=1, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                      gain\n",
      "feature                   \n",
      "Height_mean      96.551020\n",
      "Height_max       52.040816\n",
      "V1KA04_HR        48.204082\n",
      "Waist_iliac_std  40.836735\n",
      "BP_Sys_std       39.673469\n",
      "V2AF25c          36.734694\n",
      "V1BA01_LB        31.918367\n",
      "V2BA01_LB        27.530612\n",
      "Waist_std        26.775510\n",
      "V1KA02_HR        23.285714\n",
      "         gain\n",
      "feature      \n",
      "V1AF07d   0.0\n",
      "V2AF25h   0.0\n",
      "V2AF25g   0.0\n",
      "S02E02    0.0\n",
      "V2AF25e   0.0\n",
      "S02D07    0.0\n",
      "S02B03    0.0\n",
      "S02B02    0.0\n",
      "V1LF01a   0.0\n",
      "S02E04    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA24_lgb2d_pred  V2IA25_lgb2d_pred  Height_mean_lgb2d_pred  \\\n",
      "0              3.893282           3.710022              154.695279   \n",
      "1              3.974833           4.813471              166.982064   \n",
      "2              4.669150           4.826686              160.020190   \n",
      "3              4.139214           4.718632              175.122315   \n",
      "4              4.759040           5.019340              174.014453   \n",
      "...                 ...                ...                     ...   \n",
      "9284           3.974833           4.420971              169.537135   \n",
      "9285           4.870740           4.970893              156.687095   \n",
      "9286           4.345400           4.760608              168.002014   \n",
      "9287           4.013332           4.490196              136.082293   \n",
      "9288           4.970099           4.949663              160.400018   \n",
      "\n",
      "      Waist_mean_lgb2d_pred  Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                 86.477571                   106.095585           113.612766   \n",
      "1                 71.096942                    79.850034            98.098173   \n",
      "2                 75.102741                    88.960430            96.672578   \n",
      "3                 90.047908                   101.988971           111.922213   \n",
      "4                 82.850209                    94.336494            96.426516   \n",
      "...                     ...                          ...                  ...   \n",
      "9284              79.956838                    90.706608           108.033284   \n",
      "9285              80.912099                    90.059695            91.389706   \n",
      "9286              97.374471                    99.153321           101.511207   \n",
      "9287              61.008549                    62.518523            72.863082   \n",
      "9288              94.896944                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \\\n",
      "0                  89.952794               69.844140             32.659866   \n",
      "1                  77.897491               61.978064             27.723693   \n",
      "2                  91.013300               60.104043             32.101309   \n",
      "3                  85.137558               62.107580             34.384121   \n",
      "4                  88.113994               73.979982             31.502494   \n",
      "...                      ...                     ...                   ...   \n",
      "9284               84.031085               68.057116             28.132116   \n",
      "9285               89.116733               67.914896             33.865633   \n",
      "9286               90.869248               72.108074             34.866149   \n",
      "9287               60.178849               43.501362             23.147521   \n",
      "9288               83.099290               64.402220             37.850102   \n",
      "\n",
      "      Height_std_lgb2d_pred  \n",
      "0                  0.057386  \n",
      "1                  0.025927  \n",
      "2                  0.015815  \n",
      "3                  0.046316  \n",
      "4                  0.010494  \n",
      "...                     ...  \n",
      "9284               0.079732  \n",
      "9285               0.043317  \n",
      "9286              -0.003767  \n",
      "9287               0.293462  \n",
      "9288               0.027827  \n",
      "\n",
      "[9289 rows x 53 columns]\n",
      "lgb2d.csv (9289, 53)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "643/654 Waist_std 163 0.034\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8972, 4271) (317, 4271)\n",
      "(8972, 653) (8972,) (317, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0501\n",
      "Blended average after 1 repeats: 0.0501\n",
      "65.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.001, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0501\n",
      "Blended average after 2 repeats: 0.0498\n",
      "126.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.05, max_depth=3,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=100, reg_alpha=1, reg_lambda=100, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0501\n",
      "Blended average after 3 repeats: 0.0498\n",
      "202.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=50, num_leaves=30, reg_alpha=0,\n",
      "              reg_lambda=0, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0502\n",
      "Blended average after 4 repeats: 0.0499\n",
      "280.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=7, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=50, num_leaves=30,\n",
      "              reg_alpha=0.01, reg_lambda=0.001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0502\n",
      "Blended average after 5 repeats: 0.0499\n",
      "361.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=20, reg_alpha=0,\n",
      "              reg_lambda=1, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0503\n",
      "Blended average after 6 repeats: 0.0498\n",
      "427.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0503\n",
      "Blended average after 7 repeats: 0.0498\n",
      "495.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, num_leaves=20, reg_alpha=1, reg_lambda=100,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                      gain\n",
      "feature                   \n",
      "Waist_iliac_std  79.693878\n",
      "Hip_std          70.489796\n",
      "Neck_std         55.591837\n",
      "Waist_max        26.204082\n",
      "Height_std       24.673469\n",
      "CLAE02a1         21.326531\n",
      "V2AE01a_OZ       15.571429\n",
      "CLAA01b          15.551020\n",
      "CLAA01a          15.285714\n",
      "PctFedPoverty    14.265306\n",
      "             gain\n",
      "feature          \n",
      "V2AF18i       0.0\n",
      "S01Ver        0.0\n",
      "S01BCheck     0.0\n",
      "V2AF18f       0.0\n",
      "V2AF18e       0.0\n",
      "V2AF18c       0.0\n",
      "V1AE2_04c_1   0.0\n",
      "V2AF17e       0.0\n",
      "V2AF17d       0.0\n",
      "V1AF12i       0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      V2IA25_lgb2d_pred  Height_mean_lgb2d_pred  Waist_mean_lgb2d_pred  \\\n",
      "0              3.710022              154.695279              86.477571   \n",
      "1              4.813471              166.982064              71.096942   \n",
      "2              4.826686              160.020190              75.102741   \n",
      "3              4.718632              175.122315              90.047908   \n",
      "4              5.019340              174.014453              82.850209   \n",
      "...                 ...                     ...                    ...   \n",
      "9284           4.420971              169.537135              79.956838   \n",
      "9285           4.970893              156.687095              80.912099   \n",
      "9286           4.760608              168.002014              97.374471   \n",
      "9287           4.490196              136.082293              61.008549   \n",
      "9288           4.949663              160.400018              94.896944   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                      106.095585           113.612766   \n",
      "1                       79.850034            98.098173   \n",
      "2                       88.960430            96.672578   \n",
      "3                      101.988971           111.922213   \n",
      "4                       94.336494            96.426516   \n",
      "...                           ...                  ...   \n",
      "9284                    90.706608           108.033284   \n",
      "9285                    90.059695            91.389706   \n",
      "9286                    99.153321           101.511207   \n",
      "9287                    62.518523            72.863082   \n",
      "9288                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \\\n",
      "0                  89.952794               69.844140             32.659866   \n",
      "1                  77.897491               61.978064             27.723693   \n",
      "2                  91.013300               60.104043             32.101309   \n",
      "3                  85.137558               62.107580             34.384121   \n",
      "4                  88.113994               73.979982             31.502494   \n",
      "...                      ...                     ...                   ...   \n",
      "9284               84.031085               68.057116             28.132116   \n",
      "9285               89.116733               67.914896             33.865633   \n",
      "9286               90.869248               72.108074             34.866149   \n",
      "9287               60.178849               43.501362             23.147521   \n",
      "9288               83.099290               64.402220             37.850102   \n",
      "\n",
      "      Height_std_lgb2d_pred  Waist_std_lgb2d_pred  \n",
      "0                  0.057386              0.054053  \n",
      "1                  0.025927              0.019241  \n",
      "2                  0.015815              0.082272  \n",
      "3                  0.046316              0.182075  \n",
      "4                  0.010494              0.027979  \n",
      "...                     ...                   ...  \n",
      "9284               0.079732              0.210128  \n",
      "9285               0.043317              0.033824  \n",
      "9286              -0.003767              0.010504  \n",
      "9287               0.293462              0.176150  \n",
      "9288               0.027827              0.035395  \n",
      "\n",
      "[9289 rows x 54 columns]\n",
      "lgb2d.csv (9289, 54)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "644/654 Waist_iliac_std 194 0.034\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8972, 4271) (317, 4271)\n",
      "(8972, 653) (8972,) (317, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4800\n",
      "Blended average after 1 repeats: 0.4801\n",
      "70.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=50, num_leaves=50, reg_alpha=0.01,\n",
      "              reg_lambda=1e-05, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.4807\n",
      "Blended average after 2 repeats: 0.4793\n",
      "137.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, max_depth=3,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=50, num_leaves=20, reg_alpha=0.01, reg_lambda=0.001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.4803\n",
      "Blended average after 3 repeats: 0.4784\n",
      "199.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.65, max_depth=3,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=10, reg_lambda=100,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4807\n",
      "Blended average after 4 repeats: 0.4785\n",
      "261.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50, reg_alpha=0.1,\n",
      "              reg_lambda=1e-05, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4807\n",
      "Blended average after 5 repeats: 0.4783\n",
      "324.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=100, reg_alpha=0.001,\n",
      "              reg_lambda=0.0001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4802\n",
      "Blended average after 6 repeats: 0.4779\n",
      "389.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, max_depth=3,\n",
      "              min_child_samples=100, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=50, num_leaves=50, reg_alpha=0.01, reg_lambda=0.01,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4804\n",
      "Blended average after 7 repeats: 0.4779\n",
      "466.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, max_depth=7,\n",
      "              min_child_weight=0, min_split_gain=0.01, n_estimators=50,\n",
      "              num_leaves=50, reg_alpha=0, reg_lambda=100, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                       gain\n",
      "feature                    \n",
      "Waist_std         89.387755\n",
      "Waist_iliac_mean  47.530612\n",
      "Hip_std           45.857143\n",
      "Waist_iliac_max   39.551020\n",
      "Neck_std          34.795918\n",
      "V1LA03            23.857143\n",
      "S01A03            15.040816\n",
      "Height_std        14.510204\n",
      "CLAE02a1          13.571429\n",
      "V2AJ02a2          11.530612\n",
      "         gain\n",
      "feature      \n",
      "V2AF25c   0.0\n",
      "S02Ver    0.0\n",
      "V1AD12d   0.0\n",
      "V2AF22h   0.0\n",
      "S01B03c   0.0\n",
      "V2AF22e   0.0\n",
      "V1AG09    0.0\n",
      "S01B03b   0.0\n",
      "V1AA01    0.0\n",
      "S02D07    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Height_mean_lgb2d_pred  Waist_mean_lgb2d_pred  \\\n",
      "0                 154.695279              86.477571   \n",
      "1                 166.982064              71.096942   \n",
      "2                 160.020190              75.102741   \n",
      "3                 175.122315              90.047908   \n",
      "4                 174.014453              82.850209   \n",
      "...                      ...                    ...   \n",
      "9284              169.537135              79.956838   \n",
      "9285              156.687095              80.912099   \n",
      "9286              168.002014              97.374471   \n",
      "9287              136.082293              61.008549   \n",
      "9288              160.400018              94.896944   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                      106.095585           113.612766   \n",
      "1                       79.850034            98.098173   \n",
      "2                       88.960430            96.672578   \n",
      "3                      101.988971           111.922213   \n",
      "4                       94.336494            96.426516   \n",
      "...                           ...                  ...   \n",
      "9284                    90.706608           108.033284   \n",
      "9285                    90.059695            91.389706   \n",
      "9286                    99.153321           101.511207   \n",
      "9287                    62.518523            72.863082   \n",
      "9288                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \\\n",
      "0                  89.952794               69.844140             32.659866   \n",
      "1                  77.897491               61.978064             27.723693   \n",
      "2                  91.013300               60.104043             32.101309   \n",
      "3                  85.137558               62.107580             34.384121   \n",
      "4                  88.113994               73.979982             31.502494   \n",
      "...                      ...                     ...                   ...   \n",
      "9284               84.031085               68.057116             28.132116   \n",
      "9285               89.116733               67.914896             33.865633   \n",
      "9286               90.869248               72.108074             34.866149   \n",
      "9287               60.178849               43.501362             23.147521   \n",
      "9288               83.099290               64.402220             37.850102   \n",
      "\n",
      "      Height_std_lgb2d_pred  Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  \n",
      "0                  0.057386              0.054053                    0.105998  \n",
      "1                  0.025927              0.019241                    0.061465  \n",
      "2                  0.015815              0.082272                    0.163613  \n",
      "3                  0.046316              0.182075                    0.146198  \n",
      "4                  0.010494              0.027979                    0.020251  \n",
      "...                     ...                   ...                         ...  \n",
      "9284               0.079732              0.210128                    0.057112  \n",
      "9285               0.043317              0.033824                    0.003290  \n",
      "9286              -0.003767              0.010504                    0.008107  \n",
      "9287               0.293462              0.176150                    0.260723  \n",
      "9288               0.027827              0.035395                    0.076517  \n",
      "\n",
      "[9289 rows x 55 columns]\n",
      "lgb2d.csv (9289, 55)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "645/654 Hip_std 135 0.035\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(8968, 4271) (321, 4271)\n",
      "(8968, 653) (8968,) (321, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0405\n",
      "Blended average after 1 repeats: 0.0405\n",
      "75.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=100, min_child_weight=0,\n",
      "              min_split_gain=0.0001, num_leaves=30, reg_alpha=0,\n",
      "              reg_lambda=1e-05, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0404\n",
      "Blended average after 2 repeats: 0.0403\n",
      "143.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=1, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=225, num_leaves=50, reg_alpha=10,\n",
      "              reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0403\n",
      "Blended average after 3 repeats: 0.0402\n",
      "217.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.1, num_leaves=20, reg_alpha=10, reg_lambda=100,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0403\n",
      "Blended average after 4 repeats: 0.0401\n",
      "292.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=50, num_leaves=100, reg_alpha=0.1,\n",
      "              reg_lambda=100, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0403\n",
      "Blended average after 5 repeats: 0.0400\n",
      "360.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=10, reg_lambda=10, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0403\n",
      "Blended average after 6 repeats: 0.0400\n",
      "436.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=100, reg_alpha=1, reg_lambda=100,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0403\n",
      "Blended average after 7 repeats: 0.0400\n",
      "521.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.33, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.001, reg_lambda=100, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                      gain\n",
      "feature                   \n",
      "Waist_iliac_std  79.020408\n",
      "Waist_std        66.183673\n",
      "Neck_std         41.897959\n",
      "U02B03           27.979592\n",
      "Hip_max          24.571429\n",
      "CLAA01c          23.959184\n",
      "CLAE02a1         20.142857\n",
      "V2BA01_LB        18.938776\n",
      "CLAB01c          15.918367\n",
      "V2AF12_YR        15.836735\n",
      "           gain\n",
      "feature        \n",
      "V2AF01g     0.0\n",
      "V2AF08h     0.0\n",
      "S02G07      0.0\n",
      "S02G06      0.0\n",
      "V2AF05e     0.0\n",
      "V2AF05g     0.0\n",
      "V2AF05h     0.0\n",
      "V2AF08e     0.0\n",
      "V2AF08g     0.0\n",
      "AgeCat_V1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Waist_mean_lgb2d_pred  Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                 86.477571                   106.095585           113.612766   \n",
      "1                 71.096942                    79.850034            98.098173   \n",
      "2                 75.102741                    88.960430            96.672578   \n",
      "3                 90.047908                   101.988971           111.922213   \n",
      "4                 82.850209                    94.336494            96.426516   \n",
      "...                     ...                          ...                  ...   \n",
      "9284              79.956838                    90.706608           108.033284   \n",
      "9285              80.912099                    90.059695            91.389706   \n",
      "9286              97.374471                    99.153321           101.511207   \n",
      "9287              61.008549                    62.518523            72.863082   \n",
      "9288              94.896944                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \\\n",
      "0                  89.952794               69.844140             32.659866   \n",
      "1                  77.897491               61.978064             27.723693   \n",
      "2                  91.013300               60.104043             32.101309   \n",
      "3                  85.137558               62.107580             34.384121   \n",
      "4                  88.113994               73.979982             31.502494   \n",
      "...                      ...                     ...                   ...   \n",
      "9284               84.031085               68.057116             28.132116   \n",
      "9285               89.116733               67.914896             33.865633   \n",
      "9286               90.869248               72.108074             34.866149   \n",
      "9287               60.178849               43.501362             23.147521   \n",
      "9288               83.099290               64.402220             37.850102   \n",
      "\n",
      "      Height_std_lgb2d_pred  Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  \\\n",
      "0                  0.057386              0.054053                    0.105998   \n",
      "1                  0.025927              0.019241                    0.061465   \n",
      "2                  0.015815              0.082272                    0.163613   \n",
      "3                  0.046316              0.182075                    0.146198   \n",
      "4                  0.010494              0.027979                    0.020251   \n",
      "...                     ...                   ...                         ...   \n",
      "9284               0.079732              0.210128                    0.057112   \n",
      "9285               0.043317              0.033824                    0.003290   \n",
      "9286              -0.003767              0.010504                    0.008107   \n",
      "9287               0.293462              0.176150                    0.260723   \n",
      "9288               0.027827              0.035395                    0.076517   \n",
      "\n",
      "      Hip_std_lgb2d_pred  \n",
      "0               0.107697  \n",
      "1               0.006194  \n",
      "2               0.071440  \n",
      "3               0.097673  \n",
      "4              -0.002093  \n",
      "...                  ...  \n",
      "9284            0.141392  \n",
      "9285            0.025008  \n",
      "9286            0.004215  \n",
      "9287            0.107372  \n",
      "9288            0.010873  \n",
      "\n",
      "[9289 rows x 56 columns]\n",
      "lgb2d.csv (9289, 56)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "646/654 BP_Sys_std 77 0.022\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9087, 4271) (202, 4271)\n",
      "(9087, 653) (9087,) (202, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2853\n",
      "Blended average after 1 repeats: 0.2853\n",
      "72.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, max_depth=3,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3100\n",
      "Blended average after 2 repeats: 0.2601\n",
      "141.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100, reg_alpha=0.1,\n",
      "              reg_lambda=1e-05, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3471\n",
      "Blended average after 3 repeats: 0.2723\n",
      "229.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=5,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=150,\n",
      "              num_leaves=20, reg_alpha=0, reg_lambda=0.0001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3300\n",
      "Blended average after 4 repeats: 0.2486\n",
      "307.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, max_depth=5, min_child_samples=7,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=150,\n",
      "              num_leaves=50, reg_alpha=0.001, reg_lambda=0.1, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3196\n",
      "Blended average after 5 repeats: 0.2372\n",
      "383.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=0.001, reg_lambda=0.01,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3202\n",
      "Blended average after 6 repeats: 0.2359\n",
      "456.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=0.001, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3143\n",
      "Blended average after 7 repeats: 0.2279\n",
      "528.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.8, max_depth=4,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.01, reg_lambda=1,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "BP_Sys_max   838.918367\n",
      "BP_Dia_mean  579.510204\n",
      "BP_Dia_max   431.142857\n",
      "BP_Sys_mean  321.265306\n",
      "V2BA02a1      79.102041\n",
      "V2BA02b1      30.653061\n",
      "BMI           29.102041\n",
      "Waist_mean    28.102041\n",
      "V1AD01b       26.040816\n",
      "V1BA01_LB     25.306122\n",
      "             gain\n",
      "feature          \n",
      "S02G08        0.0\n",
      "S02G09        0.0\n",
      "S02G10        0.0\n",
      "S02G11        0.0\n",
      "S02G14        0.0\n",
      "S02H01        0.0\n",
      "S02Ver        0.0\n",
      "U02C02        0.0\n",
      "Ins_Mil       0.0\n",
      "V1AE2_05c_1   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Waist_iliac_mean_lgb2d_pred  Hip_mean_lgb2d_pred  \\\n",
      "0                      106.095585           113.612766   \n",
      "1                       79.850034            98.098173   \n",
      "2                       88.960430            96.672578   \n",
      "3                      101.988971           111.922213   \n",
      "4                       94.336494            96.426516   \n",
      "...                           ...                  ...   \n",
      "9284                    90.706608           108.033284   \n",
      "9285                    90.059695            91.389706   \n",
      "9286                    99.153321           101.511207   \n",
      "9287                    62.518523            72.863082   \n",
      "9288                   105.402003           114.809245   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \\\n",
      "0                  89.952794               69.844140             32.659866   \n",
      "1                  77.897491               61.978064             27.723693   \n",
      "2                  91.013300               60.104043             32.101309   \n",
      "3                  85.137558               62.107580             34.384121   \n",
      "4                  88.113994               73.979982             31.502494   \n",
      "...                      ...                     ...                   ...   \n",
      "9284               84.031085               68.057116             28.132116   \n",
      "9285               89.116733               67.914896             33.865633   \n",
      "9286               90.869248               72.108074             34.866149   \n",
      "9287               60.178849               43.501362             23.147521   \n",
      "9288               83.099290               64.402220             37.850102   \n",
      "\n",
      "      Height_std_lgb2d_pred  Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  \\\n",
      "0                  0.057386              0.054053                    0.105998   \n",
      "1                  0.025927              0.019241                    0.061465   \n",
      "2                  0.015815              0.082272                    0.163613   \n",
      "3                  0.046316              0.182075                    0.146198   \n",
      "4                  0.010494              0.027979                    0.020251   \n",
      "...                     ...                   ...                         ...   \n",
      "9284               0.079732              0.210128                    0.057112   \n",
      "9285               0.043317              0.033824                    0.003290   \n",
      "9286              -0.003767              0.010504                    0.008107   \n",
      "9287               0.293462              0.176150                    0.260723   \n",
      "9288               0.027827              0.035395                    0.076517   \n",
      "\n",
      "      Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  \n",
      "0               0.107697              28.372242  \n",
      "1               0.006194              22.951015  \n",
      "2               0.071440              43.641856  \n",
      "3               0.097673              32.473743  \n",
      "4              -0.002093              20.008343  \n",
      "...                  ...                    ...  \n",
      "9284            0.141392              22.613755  \n",
      "9285            0.025008              29.508560  \n",
      "9286            0.004215              26.952829  \n",
      "9287            0.107372              25.148863  \n",
      "9288            0.010873              26.969874  \n",
      "\n",
      "[9289 rows x 57 columns]\n",
      "lgb2d.csv (9289, 57)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "647/654 Neck_std 75 0.150\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(7899, 4271) (1390, 4271)\n",
      "(7899, 653) (7899,) (1390, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.0139\n",
      "Blended average after 1 repeats: 0.0139\n",
      "64.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=70, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=20, reg_alpha=0,\n",
      "              reg_lambda=10, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.0142\n",
      "Blended average after 2 repeats: 0.0138\n",
      "124.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, max_depth=6,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=0.01, reg_lambda=1e-05,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.0145\n",
      "Blended average after 3 repeats: 0.0141\n",
      "185.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=1, reg_lambda=1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.0146\n",
      "Blended average after 4 repeats: 0.0141\n",
      "239.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=5, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=350, num_leaves=50,\n",
      "              reg_alpha=0.01, reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.0146\n",
      "Blended average after 5 repeats: 0.0142\n",
      "305.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, max_depth=7,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=0.001, reg_lambda=0.1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.0145\n",
      "Blended average after 6 repeats: 0.0140\n",
      "364.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, max_depth=6,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0.0001,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=0.1, reg_lambda=1e-05,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.0145\n",
      "Blended average after 7 repeats: 0.0140\n",
      "435.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, colsample_bytree=0.33, max_depth=5,\n",
      "              min_child_samples=40, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=50, reg_alpha=1, reg_lambda=0.01,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                       gain\n",
      "feature                    \n",
      "Neck_mean        183.938776\n",
      "Neck_max         169.285714\n",
      "Waist_std        164.061224\n",
      "Waist_iliac_std  101.000000\n",
      "Hip_std           85.857143\n",
      "S02D01a           62.122449\n",
      "CLAA01d           58.102041\n",
      "CLAE02a1          58.020408\n",
      "S02E05            55.326531\n",
      "Height_std        52.734694\n",
      "         gain\n",
      "feature      \n",
      "V2BA01a   0.0\n",
      "S01A11    0.0\n",
      "V2BVer    0.0\n",
      "S02G14    0.0\n",
      "S01A06    0.0\n",
      "S01A05    0.0\n",
      "S02G13    0.0\n",
      "S01A01    0.0\n",
      "S02G12    0.0\n",
      "S02Ver    0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Hip_mean_lgb2d_pred  BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  \\\n",
      "0              113.612766               89.952794               69.844140   \n",
      "1               98.098173               77.897491               61.978064   \n",
      "2               96.672578               91.013300               60.104043   \n",
      "3              111.922213               85.137558               62.107580   \n",
      "4               96.426516               88.113994               73.979982   \n",
      "...                   ...                     ...                     ...   \n",
      "9284           108.033284               84.031085               68.057116   \n",
      "9285            91.389706               89.116733               67.914896   \n",
      "9286           101.511207               90.869248               72.108074   \n",
      "9287            72.863082               60.178849               43.501362   \n",
      "9288           114.809245               83.099290               64.402220   \n",
      "\n",
      "      Neck_mean_lgb2d_pred  Height_std_lgb2d_pred  Waist_std_lgb2d_pred  \\\n",
      "0                32.659866               0.057386              0.054053   \n",
      "1                27.723693               0.025927              0.019241   \n",
      "2                32.101309               0.015815              0.082272   \n",
      "3                34.384121               0.046316              0.182075   \n",
      "4                31.502494               0.010494              0.027979   \n",
      "...                    ...                    ...                   ...   \n",
      "9284             28.132116               0.079732              0.210128   \n",
      "9285             33.865633               0.043317              0.033824   \n",
      "9286             34.866149              -0.003767              0.010504   \n",
      "9287             23.147521               0.293462              0.176150   \n",
      "9288             37.850102               0.027827              0.035395   \n",
      "\n",
      "      Waist_iliac_std_lgb2d_pred  Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  \\\n",
      "0                       0.105998            0.107697              28.372242   \n",
      "1                       0.061465            0.006194              22.951015   \n",
      "2                       0.163613            0.071440              43.641856   \n",
      "3                       0.146198            0.097673              32.473743   \n",
      "4                       0.020251           -0.002093              20.008343   \n",
      "...                          ...                 ...                    ...   \n",
      "9284                    0.057112            0.141392              22.613755   \n",
      "9285                    0.003290            0.025008              29.508560   \n",
      "9286                    0.008107            0.004215              26.952829   \n",
      "9287                    0.260723            0.107372              25.148863   \n",
      "9288                    0.076517            0.010873              26.969874   \n",
      "\n",
      "      Neck_std_lgb2d_pred  \n",
      "0                0.044631  \n",
      "1                0.014570  \n",
      "2                0.048138  \n",
      "3                0.066000  \n",
      "4                0.013388  \n",
      "...                   ...  \n",
      "9284             0.082475  \n",
      "9285             0.018812  \n",
      "9286            -0.001614  \n",
      "9287             0.114119  \n",
      "9288             0.021681  \n",
      "\n",
      "[9289 rows x 58 columns]\n",
      "lgb2d.csv (9289, 58)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "648/654 Height_max 377 0.021\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9093, 4271) (196, 4271)\n",
      "(9093, 653) (9093,) (196, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4397\n",
      "Blended average after 1 repeats: 0.4397\n",
      "83.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, max_depth=6, min_child_samples=2,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=225,\n",
      "              num_leaves=100, reg_alpha=0, reg_lambda=0.01, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3916\n",
      "Blended average after 2 repeats: 0.3502\n",
      "163.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.05, max_depth=4,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.01,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0.01, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3971\n",
      "Blended average after 3 repeats: 0.3376\n",
      "242.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, max_depth=4,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=0.001, reg_lambda=10,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.4084\n",
      "Blended average after 4 repeats: 0.3363\n",
      "320.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.4040\n",
      "Blended average after 5 repeats: 0.3276\n",
      "395.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, max_depth=2,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=20, reg_alpha=0.1, reg_lambda=0, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.4046\n",
      "Blended average after 6 repeats: 0.3289\n",
      "475.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=100, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.4042\n",
      "Blended average after 7 repeats: 0.3190\n",
      "557.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=1, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=1e-05, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "Height_mean  892.000000\n",
      "BMI          297.571429\n",
      "V1AD01b      220.510204\n",
      "V1BA01_LB    181.938776\n",
      "Height_std   147.428571\n",
      "V2BA01_LB     76.122449\n",
      "BMI_Cat       49.346939\n",
      "CLAA01d       34.346939\n",
      "CLAA01c       33.081633\n",
      "CLAA01a       29.734694\n",
      "           gain\n",
      "feature        \n",
      "S02G10      0.0\n",
      "S02G08      0.0\n",
      "V2AF18i     0.0\n",
      "S02G07      0.0\n",
      "S02G06      0.0\n",
      "V2AF25h     0.0\n",
      "S02G05      0.0\n",
      "V2AF22h     0.0\n",
      "S01BCheck   0.0\n",
      "V1HVer      0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      BP_Sys_mean_lgb2d_pred  BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  \\\n",
      "0                  89.952794               69.844140             32.659866   \n",
      "1                  77.897491               61.978064             27.723693   \n",
      "2                  91.013300               60.104043             32.101309   \n",
      "3                  85.137558               62.107580             34.384121   \n",
      "4                  88.113994               73.979982             31.502494   \n",
      "...                      ...                     ...                   ...   \n",
      "9284               84.031085               68.057116             28.132116   \n",
      "9285               89.116733               67.914896             33.865633   \n",
      "9286               90.869248               72.108074             34.866149   \n",
      "9287               60.178849               43.501362             23.147521   \n",
      "9288               83.099290               64.402220             37.850102   \n",
      "\n",
      "      Height_std_lgb2d_pred  Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  \\\n",
      "0                  0.057386              0.054053                    0.105998   \n",
      "1                  0.025927              0.019241                    0.061465   \n",
      "2                  0.015815              0.082272                    0.163613   \n",
      "3                  0.046316              0.182075                    0.146198   \n",
      "4                  0.010494              0.027979                    0.020251   \n",
      "...                     ...                   ...                         ...   \n",
      "9284               0.079732              0.210128                    0.057112   \n",
      "9285               0.043317              0.033824                    0.003290   \n",
      "9286              -0.003767              0.010504                    0.008107   \n",
      "9287               0.293462              0.176150                    0.260723   \n",
      "9288               0.027827              0.035395                    0.076517   \n",
      "\n",
      "      Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  Neck_std_lgb2d_pred  \\\n",
      "0               0.107697              28.372242             0.044631   \n",
      "1               0.006194              22.951015             0.014570   \n",
      "2               0.071440              43.641856             0.048138   \n",
      "3               0.097673              32.473743             0.066000   \n",
      "4              -0.002093              20.008343             0.013388   \n",
      "...                  ...                    ...                  ...   \n",
      "9284            0.141392              22.613755             0.082475   \n",
      "9285            0.025008              29.508560             0.018812   \n",
      "9286            0.004215              26.952829            -0.001614   \n",
      "9287            0.107372              25.148863             0.114119   \n",
      "9288            0.010873              26.969874             0.021681   \n",
      "\n",
      "      Height_max_lgb2d_pred  \n",
      "0                154.784648  \n",
      "1                166.838345  \n",
      "2                159.907992  \n",
      "3                175.004126  \n",
      "4                173.993261  \n",
      "...                     ...  \n",
      "9284             169.899913  \n",
      "9285             157.398090  \n",
      "9286             168.114039  \n",
      "9287             136.068999  \n",
      "9288             160.409202  \n",
      "\n",
      "[9289 rows x 59 columns]\n",
      "lgb2d.csv (9289, 59)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "649/654 Waist_max 656 0.030\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9014, 4271) (275, 4271)\n",
      "(9014, 653) (9014,) (275, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.4310\n",
      "Blended average after 1 repeats: 0.4310\n",
      "71.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.01, num_leaves=30, reg_alpha=0, reg_lambda=10,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.6135\n",
      "Blended average after 2 repeats: 0.5129\n",
      "142.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=225, num_leaves=100,\n",
      "              reg_alpha=0.01, reg_lambda=0.1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.5988\n",
      "Blended average after 3 repeats: 0.4814\n",
      "216.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.65, learning_rate=0.05,\n",
      "              max_depth=6, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=1, reg_lambda=10,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.6317\n",
      "Blended average after 4 repeats: 0.4897\n",
      "293.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.33, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=40, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=350, num_leaves=20,\n",
      "              reg_alpha=0.1, reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.6630\n",
      "Blended average after 5 repeats: 0.4993\n",
      "364.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, learning_rate=0.05, max_depth=7,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=0.1, reg_lambda=0.01,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.6573\n",
      "Blended average after 6 repeats: 0.4871\n",
      "443.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, max_depth=5,\n",
      "              min_child_samples=70, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=150, num_leaves=20, reg_alpha=10, reg_lambda=0.001,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.6681\n",
      "Blended average after 7 repeats: 0.4878\n",
      "518.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, max_depth=7,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=30, reg_alpha=0.1, reg_lambda=0.1,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                         gain\n",
      "feature                      \n",
      "Waist_mean        1169.102041\n",
      "Waist_iliac_mean   264.285714\n",
      "Waist_iliac_max    216.448980\n",
      "BMI                212.836735\n",
      "Waist_std          142.020408\n",
      "V1AD01b             82.265306\n",
      "Neck_mean           81.591837\n",
      "Hip_mean            80.816327\n",
      "Hip_max             72.285714\n",
      "V1BA01_LB           59.755102\n",
      "             gain\n",
      "feature          \n",
      "V2AF01f       0.0\n",
      "V1KA02_AMPM   0.0\n",
      "V1KA03_AMPM   0.0\n",
      "V2AF25h       0.0\n",
      "V2AF22h       0.0\n",
      "S02Ver        0.0\n",
      "S02H01        0.0\n",
      "S02G14        0.0\n",
      "S02G13        0.0\n",
      "V1AF12i       0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      BP_Dia_mean_lgb2d_pred  Neck_mean_lgb2d_pred  Height_std_lgb2d_pred  \\\n",
      "0                  69.844140             32.659866               0.057386   \n",
      "1                  61.978064             27.723693               0.025927   \n",
      "2                  60.104043             32.101309               0.015815   \n",
      "3                  62.107580             34.384121               0.046316   \n",
      "4                  73.979982             31.502494               0.010494   \n",
      "...                      ...                   ...                    ...   \n",
      "9284               68.057116             28.132116               0.079732   \n",
      "9285               67.914896             33.865633               0.043317   \n",
      "9286               72.108074             34.866149              -0.003767   \n",
      "9287               43.501362             23.147521               0.293462   \n",
      "9288               64.402220             37.850102               0.027827   \n",
      "\n",
      "      Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  Hip_std_lgb2d_pred  \\\n",
      "0                 0.054053                    0.105998            0.107697   \n",
      "1                 0.019241                    0.061465            0.006194   \n",
      "2                 0.082272                    0.163613            0.071440   \n",
      "3                 0.182075                    0.146198            0.097673   \n",
      "4                 0.027979                    0.020251           -0.002093   \n",
      "...                    ...                         ...                 ...   \n",
      "9284              0.210128                    0.057112            0.141392   \n",
      "9285              0.033824                    0.003290            0.025008   \n",
      "9286              0.010504                    0.008107            0.004215   \n",
      "9287              0.176150                    0.260723            0.107372   \n",
      "9288              0.035395                    0.076517            0.010873   \n",
      "\n",
      "      BP_Sys_std_lgb2d_pred  Neck_std_lgb2d_pred  Height_max_lgb2d_pred  \\\n",
      "0                 28.372242             0.044631             154.784648   \n",
      "1                 22.951015             0.014570             166.838345   \n",
      "2                 43.641856             0.048138             159.907992   \n",
      "3                 32.473743             0.066000             175.004126   \n",
      "4                 20.008343             0.013388             173.993261   \n",
      "...                     ...                  ...                    ...   \n",
      "9284              22.613755             0.082475             169.899913   \n",
      "9285              29.508560             0.018812             157.398090   \n",
      "9286              26.952829            -0.001614             168.114039   \n",
      "9287              25.148863             0.114119             136.068999   \n",
      "9288              26.969874             0.021681             160.409202   \n",
      "\n",
      "      Waist_max_lgb2d_pred  \n",
      "0                86.591876  \n",
      "1                70.984231  \n",
      "2                75.235010  \n",
      "3                90.164611  \n",
      "4                82.953786  \n",
      "...                    ...  \n",
      "9284             79.981719  \n",
      "9285             81.034286  \n",
      "9286             97.444968  \n",
      "9287             61.785014  \n",
      "9288             95.068666  \n",
      "\n",
      "[9289 rows x 60 columns]\n",
      "lgb2d.csv (9289, 60)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "650/654 Waist_iliac_max 715 0.030\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9014, 4271) (275, 4271)\n",
      "(9014, 653) (9014,) (275, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 1.4562\n",
      "Blended average after 1 repeats: 1.4559\n",
      "73.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=7, min_child_samples=4, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=350, num_leaves=30,\n",
      "              reg_alpha=1, reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 1.1922\n",
      "Blended average after 2 repeats: 1.0214\n",
      "146.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, learning_rate=0.07, max_depth=3,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 1.1692\n",
      "Blended average after 3 repeats: 0.9627\n",
      "220.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, max_depth=4,\n",
      "              min_child_samples=10, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=10, reg_lambda=0.0001,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 1.1598\n",
      "Blended average after 4 repeats: 0.9320\n",
      "283.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.01, n_estimators=150, num_leaves=100,\n",
      "              reg_alpha=0.001, reg_lambda=1, subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 1.1620\n",
      "Blended average after 5 repeats: 0.9324\n",
      "363.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=0.001, reg_lambda=1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 1.1214\n",
      "Blended average after 6 repeats: 0.8987\n",
      "436.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=2, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=10, reg_lambda=0.001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 1.1587\n",
      "Blended average after 7 repeats: 0.9225\n",
      "506.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, max_depth=7,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=1, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                         gain\n",
      "feature                      \n",
      "Waist_iliac_mean  1055.244898\n",
      "Hip_mean           199.224490\n",
      "Waist_iliac_std    198.775510\n",
      "Waist_mean         158.163265\n",
      "Hip_max            149.938776\n",
      "Waist_max          122.326531\n",
      "BMI                 65.632653\n",
      "V1AD01b             56.244898\n",
      "V1BA01_LB           54.836735\n",
      "V2BA01_LB           33.326531\n",
      "             gain\n",
      "feature          \n",
      "S02E04        0.0\n",
      "S01B05        0.0\n",
      "V2AF25e       0.0\n",
      "V2AF25d       0.0\n",
      "S01A12        0.0\n",
      "S02G02        0.0\n",
      "S01A11        0.0\n",
      "S01A10        0.0\n",
      "V1AE2_04e_1   0.0\n",
      "S02G11        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Neck_mean_lgb2d_pred  Height_std_lgb2d_pred  Waist_std_lgb2d_pred  \\\n",
      "0                32.659866               0.057386              0.054053   \n",
      "1                27.723693               0.025927              0.019241   \n",
      "2                32.101309               0.015815              0.082272   \n",
      "3                34.384121               0.046316              0.182075   \n",
      "4                31.502494               0.010494              0.027979   \n",
      "...                    ...                    ...                   ...   \n",
      "9284             28.132116               0.079732              0.210128   \n",
      "9285             33.865633               0.043317              0.033824   \n",
      "9286             34.866149              -0.003767              0.010504   \n",
      "9287             23.147521               0.293462              0.176150   \n",
      "9288             37.850102               0.027827              0.035395   \n",
      "\n",
      "      Waist_iliac_std_lgb2d_pred  Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  \\\n",
      "0                       0.105998            0.107697              28.372242   \n",
      "1                       0.061465            0.006194              22.951015   \n",
      "2                       0.163613            0.071440              43.641856   \n",
      "3                       0.146198            0.097673              32.473743   \n",
      "4                       0.020251           -0.002093              20.008343   \n",
      "...                          ...                 ...                    ...   \n",
      "9284                    0.057112            0.141392              22.613755   \n",
      "9285                    0.003290            0.025008              29.508560   \n",
      "9286                    0.008107            0.004215              26.952829   \n",
      "9287                    0.260723            0.107372              25.148863   \n",
      "9288                    0.076517            0.010873              26.969874   \n",
      "\n",
      "      Neck_std_lgb2d_pred  Height_max_lgb2d_pred  Waist_max_lgb2d_pred  \\\n",
      "0                0.044631             154.784648             86.591876   \n",
      "1                0.014570             166.838345             70.984231   \n",
      "2                0.048138             159.907992             75.235010   \n",
      "3                0.066000             175.004126             90.164611   \n",
      "4                0.013388             173.993261             82.953786   \n",
      "...                   ...                    ...                   ...   \n",
      "9284             0.082475             169.899913             79.981719   \n",
      "9285             0.018812             157.398090             81.034286   \n",
      "9286            -0.001614             168.114039             97.444968   \n",
      "9287             0.114119             136.068999             61.785014   \n",
      "9288             0.021681             160.409202             95.068666   \n",
      "\n",
      "      Waist_iliac_max_lgb2d_pred  \n",
      "0                     106.092724  \n",
      "1                      80.056719  \n",
      "2                      88.863915  \n",
      "3                     102.184926  \n",
      "4                      94.328020  \n",
      "...                          ...  \n",
      "9284                   90.531017  \n",
      "9285                   89.970529  \n",
      "9286                   99.128399  \n",
      "9287                   63.217698  \n",
      "9288                  105.794453  \n",
      "\n",
      "[9289 rows x 61 columns]\n",
      "lgb2d.csv (9289, 61)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "651/654 Hip_max 664 0.030\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9010, 4271) (279, 4271)\n",
      "(9010, 653) (9010,) (279, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 1.1325\n",
      "Blended average after 1 repeats: 1.1325\n",
      "70.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=6, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=0.1,\n",
      "              reg_lambda=0.001, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 1.1308\n",
      "Blended average after 2 repeats: 0.9503\n",
      "141.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=4, min_child_weight=0, min_split_gain=0.1,\n",
      "              num_leaves=100, reg_alpha=0.01, reg_lambda=0, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 1.0506\n",
      "Blended average after 3 repeats: 0.8162\n",
      "222.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=2, min_child_samples=10, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=30, reg_alpha=1,\n",
      "              reg_lambda=1e-05, subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 1.0852\n",
      "Blended average after 4 repeats: 0.8187\n",
      "290.5s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, max_depth=1, min_child_samples=70,\n",
      "              min_child_weight=0, min_split_gain=0.1, n_estimators=350,\n",
      "              num_leaves=100, reg_alpha=1, reg_lambda=0.01, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 1.1357\n",
      "Blended average after 5 repeats: 0.8204\n",
      "368.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, learning_rate=0.07, max_depth=4,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=225,\n",
      "              num_leaves=20, reg_alpha=0.1, reg_lambda=0, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 1.1339\n",
      "Blended average after 6 repeats: 0.8066\n",
      "441.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=1, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=30,\n",
      "              reg_alpha=10, reg_lambda=0.1, subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 1.1163\n",
      "Blended average after 7 repeats: 0.7831\n",
      "515.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=7, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=150, num_leaves=20,\n",
      "              reg_alpha=0.001, reg_lambda=0, subsample=1, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                        gain\n",
      "feature                     \n",
      "Hip_mean          898.163265\n",
      "Waist_iliac_mean  158.551020\n",
      "Waist_iliac_max   155.836735\n",
      "V1AD01b           121.367347\n",
      "V1BA01_LB         118.163265\n",
      "BMI                97.734694\n",
      "Hip_std            90.265306\n",
      "V2BA01_LB          55.897959\n",
      "Waist_mean         51.959184\n",
      "Waist_max          48.877551\n",
      "         gain\n",
      "feature      \n",
      "S01B05    0.0\n",
      "V2AH06    0.0\n",
      "V1GVer    0.0\n",
      "S02G04    0.0\n",
      "V2AH04    0.0\n",
      "S02G05    0.0\n",
      "S02G06    0.0\n",
      "S02G07    0.0\n",
      "S02G08    0.0\n",
      "V1AF07f   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Height_std_lgb2d_pred  Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  \\\n",
      "0                  0.057386              0.054053                    0.105998   \n",
      "1                  0.025927              0.019241                    0.061465   \n",
      "2                  0.015815              0.082272                    0.163613   \n",
      "3                  0.046316              0.182075                    0.146198   \n",
      "4                  0.010494              0.027979                    0.020251   \n",
      "...                     ...                   ...                         ...   \n",
      "9284               0.079732              0.210128                    0.057112   \n",
      "9285               0.043317              0.033824                    0.003290   \n",
      "9286              -0.003767              0.010504                    0.008107   \n",
      "9287               0.293462              0.176150                    0.260723   \n",
      "9288               0.027827              0.035395                    0.076517   \n",
      "\n",
      "      Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  Neck_std_lgb2d_pred  \\\n",
      "0               0.107697              28.372242             0.044631   \n",
      "1               0.006194              22.951015             0.014570   \n",
      "2               0.071440              43.641856             0.048138   \n",
      "3               0.097673              32.473743             0.066000   \n",
      "4              -0.002093              20.008343             0.013388   \n",
      "...                  ...                    ...                  ...   \n",
      "9284            0.141392              22.613755             0.082475   \n",
      "9285            0.025008              29.508560             0.018812   \n",
      "9286            0.004215              26.952829            -0.001614   \n",
      "9287            0.107372              25.148863             0.114119   \n",
      "9288            0.010873              26.969874             0.021681   \n",
      "\n",
      "      Height_max_lgb2d_pred  Waist_max_lgb2d_pred  Waist_iliac_max_lgb2d_pred  \\\n",
      "0                154.784648             86.591876                  106.092724   \n",
      "1                166.838345             70.984231                   80.056719   \n",
      "2                159.907992             75.235010                   88.863915   \n",
      "3                175.004126             90.164611                  102.184926   \n",
      "4                173.993261             82.953786                   94.328020   \n",
      "...                     ...                   ...                         ...   \n",
      "9284             169.899913             79.981719                   90.531017   \n",
      "9285             157.398090             81.034286                   89.970529   \n",
      "9286             168.114039             97.444968                   99.128399   \n",
      "9287             136.068999             61.785014                   63.217698   \n",
      "9288             160.409202             95.068666                  105.794453   \n",
      "\n",
      "      Hip_max_lgb2d_pred  \n",
      "0             113.477225  \n",
      "1              97.992614  \n",
      "2              97.108531  \n",
      "3             112.051239  \n",
      "4              96.520567  \n",
      "...                  ...  \n",
      "9284          108.161618  \n",
      "9285           91.235114  \n",
      "9286          101.843612  \n",
      "9287           73.343669  \n",
      "9288          114.967730  \n",
      "\n",
      "[9289 rows x 62 columns]\n",
      "lgb2d.csv (9289, 62)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "652/654 BP_Sys_max 85 0.022\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9087, 4271) (202, 4271)\n",
      "(9087, 653) (9087,) (202, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3341\n",
      "Blended average after 1 repeats: 0.3341\n",
      "78.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=5, min_child_weight=0, min_split_gain=0.001,\n",
      "              num_leaves=50, reg_alpha=1, reg_lambda=1, subsample=0.8,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3625\n",
      "Blended average after 2 repeats: 0.2811\n",
      "153.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, max_depth=4,\n",
      "              min_child_samples=1, min_child_weight=0, min_split_gain=0,\n",
      "              num_leaves=20, reg_alpha=0.1, reg_lambda=0, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3381\n",
      "Blended average after 3 repeats: 0.2322\n",
      "226.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, max_depth=3,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0.0001,\n",
      "              num_leaves=100, reg_alpha=10, reg_lambda=0.001, subsample=0.9,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3310\n",
      "Blended average after 4 repeats: 0.2090\n",
      "314.0s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, learning_rate=0.05,\n",
      "              max_depth=5, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=150, num_leaves=20, reg_alpha=10,\n",
      "              reg_lambda=0.0001, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3440\n",
      "Blended average after 5 repeats: 0.2032\n",
      "396.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.8, learning_rate=0.05,\n",
      "              max_depth=3, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0.001, n_estimators=150, num_leaves=50,\n",
      "              reg_alpha=0.001, reg_lambda=10, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3460\n",
      "Blended average after 6 repeats: 0.1933\n",
      "480.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.33, max_depth=3,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=225,\n",
      "              num_leaves=50, reg_alpha=10, reg_lambda=1, subsample=1,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3565\n",
      "Blended average after 7 repeats: 0.1991\n",
      "564.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.5, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=100, reg_alpha=1, reg_lambda=0.01,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "BP_Sys_std   671.755102\n",
      "BP_Sys_mean  657.346939\n",
      "BP_Dia_mean  192.938776\n",
      "BP_Dia_max   143.306122\n",
      "V2BA02a1      75.734694\n",
      "BMI           40.061224\n",
      "V1BA01_LB     36.244898\n",
      "CLAA01d       33.836735\n",
      "V1AD01b       32.612245\n",
      "V2BA01_LB     31.408163\n",
      "             gain\n",
      "feature          \n",
      "S02G10        0.0\n",
      "V2AF25h       0.0\n",
      "S01A05        0.0\n",
      "S02G08        0.0\n",
      "V1AE2_05d_1   0.0\n",
      "S02G07        0.0\n",
      "S01A01        0.0\n",
      "S02G05        0.0\n",
      "S02G04        0.0\n",
      "S02G09        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Waist_std_lgb2d_pred  Waist_iliac_std_lgb2d_pred  Hip_std_lgb2d_pred  \\\n",
      "0                 0.054053                    0.105998            0.107697   \n",
      "1                 0.019241                    0.061465            0.006194   \n",
      "2                 0.082272                    0.163613            0.071440   \n",
      "3                 0.182075                    0.146198            0.097673   \n",
      "4                 0.027979                    0.020251           -0.002093   \n",
      "...                    ...                         ...                 ...   \n",
      "9284              0.210128                    0.057112            0.141392   \n",
      "9285              0.033824                    0.003290            0.025008   \n",
      "9286              0.010504                    0.008107            0.004215   \n",
      "9287              0.176150                    0.260723            0.107372   \n",
      "9288              0.035395                    0.076517            0.010873   \n",
      "\n",
      "      BP_Sys_std_lgb2d_pred  Neck_std_lgb2d_pred  Height_max_lgb2d_pred  \\\n",
      "0                 28.372242             0.044631             154.784648   \n",
      "1                 22.951015             0.014570             166.838345   \n",
      "2                 43.641856             0.048138             159.907992   \n",
      "3                 32.473743             0.066000             175.004126   \n",
      "4                 20.008343             0.013388             173.993261   \n",
      "...                     ...                  ...                    ...   \n",
      "9284              22.613755             0.082475             169.899913   \n",
      "9285              29.508560             0.018812             157.398090   \n",
      "9286              26.952829            -0.001614             168.114039   \n",
      "9287              25.148863             0.114119             136.068999   \n",
      "9288              26.969874             0.021681             160.409202   \n",
      "\n",
      "      Waist_max_lgb2d_pred  Waist_iliac_max_lgb2d_pred  Hip_max_lgb2d_pred  \\\n",
      "0                86.591876                  106.092724          113.477225   \n",
      "1                70.984231                   80.056719           97.992614   \n",
      "2                75.235010                   88.863915           97.108531   \n",
      "3                90.164611                  102.184926          112.051239   \n",
      "4                82.953786                   94.328020           96.520567   \n",
      "...                    ...                         ...                 ...   \n",
      "9284             79.981719                   90.531017          108.161618   \n",
      "9285             81.034286                   89.970529           91.235114   \n",
      "9286             97.444968                   99.128399          101.843612   \n",
      "9287             61.785014                   63.217698           73.343669   \n",
      "9288             95.068666                  105.794453          114.967730   \n",
      "\n",
      "      BP_Sys_max_lgb2d_pred  \n",
      "0                110.016916  \n",
      "1                 94.075244  \n",
      "2                121.668056  \n",
      "3                108.285161  \n",
      "4                101.865451  \n",
      "...                     ...  \n",
      "9284             100.100260  \n",
      "9285             110.056340  \n",
      "9286             109.952193  \n",
      "9287              72.042289  \n",
      "9288             101.898350  \n",
      "\n",
      "[9289 rows x 63 columns]\n",
      "lgb2d.csv (9289, 63)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "653/654 BP_Dia_max 64 0.022\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(9087, 4271) (202, 4271)\n",
      "(9087, 653) (9087,) (202, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.3687\n",
      "Blended average after 1 repeats: 0.3687\n",
      "72.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, learning_rate=0.07,\n",
      "              max_depth=4, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.1, n_estimators=225, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=0.01, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.3644\n",
      "Blended average after 2 repeats: 0.3213\n",
      "139.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.33, max_depth=3,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.1, reg_lambda=1,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.3663\n",
      "Blended average after 3 repeats: 0.2980\n",
      "218.9s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=6,\n",
      "              min_child_samples=4, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=30, reg_alpha=0.01, reg_lambda=0.001,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.3683\n",
      "Blended average after 4 repeats: 0.2927\n",
      "287.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.9, learning_rate=0.07,\n",
      "              max_depth=3, min_child_samples=2, min_child_weight=0,\n",
      "              min_split_gain=0.0001, n_estimators=350, num_leaves=20,\n",
      "              reg_alpha=1, reg_lambda=0.1, subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.3672\n",
      "Blended average after 5 repeats: 0.2891\n",
      "361.4s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.5, max_depth=7,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=225, num_leaves=50, reg_alpha=10, reg_lambda=0.1,\n",
      "              subsample=1, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.3696\n",
      "Blended average after 6 repeats: 0.2895\n",
      "428.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=2, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.3720\n",
      "Blended average after 7 repeats: 0.2882\n",
      "493.3s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.8, learning_rate=0.07,\n",
      "              max_depth=2, min_child_weight=0, min_split_gain=0,\n",
      "              n_estimators=150, num_leaves=30, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=0.9, subsample_freq=1)\n",
      "\u001b[33m\n",
      "                   gain\n",
      "feature                \n",
      "BP_Dia_mean  576.000000\n",
      "BP_Sys_mean  316.938776\n",
      "BP_Sys_std   296.448980\n",
      "BP_Sys_max   133.571429\n",
      "V2BA02b1      62.938776\n",
      "V2BA02a1      35.734694\n",
      "V1BA01_LB     25.836735\n",
      "V2BA01_LB     23.551020\n",
      "V1AD01b       20.122449\n",
      "CLAA01a       17.428571\n",
      "             gain\n",
      "feature          \n",
      "S02ECheck     0.0\n",
      "V2AH05        0.0\n",
      "V1EVer        0.0\n",
      "V1AF07f       0.0\n",
      "S02G01        0.0\n",
      "S02G02        0.0\n",
      "S02G03        0.0\n",
      "S02G04        0.0\n",
      "S02G05        0.0\n",
      "V1KA02_AMPM   0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Waist_iliac_std_lgb2d_pred  Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  \\\n",
      "0                       0.105998            0.107697              28.372242   \n",
      "1                       0.061465            0.006194              22.951015   \n",
      "2                       0.163613            0.071440              43.641856   \n",
      "3                       0.146198            0.097673              32.473743   \n",
      "4                       0.020251           -0.002093              20.008343   \n",
      "...                          ...                 ...                    ...   \n",
      "9284                    0.057112            0.141392              22.613755   \n",
      "9285                    0.003290            0.025008              29.508560   \n",
      "9286                    0.008107            0.004215              26.952829   \n",
      "9287                    0.260723            0.107372              25.148863   \n",
      "9288                    0.076517            0.010873              26.969874   \n",
      "\n",
      "      Neck_std_lgb2d_pred  Height_max_lgb2d_pred  Waist_max_lgb2d_pred  \\\n",
      "0                0.044631             154.784648             86.591876   \n",
      "1                0.014570             166.838345             70.984231   \n",
      "2                0.048138             159.907992             75.235010   \n",
      "3                0.066000             175.004126             90.164611   \n",
      "4                0.013388             173.993261             82.953786   \n",
      "...                   ...                    ...                   ...   \n",
      "9284             0.082475             169.899913             79.981719   \n",
      "9285             0.018812             157.398090             81.034286   \n",
      "9286            -0.001614             168.114039             97.444968   \n",
      "9287             0.114119             136.068999             61.785014   \n",
      "9288             0.021681             160.409202             95.068666   \n",
      "\n",
      "      Waist_iliac_max_lgb2d_pred  Hip_max_lgb2d_pred  BP_Sys_max_lgb2d_pred  \\\n",
      "0                     106.092724          113.477225             110.016916   \n",
      "1                      80.056719           97.992614              94.075244   \n",
      "2                      88.863915           97.108531             121.668056   \n",
      "3                     102.184926          112.051239             108.285161   \n",
      "4                      94.328020           96.520567             101.865451   \n",
      "...                          ...                 ...                    ...   \n",
      "9284                   90.531017          108.161618             100.100260   \n",
      "9285                   89.970529           91.235114             110.056340   \n",
      "9286                   99.128399          101.843612             109.952193   \n",
      "9287                   63.217698           73.343669              72.042289   \n",
      "9288                  105.794453          114.967730             101.898350   \n",
      "\n",
      "      BP_Dia_max_lgb2d_pred  \n",
      "0                 70.004176  \n",
      "1                 61.948779  \n",
      "2                 60.013986  \n",
      "3                 62.091930  \n",
      "4                 74.013877  \n",
      "...                     ...  \n",
      "9284              68.063455  \n",
      "9285              67.940603  \n",
      "9286              72.004871  \n",
      "9287              45.778201  \n",
      "9288              64.147928  \n",
      "\n",
      "[9289 rows x 64 columns]\n",
      "lgb2d.csv (9289, 64)\n",
      "\n",
      "\u001b[32m\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "654/654 Neck_max 203 0.145\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\u001b[36m\n",
      "(7944, 4271) (1345, 4271)\n",
      "(7944, 653) (7944,) (1345, 653)\n",
      "\u001b[36m\n",
      "Running average after 1 repeats: 0.2311\n",
      "Blended average after 1 repeats: 0.2311\n",
      "70.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, colsample_bytree=0.9, max_depth=5,\n",
      "              min_child_samples=7, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=350, num_leaves=20, reg_alpha=10, reg_lambda=1,\n",
      "              subsample=0.6, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 2 repeats: 0.2089\n",
      "Blended average after 2 repeats: 0.1899\n",
      "150.8s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, learning_rate=0.05, max_depth=5,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=225,\n",
      "              num_leaves=20, reg_alpha=0, reg_lambda=100, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 3 repeats: 0.1995\n",
      "Blended average after 3 repeats: 0.1755\n",
      "215.1s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.81, max_depth=3, min_child_samples=4,\n",
      "              min_child_weight=0, min_split_gain=0, n_estimators=50,\n",
      "              num_leaves=30, reg_alpha=0.1, reg_lambda=0, subsample=0.7,\n",
      "              subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 4 repeats: 0.1948\n",
      "Blended average after 4 repeats: 0.1703\n",
      "285.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.9, colsample_bytree=0.65, learning_rate=0.07,\n",
      "              max_depth=6, min_child_samples=30, min_child_weight=0,\n",
      "              min_split_gain=0, n_estimators=350, num_leaves=20, reg_alpha=1,\n",
      "              reg_lambda=0, subsample=0.9, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 5 repeats: 0.1993\n",
      "Blended average after 5 repeats: 0.1721\n",
      "349.6s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.33, learning_rate=0.07, max_depth=4,\n",
      "              min_child_samples=2, min_child_weight=0, min_split_gain=0.001,\n",
      "              n_estimators=150, num_leaves=100, reg_alpha=0.01, reg_lambda=0.01,\n",
      "              subsample=0.7, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 6 repeats: 0.1985\n",
      "Blended average after 6 repeats: 0.1709\n",
      "419.7s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=0.65, colsample_bytree=0.9, max_depth=7,\n",
      "              min_child_samples=30, min_child_weight=0, min_split_gain=0.1,\n",
      "              n_estimators=225, num_leaves=100, reg_alpha=0.1, reg_lambda=0.001,\n",
      "              subsample=0.8, subsample_freq=1)\n",
      "\u001b[36m\n",
      "Running average after 7 repeats: 0.1961\n",
      "Blended average after 7 repeats: 0.1672\n",
      "487.2s\n",
      "\u001b[36m\n",
      "LGBMRegressor(colsample_bynode=1.0, max_depth=7, min_child_samples=7,\n",
      "              min_child_weight=0, min_split_gain=0.001, n_estimators=150,\n",
      "              num_leaves=50, reg_alpha=0, reg_lambda=1e-05, subsample=0.6,\n",
      "              subsample_freq=1)\n",
      "\u001b[33m\n",
      "                        gain\n",
      "feature                     \n",
      "Neck_mean         867.163265\n",
      "Waist_mean        162.673469\n",
      "Neck_std          140.877551\n",
      "Waist_max         128.775510\n",
      "Waist_iliac_mean   59.122449\n",
      "BMI                55.612245\n",
      "V1AD01b            54.979592\n",
      "V1BA01_LB          51.938776\n",
      "Waist_iliac_max    49.816327\n",
      "Hip_mean           46.877551\n",
      "             gain\n",
      "feature          \n",
      "S02G06        0.0\n",
      "V1AE2_04e_1   0.0\n",
      "V1AE2_04f_1   0.0\n",
      "V1AE2_04g_1   0.0\n",
      "V1AF15g       0.0\n",
      "V1GVer        0.0\n",
      "S02G10        0.0\n",
      "V2BVer        0.0\n",
      "V1AA01        0.0\n",
      "S02G09        0.0\n",
      "\u001b[36m\n",
      "\n",
      "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
      "0      00001U            2.348026            0.435350           0.992283   \n",
      "1      00004O            1.474683           -0.012537           0.996685   \n",
      "2      00007I           24.095593            1.722903           0.997104   \n",
      "3      00008G           -0.172039           -0.003570           0.999620   \n",
      "4      00015J            0.100838            0.022685           0.998037   \n",
      "...       ...                 ...                 ...                ...   \n",
      "9284   17349I            0.866327            0.006257           0.998894   \n",
      "9285   17350A            0.450175            0.392335           1.000883   \n",
      "9286   17351V           -0.153617           -0.000846           1.004393   \n",
      "9287   17352T            0.851284           -0.007500           1.003374   \n",
      "9288   17354P            1.434162            0.484234           1.000187   \n",
      "\n",
      "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
      "0              1.004332           1.235634           1.531926   \n",
      "1              1.004756           1.004982           0.979120   \n",
      "2              1.008092           0.994186           1.042216   \n",
      "3              0.999381           0.998314           1.010470   \n",
      "4              0.999813           1.017472           1.055551   \n",
      "...                 ...                ...                ...   \n",
      "9284           0.999205           1.001113           0.988975   \n",
      "9285           0.992716           1.052183           1.355391   \n",
      "9286           0.999383           1.000165           0.999689   \n",
      "9287           0.999662           1.003295           0.998515   \n",
      "9288           1.001221           1.007896           1.030382   \n",
      "\n",
      "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
      "0              1.011470           0.994452           1.355741  ...   \n",
      "1              1.012228           1.019569           1.125877  ...   \n",
      "2              0.992822           1.083187           1.119065  ...   \n",
      "3              0.998857           1.036859           0.975540  ...   \n",
      "4              1.022873           1.010900           1.227488  ...   \n",
      "...                 ...                ...                ...  ...   \n",
      "9284           1.006103           1.045727           1.046157  ...   \n",
      "9285           1.069873           1.347627           1.393278  ...   \n",
      "9286           1.006484           0.985544           1.157548  ...   \n",
      "9287           1.000656           1.001288           1.055910  ...   \n",
      "9288           0.996453           0.986186           1.385738  ...   \n",
      "\n",
      "      Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  Neck_std_lgb2d_pred  \\\n",
      "0               0.107697              28.372242             0.044631   \n",
      "1               0.006194              22.951015             0.014570   \n",
      "2               0.071440              43.641856             0.048138   \n",
      "3               0.097673              32.473743             0.066000   \n",
      "4              -0.002093              20.008343             0.013388   \n",
      "...                  ...                    ...                  ...   \n",
      "9284            0.141392              22.613755             0.082475   \n",
      "9285            0.025008              29.508560             0.018812   \n",
      "9286            0.004215              26.952829            -0.001614   \n",
      "9287            0.107372              25.148863             0.114119   \n",
      "9288            0.010873              26.969874             0.021681   \n",
      "\n",
      "      Height_max_lgb2d_pred  Waist_max_lgb2d_pred  Waist_iliac_max_lgb2d_pred  \\\n",
      "0                154.784648             86.591876                  106.092724   \n",
      "1                166.838345             70.984231                   80.056719   \n",
      "2                159.907992             75.235010                   88.863915   \n",
      "3                175.004126             90.164611                  102.184926   \n",
      "4                173.993261             82.953786                   94.328020   \n",
      "...                     ...                   ...                         ...   \n",
      "9284             169.899913             79.981719                   90.531017   \n",
      "9285             157.398090             81.034286                   89.970529   \n",
      "9286             168.114039             97.444968                   99.128399   \n",
      "9287             136.068999             61.785014                   63.217698   \n",
      "9288             160.409202             95.068666                  105.794453   \n",
      "\n",
      "      Hip_max_lgb2d_pred  BP_Sys_max_lgb2d_pred  BP_Dia_max_lgb2d_pred  \\\n",
      "0             113.477225             110.016916              70.004176   \n",
      "1              97.992614              94.075244              61.948779   \n",
      "2              97.108531             121.668056              60.013986   \n",
      "3             112.051239             108.285161              62.091930   \n",
      "4              96.520567             101.865451              74.013877   \n",
      "...                  ...                    ...                    ...   \n",
      "9284          108.161618             100.100260              68.063455   \n",
      "9285           91.235114             110.056340              67.940603   \n",
      "9286          101.843612             109.952193              72.004871   \n",
      "9287           73.343669              72.042289              45.778201   \n",
      "9288          114.967730             101.898350              64.147928   \n",
      "\n",
      "      Neck_max_lgb2d_pred  \n",
      "0               32.727797  \n",
      "1               27.601300  \n",
      "2               32.069134  \n",
      "3               34.511375  \n",
      "4               31.513454  \n",
      "...                   ...  \n",
      "9284            28.168945  \n",
      "9285            33.915857  \n",
      "9286            34.921038  \n",
      "9287            25.284948  \n",
      "9288            37.862172  \n",
      "\n",
      "[9289 rows x 65 columns]\n",
      "lgb2d.csv (9289, 65)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PublicID</th>\n",
       "      <th>V2AH02b_lgb2d_pred</th>\n",
       "      <th>V2AH02c_lgb2d_pred</th>\n",
       "      <th>V2AI01_lgb2d_pred</th>\n",
       "      <th>V2AI02_lgb2d_pred</th>\n",
       "      <th>V2AI03_lgb2d_pred</th>\n",
       "      <th>V2AI04_lgb2d_pred</th>\n",
       "      <th>V2AI05_lgb2d_pred</th>\n",
       "      <th>V2AI06_lgb2d_pred</th>\n",
       "      <th>V2AI07_lgb2d_pred</th>\n",
       "      <th>...</th>\n",
       "      <th>Hip_std_lgb2d_pred</th>\n",
       "      <th>BP_Sys_std_lgb2d_pred</th>\n",
       "      <th>Neck_std_lgb2d_pred</th>\n",
       "      <th>Height_max_lgb2d_pred</th>\n",
       "      <th>Waist_max_lgb2d_pred</th>\n",
       "      <th>Waist_iliac_max_lgb2d_pred</th>\n",
       "      <th>Hip_max_lgb2d_pred</th>\n",
       "      <th>BP_Sys_max_lgb2d_pred</th>\n",
       "      <th>BP_Dia_max_lgb2d_pred</th>\n",
       "      <th>Neck_max_lgb2d_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001U</td>\n",
       "      <td>2.348026</td>\n",
       "      <td>0.435350</td>\n",
       "      <td>0.992283</td>\n",
       "      <td>1.004332</td>\n",
       "      <td>1.235634</td>\n",
       "      <td>1.531926</td>\n",
       "      <td>1.011470</td>\n",
       "      <td>0.994452</td>\n",
       "      <td>1.355741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107697</td>\n",
       "      <td>28.372242</td>\n",
       "      <td>0.044631</td>\n",
       "      <td>154.784648</td>\n",
       "      <td>86.591876</td>\n",
       "      <td>106.092724</td>\n",
       "      <td>113.477225</td>\n",
       "      <td>110.016916</td>\n",
       "      <td>70.004176</td>\n",
       "      <td>32.727797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004O</td>\n",
       "      <td>1.474683</td>\n",
       "      <td>-0.012537</td>\n",
       "      <td>0.996685</td>\n",
       "      <td>1.004756</td>\n",
       "      <td>1.004982</td>\n",
       "      <td>0.979120</td>\n",
       "      <td>1.012228</td>\n",
       "      <td>1.019569</td>\n",
       "      <td>1.125877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>22.951015</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>166.838345</td>\n",
       "      <td>70.984231</td>\n",
       "      <td>80.056719</td>\n",
       "      <td>97.992614</td>\n",
       "      <td>94.075244</td>\n",
       "      <td>61.948779</td>\n",
       "      <td>27.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007I</td>\n",
       "      <td>24.095593</td>\n",
       "      <td>1.722903</td>\n",
       "      <td>0.997104</td>\n",
       "      <td>1.008092</td>\n",
       "      <td>0.994186</td>\n",
       "      <td>1.042216</td>\n",
       "      <td>0.992822</td>\n",
       "      <td>1.083187</td>\n",
       "      <td>1.119065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071440</td>\n",
       "      <td>43.641856</td>\n",
       "      <td>0.048138</td>\n",
       "      <td>159.907992</td>\n",
       "      <td>75.235010</td>\n",
       "      <td>88.863915</td>\n",
       "      <td>97.108531</td>\n",
       "      <td>121.668056</td>\n",
       "      <td>60.013986</td>\n",
       "      <td>32.069134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00008G</td>\n",
       "      <td>-0.172039</td>\n",
       "      <td>-0.003570</td>\n",
       "      <td>0.999620</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.998314</td>\n",
       "      <td>1.010470</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>1.036859</td>\n",
       "      <td>0.975540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097673</td>\n",
       "      <td>32.473743</td>\n",
       "      <td>0.066000</td>\n",
       "      <td>175.004126</td>\n",
       "      <td>90.164611</td>\n",
       "      <td>102.184926</td>\n",
       "      <td>112.051239</td>\n",
       "      <td>108.285161</td>\n",
       "      <td>62.091930</td>\n",
       "      <td>34.511375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00015J</td>\n",
       "      <td>0.100838</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.998037</td>\n",
       "      <td>0.999813</td>\n",
       "      <td>1.017472</td>\n",
       "      <td>1.055551</td>\n",
       "      <td>1.022873</td>\n",
       "      <td>1.010900</td>\n",
       "      <td>1.227488</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002093</td>\n",
       "      <td>20.008343</td>\n",
       "      <td>0.013388</td>\n",
       "      <td>173.993261</td>\n",
       "      <td>82.953786</td>\n",
       "      <td>94.328020</td>\n",
       "      <td>96.520567</td>\n",
       "      <td>101.865451</td>\n",
       "      <td>74.013877</td>\n",
       "      <td>31.513454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9284</th>\n",
       "      <td>17349I</td>\n",
       "      <td>0.866327</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>0.998894</td>\n",
       "      <td>0.999205</td>\n",
       "      <td>1.001113</td>\n",
       "      <td>0.988975</td>\n",
       "      <td>1.006103</td>\n",
       "      <td>1.045727</td>\n",
       "      <td>1.046157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141392</td>\n",
       "      <td>22.613755</td>\n",
       "      <td>0.082475</td>\n",
       "      <td>169.899913</td>\n",
       "      <td>79.981719</td>\n",
       "      <td>90.531017</td>\n",
       "      <td>108.161618</td>\n",
       "      <td>100.100260</td>\n",
       "      <td>68.063455</td>\n",
       "      <td>28.168945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>17350A</td>\n",
       "      <td>0.450175</td>\n",
       "      <td>0.392335</td>\n",
       "      <td>1.000883</td>\n",
       "      <td>0.992716</td>\n",
       "      <td>1.052183</td>\n",
       "      <td>1.355391</td>\n",
       "      <td>1.069873</td>\n",
       "      <td>1.347627</td>\n",
       "      <td>1.393278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>29.508560</td>\n",
       "      <td>0.018812</td>\n",
       "      <td>157.398090</td>\n",
       "      <td>81.034286</td>\n",
       "      <td>89.970529</td>\n",
       "      <td>91.235114</td>\n",
       "      <td>110.056340</td>\n",
       "      <td>67.940603</td>\n",
       "      <td>33.915857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>17351V</td>\n",
       "      <td>-0.153617</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>1.004393</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>1.000165</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>1.006484</td>\n",
       "      <td>0.985544</td>\n",
       "      <td>1.157548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>26.952829</td>\n",
       "      <td>-0.001614</td>\n",
       "      <td>168.114039</td>\n",
       "      <td>97.444968</td>\n",
       "      <td>99.128399</td>\n",
       "      <td>101.843612</td>\n",
       "      <td>109.952193</td>\n",
       "      <td>72.004871</td>\n",
       "      <td>34.921038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>17352T</td>\n",
       "      <td>0.851284</td>\n",
       "      <td>-0.007500</td>\n",
       "      <td>1.003374</td>\n",
       "      <td>0.999662</td>\n",
       "      <td>1.003295</td>\n",
       "      <td>0.998515</td>\n",
       "      <td>1.000656</td>\n",
       "      <td>1.001288</td>\n",
       "      <td>1.055910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107372</td>\n",
       "      <td>25.148863</td>\n",
       "      <td>0.114119</td>\n",
       "      <td>136.068999</td>\n",
       "      <td>61.785014</td>\n",
       "      <td>63.217698</td>\n",
       "      <td>73.343669</td>\n",
       "      <td>72.042289</td>\n",
       "      <td>45.778201</td>\n",
       "      <td>25.284948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9288</th>\n",
       "      <td>17354P</td>\n",
       "      <td>1.434162</td>\n",
       "      <td>0.484234</td>\n",
       "      <td>1.000187</td>\n",
       "      <td>1.001221</td>\n",
       "      <td>1.007896</td>\n",
       "      <td>1.030382</td>\n",
       "      <td>0.996453</td>\n",
       "      <td>0.986186</td>\n",
       "      <td>1.385738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010873</td>\n",
       "      <td>26.969874</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>160.409202</td>\n",
       "      <td>95.068666</td>\n",
       "      <td>105.794453</td>\n",
       "      <td>114.967730</td>\n",
       "      <td>101.898350</td>\n",
       "      <td>64.147928</td>\n",
       "      <td>37.862172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9289 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PublicID  V2AH02b_lgb2d_pred  V2AH02c_lgb2d_pred  V2AI01_lgb2d_pred  \\\n",
       "0      00001U            2.348026            0.435350           0.992283   \n",
       "1      00004O            1.474683           -0.012537           0.996685   \n",
       "2      00007I           24.095593            1.722903           0.997104   \n",
       "3      00008G           -0.172039           -0.003570           0.999620   \n",
       "4      00015J            0.100838            0.022685           0.998037   \n",
       "...       ...                 ...                 ...                ...   \n",
       "9284   17349I            0.866327            0.006257           0.998894   \n",
       "9285   17350A            0.450175            0.392335           1.000883   \n",
       "9286   17351V           -0.153617           -0.000846           1.004393   \n",
       "9287   17352T            0.851284           -0.007500           1.003374   \n",
       "9288   17354P            1.434162            0.484234           1.000187   \n",
       "\n",
       "      V2AI02_lgb2d_pred  V2AI03_lgb2d_pred  V2AI04_lgb2d_pred  \\\n",
       "0              1.004332           1.235634           1.531926   \n",
       "1              1.004756           1.004982           0.979120   \n",
       "2              1.008092           0.994186           1.042216   \n",
       "3              0.999381           0.998314           1.010470   \n",
       "4              0.999813           1.017472           1.055551   \n",
       "...                 ...                ...                ...   \n",
       "9284           0.999205           1.001113           0.988975   \n",
       "9285           0.992716           1.052183           1.355391   \n",
       "9286           0.999383           1.000165           0.999689   \n",
       "9287           0.999662           1.003295           0.998515   \n",
       "9288           1.001221           1.007896           1.030382   \n",
       "\n",
       "      V2AI05_lgb2d_pred  V2AI06_lgb2d_pred  V2AI07_lgb2d_pred  ...  \\\n",
       "0              1.011470           0.994452           1.355741  ...   \n",
       "1              1.012228           1.019569           1.125877  ...   \n",
       "2              0.992822           1.083187           1.119065  ...   \n",
       "3              0.998857           1.036859           0.975540  ...   \n",
       "4              1.022873           1.010900           1.227488  ...   \n",
       "...                 ...                ...                ...  ...   \n",
       "9284           1.006103           1.045727           1.046157  ...   \n",
       "9285           1.069873           1.347627           1.393278  ...   \n",
       "9286           1.006484           0.985544           1.157548  ...   \n",
       "9287           1.000656           1.001288           1.055910  ...   \n",
       "9288           0.996453           0.986186           1.385738  ...   \n",
       "\n",
       "      Hip_std_lgb2d_pred  BP_Sys_std_lgb2d_pred  Neck_std_lgb2d_pred  \\\n",
       "0               0.107697              28.372242             0.044631   \n",
       "1               0.006194              22.951015             0.014570   \n",
       "2               0.071440              43.641856             0.048138   \n",
       "3               0.097673              32.473743             0.066000   \n",
       "4              -0.002093              20.008343             0.013388   \n",
       "...                  ...                    ...                  ...   \n",
       "9284            0.141392              22.613755             0.082475   \n",
       "9285            0.025008              29.508560             0.018812   \n",
       "9286            0.004215              26.952829            -0.001614   \n",
       "9287            0.107372              25.148863             0.114119   \n",
       "9288            0.010873              26.969874             0.021681   \n",
       "\n",
       "      Height_max_lgb2d_pred  Waist_max_lgb2d_pred  Waist_iliac_max_lgb2d_pred  \\\n",
       "0                154.784648             86.591876                  106.092724   \n",
       "1                166.838345             70.984231                   80.056719   \n",
       "2                159.907992             75.235010                   88.863915   \n",
       "3                175.004126             90.164611                  102.184926   \n",
       "4                173.993261             82.953786                   94.328020   \n",
       "...                     ...                   ...                         ...   \n",
       "9284             169.899913             79.981719                   90.531017   \n",
       "9285             157.398090             81.034286                   89.970529   \n",
       "9286             168.114039             97.444968                   99.128399   \n",
       "9287             136.068999             61.785014                   63.217698   \n",
       "9288             160.409202             95.068666                  105.794453   \n",
       "\n",
       "      Hip_max_lgb2d_pred  BP_Sys_max_lgb2d_pred  BP_Dia_max_lgb2d_pred  \\\n",
       "0             113.477225             110.016916              70.004176   \n",
       "1              97.992614              94.075244              61.948779   \n",
       "2              97.108531             121.668056              60.013986   \n",
       "3             112.051239             108.285161              62.091930   \n",
       "4              96.520567             101.865451              74.013877   \n",
       "...                  ...                    ...                    ...   \n",
       "9284          108.161618             100.100260              68.063455   \n",
       "9285           91.235114             110.056340              67.940603   \n",
       "9286          101.843612             109.952193              72.004871   \n",
       "9287           73.343669              72.042289              45.778201   \n",
       "9288          114.967730             101.898350              64.147928   \n",
       "\n",
       "      Neck_max_lgb2d_pred  \n",
       "0               32.727797  \n",
       "1               27.601300  \n",
       "2               32.069134  \n",
       "3               34.511375  \n",
       "4               31.513454  \n",
       "...                   ...  \n",
       "9284            28.168945  \n",
       "9285            33.915857  \n",
       "9286            34.921038  \n",
       "9287            25.284948  \n",
       "9288            37.862172  \n",
       "\n",
       "[9289 rows x 65 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over all features, impute missing values with lgb\n",
    "rez = a[['PublicID']].copy()\n",
    "n = len(a)\n",
    "for i,target in enumerate(features0):\n",
    "        \n",
    "    if target in drop: continue\n",
    "    if i < start: continue\n",
    "    if i >= stop: continue\n",
    "    \n",
    "    miss = a[target].isnull()\n",
    "    nmiss = miss.sum()\n",
    "    # if nmiss==0: continue\n",
    "        \n",
    "    nu = a[target].nunique()\n",
    "    \n",
    "    if nu <= 2: continue\n",
    "    \n",
    "    print(g_)\n",
    "    print('+'*60)\n",
    "    print(f'{i+1}/{nf}',target,nu,f'{nmiss/n:.3f}')\n",
    "    print('+'*60)\n",
    "    print(c_)\n",
    "    \n",
    "    features = [f for f in features0 if f != target]\n",
    "    \n",
    "    # training and test data based on missingness\n",
    "    d = a[~miss]\n",
    "    t = a[miss]\n",
    "    print(d.shape, t.shape)\n",
    "    \n",
    "    x = d[features]\n",
    "    y = d[target]\n",
    "    x_test = t[features]\n",
    "    print(x.shape, y.shape, x_test.shape)\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    if nu==2: \n",
    "        est = lgb.LGBMClassifier()\n",
    "        loss = 'neg_brier_score'\n",
    "        # loss = 'brier_score_loss'\n",
    "        y = y.astype(int)\n",
    "        for i in range(N_REPEATS):\n",
    "            folds.extend(list(StratifiedKFold(n_splits=N_SPLITS, random_state=i+seed, shuffle=True).split(x, y)))\n",
    "        kf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True)\n",
    "    else: \n",
    "        est = lgb.LGBMRegressor()\n",
    "        loss = 'neg_mean_squared_error'\n",
    "        for i in range(N_REPEATS):\n",
    "            folds.extend(list(KFold(n_splits=N_SPLITS, random_state=i+seed, shuffle=True).split(x, y)))\n",
    "        kf = KFold(n_splits=N_SPLITS, shuffle=True)\n",
    "        \n",
    "    models, scores, yp, tp = fitModel(folds, x, y, est, params, N_TRIES, loss, kf, verbose=5)\n",
    "\n",
    "    imp = [pd.DataFrame({'feature':features,'gain':m.feature_importances_}) for m in models]\n",
    "    imp = pd.concat(imp).groupby('feature').mean()\n",
    "    imp.sort_values('gain', inplace=True, ascending=False)\n",
    "    print(y_)\n",
    "    print(imp[:10])\n",
    "    print(imp[-10:])\n",
    "    print(c_)\n",
    "    \n",
    "    pn = target+'_'+mname+'_pred'\n",
    "    rez[pn] = 0\n",
    "    rez.loc[~miss,pn] = yp\n",
    "    rez.loc[miss,pn] = tp\n",
    "    \n",
    "    # save current results\n",
    "    fname = f'{mname}.csv'\n",
    "    rez.to_csv(fname, index=False)\n",
    "    print()\n",
    "    print(rez)\n",
    "    print(fname, rez.shape)\n",
    "    print()\n",
    "    \n",
    "rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fcddf4-32f3-4b09-abba-55adcdabda71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
